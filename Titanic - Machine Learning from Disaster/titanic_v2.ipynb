{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "623ee1f8",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#F14925\";><big>Titanic - Machine Learning from Disaster</big></h1>\n",
    "\n",
    "This competition is one of the most popular introductory challenges on [Kaggle website](https://www.kaggle.com/competitions/titanic) and is designed to help participants learn the basics of data analysis, data visualization, and machine learning.\n",
    "\n",
    "\n",
    "## Overview of the Competition:\n",
    "\n",
    "* The Titanic competition is based on the sinking of the RMS Titanic in 1912.\n",
    "* **The goal** is to predict whether a passenger survived or not (binary classification) based on the provided features.\n",
    "* You are given two datasets: one for training and one for testing the model's performance.\n",
    "    1. The training dataset contains information about passengers, including their age, sex, ticket class, fare, etc., along with a \"Survived\" column (1 for survived, 0 for not survived).\n",
    "    1. The testing dataset is similar, but it does not have the \"Survived\" column that you need to predict.\n",
    "    \n",
    "### The competition is simple:\n",
    "> Use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\\\n",
    "Using the patterns you find in the train.csv data, predict whether\\\n",
    "the other 418 passengers on board (found in test.csv) survived.\n",
    "\n",
    "---\n",
    "**Submission Score:  0.78947**\n",
    "\n",
    "**Leaderboard position: 1418/16160**\n",
    "\n",
    "**Top 9%**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5b2fe",
   "metadata": {},
   "source": [
    "# Data Description:\n",
    "\n",
    "* The training dataset contains 12 columns: PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, and Embarked.\n",
    "* The testing dataset contains 11 columns (no \"Survived\" column).\n",
    "* \"Pclass\" represents the passenger class (1st, 2nd, or 3rd class).\n",
    "* \"SibSp\" refers to the number of siblings or spouses aboard.\n",
    "* \"Parch\" refers to the number of parents or children aboard.\n",
    "* \"Embarked\" represents the port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n",
    "\n",
    "#### The data is contain in two files:\n",
    "    \n",
    "        1. Train.csv will contain the details of a subset of the passengers on board (891 to be exact) \n",
    "    and importantly, will reveal whether they survived or not, also known as the “ground truth”.\n",
    "\n",
    "        2. The `test.csv` dataset contains similar information but does not disclose the “ground truth”\n",
    "    for each passenger. It’s your job to predict these outcomes.\n",
    "    \n",
    "#### It is organized as follows:\n",
    "    \n",
    "    Variable | Definition\t       |  Key\n",
    "    ---------|---------------------|---------------------\n",
    "    survival |  Survival\t       |  0 = No, 1 = Yes\n",
    "    pclass   |  Ticket class       | 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex      |   Sex               |  female, male\t\n",
    "    Age      |   Age in years      |\n",
    "    sibsp    |   # of siblings /   |\n",
    "             |   spouses aboard    |\n",
    "             |   the Titanic       |\n",
    "    parch\t |   # of parents /    |\n",
    "             |   children aboard   |\n",
    "             |   the Titanic       |\n",
    "    ticket   |   Ticket number     |\n",
    "    fare     |   Passenger fare    |\n",
    "    cabin    |   Cabin number      |\n",
    "    embarked |  Port of Embarkation|  C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc04384d",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fac2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4cb28",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa5848c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train dataframe\n",
    "train_df = pd.read_csv('kdata_train.csv', sep=',', header='infer')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e943f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check test data frame\n",
    "test_df  = pd.read_csv('kdata_test.csv', sep=',', header='infer')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9f4ec",
   "metadata": {},
   "source": [
    "### Checking for missing values and simplifying meaningless columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f4cd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Coloum labels: ['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked']\n",
      "\n",
      "--Missing values in train data--\t\n",
      "Coloum: Age, Empty:177 corresponding to 19.89%\n",
      "Coloum: Cabin, Empty:687 corresponding to 77.19%\n",
      "Coloum: Embarked, Empty:2 corresponding to 0.22%\n"
     ]
    }
   ],
   "source": [
    "### Get keys for reference\n",
    "df_keys = train_df.keys()\n",
    "df_keys = np.array(df_keys)\n",
    "print('\\nData Coloum labels:',df_keys)\n",
    "\n",
    "### Checking for empty values\n",
    "print('\\n--Missing values in train data--\\t')\n",
    "mask = np.where(pd.isnull(train_df))[1]\n",
    "mask = np.unique(mask, return_counts=True)\n",
    "\n",
    "for i in range(len(mask[0])):\n",
    "    print('Coloum: %s, Empty:%i corresponding to %.2f%%'%(df_keys[mask[0]][i],mask[1][i],mask[1][i]/890*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a327a",
   "metadata": {},
   "source": [
    "    * \"Age\": could potentially be troublesome since we expecte that kids and older people to \n",
    "    had a lower chance to survive let go deep into this.\n",
    "    \n",
    "    * \"Cabin\": contains a lot of unkown entries, so we will ignore this coloum for now.\n",
    "    \n",
    "    * \"Embarked\": can be use let's set the 2 missing values to the most frequent value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e95590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--Missing values in test data--\t\n",
      "Coloum: Sex, Empty:86 corresponding to 20.57%\n",
      "Coloum: Ticket, Empty:1 corresponding to 0.24%\n",
      "Coloum: Fare, Empty:327 corresponding to 78.23%\n"
     ]
    }
   ],
   "source": [
    "### Checking for empty values\n",
    "print('\\n--Missing values in test data--\\t')\n",
    "\n",
    "df_keys_test = test_df.keys()\n",
    "df_keys_test = np.array(df_keys)\n",
    "\n",
    "mask = np.where(pd.isnull(test_df))[1]\n",
    "mask = np.unique(mask, return_counts=True)\n",
    "\n",
    "for i in range(len(mask[0])):\n",
    "    print('Coloum: %s, Empty:%i corresponding to %.2f%%'%(df_keys_test[mask[0]][i],mask[1][i],mask[1][i]/418*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f58889",
   "metadata": {},
   "source": [
    "    \"Age\": As in the train data set, this could potentially be troublesome since we expecte that kids and older people to \n",
    "    had a lower chance to survive let go deep into this.\n",
    "    \n",
    "    \"Cabin\": we will ignore this coloum.\n",
    "    \n",
    "    \"Fare\": since it is only one let's manually set it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e585b7",
   "metadata": {},
   "source": [
    "#### Dropped coulums: Cabin, PassengerId, and Ticket\n",
    "    Cabin: Too many empty Values.\n",
    "    PassengerId: is just the position on the list\n",
    "    Ticket number: probably does not mean anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b60742a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass                                               Name  \\\n",
       "0           0       3                            Braund, Mr. Owen Harris   \n",
       "1           1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2           1       3                             Heikkinen, Miss. Laina   \n",
       "3           1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4           0       3                           Allen, Mr. William Henry   \n",
       "..        ...     ...                                                ...   \n",
       "886         0       2                              Montvila, Rev. Juozas   \n",
       "887         1       1                       Graham, Miss. Margaret Edith   \n",
       "888         0       3           Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "889         1       1                              Behr, Mr. Karl Howell   \n",
       "890         0       3                                Dooley, Mr. Patrick   \n",
       "\n",
       "        Sex   Age  SibSp  Parch     Fare Embarked  \n",
       "0      male  22.0      1      0   7.2500        S  \n",
       "1    female  38.0      1      0  71.2833        C  \n",
       "2    female  26.0      0      0   7.9250        S  \n",
       "3    female  35.0      1      0  53.1000        S  \n",
       "4      male  35.0      0      0   8.0500        S  \n",
       "..      ...   ...    ...    ...      ...      ...  \n",
       "886    male  27.0      0      0  13.0000        S  \n",
       "887  female  19.0      0      0  30.0000        S  \n",
       "888  female   NaN      1      2  23.4500        S  \n",
       "889    male  26.0      0      0  30.0000        C  \n",
       "890    male  32.0      0      0   7.7500        Q  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=train_df.drop(['Cabin','Ticket','PassengerId'],axis=1)\n",
    "test_df=test_df.drop(['Cabin','Ticket','PassengerId'],axis=1)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec359b",
   "metadata": {},
   "source": [
    "### Filling missing values and encoding data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9809ba",
   "metadata": {},
   "source": [
    "#### First set the Embarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98cabda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequent value in a pandas column  S\n",
      "Any other missing value  (array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "# most frequent value in a pandas column\n",
    "embarked_mostfrequent = train_df['Embarked'].value_counts().idxmax()\n",
    "print('most frequent value in a pandas column ',embarked_mostfrequent)\n",
    "\n",
    "mask = pd.isnull(train_df['Embarked'])\n",
    "temp = np.copy(train_df['Embarked'])\n",
    "temp[mask] = embarked_mostfrequent\n",
    "train_df['Embarked'] = temp\n",
    "print('Any other missing value ',np.where(pd.isnull(train_df['Embarked'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be846191",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encode class labels as integer values between 0 and (n_classes-1)\n",
    "labelencoder = preprocessing.LabelEncoder()\n",
    "labelencoder.fit(train_df['Embarked'])\n",
    "train_df['Embarked'] = labelencoder.transform(train_df['Embarked'])\n",
    "test_df['Embarked'] = labelencoder.transform(test_df['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff531c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass                                               Name  \\\n",
       "0           0       3                            Braund, Mr. Owen Harris   \n",
       "1           1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2           1       3                             Heikkinen, Miss. Laina   \n",
       "3           1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4           0       3                           Allen, Mr. William Henry   \n",
       "..        ...     ...                                                ...   \n",
       "886         0       2                              Montvila, Rev. Juozas   \n",
       "887         1       1                       Graham, Miss. Margaret Edith   \n",
       "888         0       3           Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "889         1       1                              Behr, Mr. Karl Howell   \n",
       "890         0       3                                Dooley, Mr. Patrick   \n",
       "\n",
       "        Sex   Age  SibSp  Parch     Fare  Embarked  \n",
       "0      male  22.0      1      0   7.2500         2  \n",
       "1    female  38.0      1      0  71.2833         0  \n",
       "2    female  26.0      0      0   7.9250         2  \n",
       "3    female  35.0      1      0  53.1000         2  \n",
       "4      male  35.0      0      0   8.0500         2  \n",
       "..      ...   ...    ...    ...      ...       ...  \n",
       "886    male  27.0      0      0  13.0000         2  \n",
       "887  female  19.0      0      0  30.0000         2  \n",
       "888  female   NaN      1      2  23.4500         2  \n",
       "889    male  26.0      0      0  30.0000         0  \n",
       "890    male  32.0      0      0   7.7500         1  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "589e6069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass                                          Name     Sex   Age  \\\n",
       "0         3                              Kelly, Mr. James    male  34.5   \n",
       "1         3              Wilkes, Mrs. James (Ellen Needs)  female  47.0   \n",
       "2         2                     Myles, Mr. Thomas Francis    male  62.0   \n",
       "3         3                              Wirz, Mr. Albert    male  27.0   \n",
       "4         3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0   \n",
       "..      ...                                           ...     ...   ...   \n",
       "413       3                            Spector, Mr. Woolf    male   NaN   \n",
       "414       1                  Oliva y Ocana, Dona. Fermina  female  39.0   \n",
       "415       3                  Saether, Mr. Simon Sivertsen    male  38.5   \n",
       "416       3                           Ware, Mr. Frederick    male   NaN   \n",
       "417       3                      Peter, Master. Michael J    male   NaN   \n",
       "\n",
       "     SibSp  Parch      Fare  Embarked  \n",
       "0        0      0    7.8292         1  \n",
       "1        1      0    7.0000         2  \n",
       "2        0      0    9.6875         1  \n",
       "3        0      0    8.6625         2  \n",
       "4        1      1   12.2875         2  \n",
       "..     ...    ...       ...       ...  \n",
       "413      0      0    8.0500         2  \n",
       "414      0      0  108.9000         0  \n",
       "415      0      0    7.2500         2  \n",
       "416      0      0    8.0500         2  \n",
       "417      1      1   22.3583         0  \n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36021676",
   "metadata": {},
   "source": [
    "#### Second relate the Age and the Name, \n",
    "    since the name contains their \"honorific label\" we are going to\n",
    "    fill missing age values depending on their honorific name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c9c79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "honor = np.copy(train_df['Name'])\n",
    "honor = [(name.split(',')[1]).split('.')[0][1:] for name in honor]\n",
    "\n",
    "for i,name in enumerate(honor):\n",
    "    if name=='Capt' or name=='Col' or name=='Don' or name=='Dr' or name=='Jonkheer' or name=='Major' or name=='Rev'or name=='Sir':\n",
    "        honor[i] = 'Mr'\n",
    "        \n",
    "    elif name=='Lady' or name=='Mlle' or name=='Ms':\n",
    "        honor[i] = 'Miss'\n",
    "        \n",
    "    elif name=='Mme' or name=='the Countess':\n",
    "        honor[i] = 'Mrs'  \n",
    "honor = np.array(honor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b452ba6",
   "metadata": {},
   "source": [
    "    Mr -> refers to a male adult,\n",
    "    Mrs -> Married women\n",
    "    Miss -> non Married women\n",
    "    Master -> kids\n",
    "    \n",
    "    can we correlate this to surv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9699f9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 40.,   0.,   0., 186.,   0.,   0., 538.,   0.,   0., 127.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's convert this values into numerical categories\n",
    "## Encode class labels as integer values between 0 and (n_classes-1)\n",
    "labelencoder = preprocessing.LabelEncoder()\n",
    "labelencoder.fit(honor)\n",
    "honor = labelencoder.transform(honor)\n",
    "\n",
    "#['Master' 'Miss' 'Mr' 'Mrs'] ---> [0,1,2,3]\n",
    "plt.hist(honor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b77504d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mean age for ['Master'] is 4\n",
      " mean age for ['Miss'] is 22\n",
      " mean age for ['Mr'] is 33\n",
      " mean age for ['Mrs'] is 35\n",
      "\n",
      "Filling missing values...\n",
      "\n",
      "Check any missing value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: Age, dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the non-empty values of age\n",
    "mask = pd.isnull(train_df['Age'])\n",
    "honor_nonnan = honor[~mask]\n",
    "age_nonnan = np.copy(train_df['Age'][~mask])\n",
    "\n",
    "## Get the mean age value for each of the honor labels\n",
    "mean_honor_age = [0,0,0,0]\n",
    "for h in [0, 1, 2, 3]:\n",
    "    mask = (honor_nonnan == h)\n",
    "    mean_honor_age[h] = np.mean(age_nonnan[mask]).astype(np.int64)\n",
    "\n",
    "print(' mean age for %s is %i'%(labelencoder.inverse_transform([0]),mean_honor_age[0]))\n",
    "print(' mean age for %s is %i'%(labelencoder.inverse_transform([1]),mean_honor_age[1]))\n",
    "print(' mean age for %s is %i'%(labelencoder.inverse_transform([2]),mean_honor_age[2]))\n",
    "print(' mean age for %s is %i'%(labelencoder.inverse_transform([3]),mean_honor_age[3]))\n",
    "\n",
    "print('\\nFilling missing values...')\n",
    "temp_age = np.copy(train_df['Age'])\n",
    "temp = np.array([temp_age,honor]).T\n",
    "\n",
    "for i,age in enumerate(temp):\n",
    "    if pd.isna(age[0]):\n",
    "        temp[i][0]= mean_honor_age[int(age[1])]\n",
    "train_df['Age'] = temp.astype(np.int64)\n",
    "\n",
    "print('\\nCheck any missing value')\n",
    "train_df['Age'][pd.isnull(train_df['Age'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "039c6624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### We could actually change the names by its honorific name to vectorize them\n",
    "#Also we could make a family size group to gain more information\n",
    "train_df['Name'] = honor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe5133e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Name     Sex  Age  SibSp  Parch     Fare  Embarked\n",
       "0           0       3     2    male   22      1      0   7.2500         2\n",
       "1           1       1     3  female   38      1      0  71.2833         0\n",
       "2           1       3     1  female   26      0      0   7.9250         2\n",
       "3           1       1     3  female   35      1      0  53.1000         2\n",
       "4           0       3     2    male   35      0      0   8.0500         2\n",
       "..        ...     ...   ...     ...  ...    ...    ...      ...       ...\n",
       "886         0       2     2    male   27      0      0  13.0000         2\n",
       "887         1       1     1  female   19      0      0  30.0000         2\n",
       "888         0       3     1  female   22      1      2  23.4500         2\n",
       "889         1       1     2    male   26      0      0  30.0000         0\n",
       "890         0       3     2    male   32      0      0   7.7500         1\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2bd3f5",
   "metadata": {},
   "source": [
    "##### Let's do the same to fill empty ages in the test data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6150dcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mean age for ['Master'] is 7\n",
      " mean age for ['Miss'] is 22\n",
      " mean age for ['Mr'] is 32\n",
      " mean age for ['Mrs'] is 38\n",
      "\n",
      "Filling missing values...\n",
      "\n",
      "Check any missing value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Name     Sex  Age  SibSp  Parch      Fare  Embarked\n",
       "0         3     2    male   34      0      0    7.8292         1\n",
       "1         3     3  female   47      1      0    7.0000         2\n",
       "2         2     2    male   62      0      0    9.6875         1\n",
       "3         3     2    male   27      0      0    8.6625         2\n",
       "4         3     3  female   22      1      1   12.2875         2\n",
       "..      ...   ...     ...  ...    ...    ...       ...       ...\n",
       "413       3     2    male   32      0      0    8.0500         2\n",
       "414       1     1  female   39      0      0  108.9000         0\n",
       "415       3     2    male   38      0      0    7.2500         2\n",
       "416       3     2    male   32      0      0    8.0500         2\n",
       "417       3     0    male    7      1      1   22.3583         0\n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "honor = np.copy(test_df['Name'])\n",
    "honor = [(name.split(',')[1]).split('.')[0][1:] for name in honor]\n",
    "np.unique(honor)\n",
    "\n",
    "for i,name in enumerate(honor):\n",
    "    if name=='Col' or name=='Dr' or name=='Rev':\n",
    "        honor[i] = 'Mr'\n",
    "        \n",
    "    elif name=='Dona' or name=='Ms':\n",
    "        honor[i] = 'Miss'\n",
    "        \n",
    "honor = np.array(honor)\n",
    "\n",
    "# Let's convert this values into numerical categories\n",
    "honor = labelencoder.transform(honor)\n",
    "\n",
    "mask = pd.isnull(test_df['Age'])\n",
    "honor_nonnan = honor[~mask]\n",
    "age_nonnan = np.copy(test_df['Age'][~mask])\n",
    "\n",
    "mean_honor_age = [0,0,0,0]\n",
    "for h in [0, 1, 2, 3]:\n",
    "    mask = (honor_nonnan == h)\n",
    "    mean_honor_age[h] = np.mean(age_nonnan[mask])\n",
    "\n",
    "print(' mean age for %s is %i'%(labelencoder.inverse_transform([0]),mean_honor_age[0]))\n",
    "print(' mean age for %s is %i'%(labelencoder.inverse_transform([1]),mean_honor_age[1]))\n",
    "print(' mean age for %s is %i'%(labelencoder.inverse_transform([2]),mean_honor_age[2]))\n",
    "print(' mean age for %s is %i'%(labelencoder.inverse_transform([3]),mean_honor_age[3]))\n",
    "\n",
    "\n",
    "print('\\nFilling missing values...')\n",
    "temp_age = np.copy(test_df['Age'])\n",
    "temp = np.array([temp_age,honor]).T\n",
    "\n",
    "for i,age in enumerate(temp):\n",
    "    if pd.isna(age[0]):\n",
    "        temp[i][0]= mean_honor_age[int(age[1])]\n",
    "test_df['Age'] = temp.astype(np.int64)\n",
    "\n",
    "print('\\nCheck any missing value')\n",
    "test_df['Age'][pd.isnull(test_df['Age'])]\n",
    "\n",
    "test_df['Name'] = honor\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebee44d7",
   "metadata": {},
   "source": [
    "#### lets normalize the values for age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d0eeb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = preprocessing.StandardScaler(with_mean=True, with_std=True)\n",
    "labelencoder.fit(np.array(train_df['Age']).reshape(-1, 1))\n",
    "norm_age = labelencoder.transform(np.array(train_df['Age']).reshape(-1, 1)).flatten()\n",
    "train_df['Age'] = norm_age\n",
    "\n",
    "norm_age = labelencoder.transform(np.array(test_df['Age']).reshape(-1, 1)).flatten()\n",
    "test_df['Age'] = norm_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "076df27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.587386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.617127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.286258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.391281</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.391281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.210976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.813232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.587386</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.286258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.165435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Name     Sex       Age  SibSp  Parch     Fare  Embarked\n",
       "0           0       3     2    male -0.587386      1      0   7.2500         2\n",
       "1           1       1     3  female  0.617127      1      0  71.2833         0\n",
       "2           1       3     1  female -0.286258      0      0   7.9250         2\n",
       "3           1       1     3  female  0.391281      1      0  53.1000         2\n",
       "4           0       3     2    male  0.391281      0      0   8.0500         2\n",
       "..        ...     ...   ...     ...       ...    ...    ...      ...       ...\n",
       "886         0       2     2    male -0.210976      0      0  13.0000         2\n",
       "887         1       1     1  female -0.813232      0      0  30.0000         2\n",
       "888         0       3     1  female -0.587386      1      2  23.4500         2\n",
       "889         1       1     2    male -0.286258      0      0  30.0000         0\n",
       "890         0       3     2    male  0.165435      0      0   7.7500         1\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66c2f7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.315999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1.294666</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>2.423897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.210976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.587386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.165435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.692409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.617127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.165435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>-1.716617</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Name     Sex       Age  SibSp  Parch      Fare  Embarked\n",
       "0         3     2    male  0.315999      0      0    7.8292         1\n",
       "1         3     3  female  1.294666      1      0    7.0000         2\n",
       "2         2     2    male  2.423897      0      0    9.6875         1\n",
       "3         3     2    male -0.210976      0      0    8.6625         2\n",
       "4         3     3  female -0.587386      1      1   12.2875         2\n",
       "..      ...   ...     ...       ...    ...    ...       ...       ...\n",
       "413       3     2    male  0.165435      0      0    8.0500         2\n",
       "414       1     1  female  0.692409      0      0  108.9000         0\n",
       "415       3     2    male  0.617127      0      0    7.2500         2\n",
       "416       3     2    male  0.165435      0      0    8.0500         2\n",
       "417       3     0    male -1.716617      1      1   22.3583         0\n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd11f0",
   "metadata": {},
   "source": [
    "#### lets bin the Fare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c895f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "histo = plt.hist(train_df['Fare'],bins=[15,35,75,100])\n",
    "fare_count,fare_bins = histo[0],histo[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac10838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fare = np.copy(train_df['Fare'])\n",
    "\n",
    "groups = np.arange(len(fare_bins))\n",
    "for i,far in enumerate(fare):\n",
    "    if far <fare_bins[0]:\n",
    "        fare[i] = groups[0]\n",
    "    elif far <fare_bins[1]:\n",
    "        fare[i] = groups[1]\n",
    "    elif far <fare_bins[2]:\n",
    "        fare[i] = groups[2]\n",
    "    else:\n",
    "        fare[i] = groups[3]\n",
    "        \n",
    "train_df['Fare']=fare.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8422d01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.587386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.617127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.286258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.391281</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.391281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.210976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.813232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.587386</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.286258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.165435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Name     Sex       Age  SibSp  Parch  Fare  Embarked\n",
       "0           0       3     2    male -0.587386      1      0     0         2\n",
       "1           1       1     3  female  0.617127      1      0     2         0\n",
       "2           1       3     1  female -0.286258      0      0     0         2\n",
       "3           1       1     3  female  0.391281      1      0     2         2\n",
       "4           0       3     2    male  0.391281      0      0     0         2\n",
       "..        ...     ...   ...     ...       ...    ...    ...   ...       ...\n",
       "886         0       2     2    male -0.210976      0      0     0         2\n",
       "887         1       1     1  female -0.813232      0      0     1         2\n",
       "888         0       3     1  female -0.587386      1      2     1         2\n",
       "889         1       1     2    male -0.286258      0      0     1         0\n",
       "890         0       3     2    male  0.165435      0      0     0         1\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b0bb31",
   "metadata": {},
   "source": [
    "##### Bin fare for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a559eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fare = np.copy(test_df['Fare'])\n",
    "\n",
    "groups = np.arange(len(fare_bins))\n",
    "for i,far in enumerate(fare):\n",
    "    if far <fare_bins[0]:\n",
    "        fare[i] = groups[0]\n",
    "    elif far <fare_bins[1]:\n",
    "        fare[i] = groups[1]\n",
    "    elif far <fare_bins[2]:\n",
    "        fare[i] = groups[2]\n",
    "    else:\n",
    "        fare[i] = groups[3]\n",
    "\n",
    "        \n",
    "test_df['Fare']=fare.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e14fe3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.315999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1.294666</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>2.423897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.210976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.587386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.165435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.692409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.617127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0.165435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>-1.716617</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Name     Sex       Age  SibSp  Parch  Fare  Embarked\n",
       "0         3     2    male  0.315999      0      0     0         1\n",
       "1         3     3  female  1.294666      1      0     0         2\n",
       "2         2     2    male  2.423897      0      0     0         1\n",
       "3         3     2    male -0.210976      0      0     0         2\n",
       "4         3     3  female -0.587386      1      1     0         2\n",
       "..      ...   ...     ...       ...    ...    ...   ...       ...\n",
       "413       3     2    male  0.165435      0      0     0         2\n",
       "414       1     1  female  0.692409      0      0     3         0\n",
       "415       3     2    male  0.617127      0      0     0         2\n",
       "416       3     2    male  0.165435      0      0     0         2\n",
       "417       3     0    male -1.716617      1      1     1         0\n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed61be5f",
   "metadata": {},
   "source": [
    "#### Convert Sex into a numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85b6d755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.587386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.617127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.286258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.391281</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.210976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.813232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.587386</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.286258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.165435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Name  Sex       Age  SibSp  Parch  Fare  Embarked\n",
       "0           0       3     2    0 -0.587386      1      0     0         2\n",
       "1           1       1     3    1  0.617127      1      0     2         0\n",
       "2           1       3     1    1 -0.286258      0      0     0         2\n",
       "3           1       1     3    1  0.391281      1      0     2         2\n",
       "4           0       3     2    0  0.391281      0      0     0         2\n",
       "..        ...     ...   ...  ...       ...    ...    ...   ...       ...\n",
       "886         0       2     2    0 -0.210976      0      0     0         2\n",
       "887         1       1     1    1 -0.813232      0      0     1         2\n",
       "888         0       3     1    1 -0.587386      1      2     1         2\n",
       "889         1       1     2    0 -0.286258      0      0     1         0\n",
       "890         0       3     2    0  0.165435      0      0     0         1\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Sex']=(train_df['Sex']=='female').astype(int)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb7b374c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.294666</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.423897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.210976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.587386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.165435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.692409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.617127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.165435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.716617</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Name  Sex       Age  SibSp  Parch  Fare  Embarked\n",
       "0         3     2    0  0.315999      0      0     0         1\n",
       "1         3     3    1  1.294666      1      0     0         2\n",
       "2         2     2    0  2.423897      0      0     0         1\n",
       "3         3     2    0 -0.210976      0      0     0         2\n",
       "4         3     3    1 -0.587386      1      1     0         2\n",
       "..      ...   ...  ...       ...    ...    ...   ...       ...\n",
       "413       3     2    0  0.165435      0      0     0         2\n",
       "414       1     1    1  0.692409      0      0     3         0\n",
       "415       3     2    0  0.617127      0      0     0         2\n",
       "416       3     2    0  0.165435      0      0     0         2\n",
       "417       3     0    0 -1.716617      1      1     1         0\n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Sex']=(test_df['Sex']=='female').astype(int)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b1ca5",
   "metadata": {},
   "source": [
    "### Let's check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb30bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    int64  \n",
      " 3   Sex       891 non-null    int64  \n",
      " 4   Age       891 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Fare      891 non-null    int64  \n",
      " 8   Embarked  891 non-null    int64  \n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 62.8 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe29f51",
   "metadata": {},
   "source": [
    "### visualize correlation on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfc1aa1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.092853</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.329232</td>\n",
       "      <td>-0.167675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.117194</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.339511</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.697794</td>\n",
       "      <td>0.162098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>-0.073434</td>\n",
       "      <td>-0.117194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033058</td>\n",
       "      <td>0.501643</td>\n",
       "      <td>-0.222212</td>\n",
       "      <td>-0.103666</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>0.023065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.033058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.121678</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.237804</td>\n",
       "      <td>-0.108262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.092853</td>\n",
       "      <td>-0.339511</td>\n",
       "      <td>0.501643</td>\n",
       "      <td>-0.121678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.268392</td>\n",
       "      <td>-0.199150</td>\n",
       "      <td>0.109649</td>\n",
       "      <td>-0.022064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.222212</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>-0.268392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.310225</td>\n",
       "      <td>0.068230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.103666</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>-0.199150</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303941</td>\n",
       "      <td>0.039798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.329232</td>\n",
       "      <td>-0.697794</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>0.237804</td>\n",
       "      <td>0.109649</td>\n",
       "      <td>0.310225</td>\n",
       "      <td>0.303941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.217540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>-0.167675</td>\n",
       "      <td>0.162098</td>\n",
       "      <td>0.023065</td>\n",
       "      <td>-0.108262</td>\n",
       "      <td>-0.022064</td>\n",
       "      <td>0.068230</td>\n",
       "      <td>0.039798</td>\n",
       "      <td>-0.217540</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass      Name       Sex       Age     SibSp  \\\n",
       "Survived  1.000000 -0.338481 -0.073434  0.543351 -0.092853 -0.035322   \n",
       "Pclass   -0.338481  1.000000 -0.117194 -0.131900 -0.339511  0.083081   \n",
       "Name     -0.073434 -0.117194  1.000000 -0.033058  0.501643 -0.222212   \n",
       "Sex       0.543351 -0.131900 -0.033058  1.000000 -0.121678  0.114631   \n",
       "Age      -0.092853 -0.339511  0.501643 -0.121678  1.000000 -0.268392   \n",
       "SibSp    -0.035322  0.083081 -0.222212  0.114631 -0.268392  1.000000   \n",
       "Parch     0.081629  0.018443 -0.103666  0.245489 -0.199150  0.414838   \n",
       "Fare      0.329232 -0.697794  0.007587  0.237804  0.109649  0.310225   \n",
       "Embarked -0.167675  0.162098  0.023065 -0.108262 -0.022064  0.068230   \n",
       "\n",
       "             Parch      Fare  Embarked  \n",
       "Survived  0.081629  0.329232 -0.167675  \n",
       "Pclass    0.018443 -0.697794  0.162098  \n",
       "Name     -0.103666  0.007587  0.023065  \n",
       "Sex       0.245489  0.237804 -0.108262  \n",
       "Age      -0.199150  0.109649 -0.022064  \n",
       "SibSp     0.414838  0.310225  0.068230  \n",
       "Parch     1.000000  0.303941  0.039798  \n",
       "Fare      0.303941  1.000000 -0.217540  \n",
       "Embarked  0.039798 -0.217540  1.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's check if there are some correlation on the data\n",
    "corr=train_df.corr()\n",
    "plt.matshow(corr,vmin=-0.6,vmax=0.6,cmap = 'bwr')\n",
    "plt.colorbar()\n",
    "plt.title('correlation')\n",
    "corr#>0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34679060",
   "metadata": {},
   "source": [
    "    relevant fetures correlated *Survived*\n",
    "        Pclass, Sex, Fare, Embarked\n",
    "        \n",
    "    * Pclass is highly correlated with ticket fare.\n",
    "    \n",
    "    * Other correlations are shown but let's ignore them for now\n",
    "    \n",
    "    \n",
    "    Now let's contruct our data vector with the coloums\n",
    "        D_vec = [Pclass, Sex, fare, Embarked]\n",
    "    and the labels:\n",
    "        D_labels = [Survived]\n",
    "        \n",
    "    Final Notes:\n",
    "        How could I improve the correlation between surv and other parameters?\n",
    "        for example Age doesn't seem to be correlated with survavility, why?\n",
    "        Neither the title of the person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f2bd3",
   "metadata": {},
   "source": [
    "##  One hot econding\n",
    "\n",
    "For better performance let's one hot encoding the categorical inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "314b20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new data frame with One hot encoding\n",
    "train_OH = pd.DataFrame()\n",
    "train_OH['Survived'] = train_df['Survived']\n",
    "#train_OH['Age'] = train_df['Age']\n",
    "train_OH['Sex'] = train_df['Sex']\n",
    "\n",
    "group_vectorization = []\n",
    "df_keys = ['Pclass', 'Name','Fare', 'Embarked']\n",
    "for key in df_keys:\n",
    "    group_size = np.unique(train_df[key])\n",
    "    group_data = np.copy(train_df[key])\n",
    "    group_save = []\n",
    "    for group in group_size:\n",
    "        newlabel =key+'g'+str(group)\n",
    "        temp = np.zeros(len(train_OH['Survived']),dtype = int)\n",
    "        mask = group_data==group\n",
    "        temp[mask]=1\n",
    "        train_OH[newlabel] = temp\n",
    "        group_save.append(group)\n",
    "    group_vectorization.append(group_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56b15a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclassg1</th>\n",
       "      <th>Pclassg2</th>\n",
       "      <th>Pclassg3</th>\n",
       "      <th>Nameg0</th>\n",
       "      <th>Nameg1</th>\n",
       "      <th>Nameg2</th>\n",
       "      <th>Nameg3</th>\n",
       "      <th>Fareg0</th>\n",
       "      <th>Fareg1</th>\n",
       "      <th>Fareg2</th>\n",
       "      <th>Fareg3</th>\n",
       "      <th>Embarkedg0</th>\n",
       "      <th>Embarkedg1</th>\n",
       "      <th>Embarkedg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Sex  Pclassg1  Pclassg2  Pclassg3  Nameg0  Nameg1  Nameg2  \\\n",
       "0           0    0         0         0         1       0       0       1   \n",
       "1           1    1         1         0         0       0       0       0   \n",
       "2           1    1         0         0         1       0       1       0   \n",
       "3           1    1         1         0         0       0       0       0   \n",
       "4           0    0         0         0         1       0       0       1   \n",
       "..        ...  ...       ...       ...       ...     ...     ...     ...   \n",
       "886         0    0         0         1         0       0       0       1   \n",
       "887         1    1         1         0         0       0       1       0   \n",
       "888         0    1         0         0         1       0       1       0   \n",
       "889         1    0         1         0         0       0       0       1   \n",
       "890         0    0         0         0         1       0       0       1   \n",
       "\n",
       "     Nameg3  Fareg0  Fareg1  Fareg2  Fareg3  Embarkedg0  Embarkedg1  \\\n",
       "0         0       1       0       0       0           0           0   \n",
       "1         1       0       0       1       0           1           0   \n",
       "2         0       1       0       0       0           0           0   \n",
       "3         1       0       0       1       0           0           0   \n",
       "4         0       1       0       0       0           0           0   \n",
       "..      ...     ...     ...     ...     ...         ...         ...   \n",
       "886       0       1       0       0       0           0           0   \n",
       "887       0       0       1       0       0           0           0   \n",
       "888       0       0       1       0       0           0           0   \n",
       "889       0       0       1       0       0           1           0   \n",
       "890       0       1       0       0       0           0           1   \n",
       "\n",
       "     Embarkedg2  \n",
       "0             1  \n",
       "1             0  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "..          ...  \n",
       "886           1  \n",
       "887           1  \n",
       "888           1  \n",
       "889           0  \n",
       "890           0  \n",
       "\n",
       "[891 rows x 16 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_OH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2da50c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclassg1</th>\n",
       "      <th>Pclassg2</th>\n",
       "      <th>Pclassg3</th>\n",
       "      <th>Nameg0</th>\n",
       "      <th>Nameg1</th>\n",
       "      <th>Nameg2</th>\n",
       "      <th>Nameg3</th>\n",
       "      <th>Fareg0</th>\n",
       "      <th>Fareg1</th>\n",
       "      <th>Fareg2</th>\n",
       "      <th>Fareg3</th>\n",
       "      <th>Embarkedg0</th>\n",
       "      <th>Embarkedg1</th>\n",
       "      <th>Embarkedg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>0.285904</td>\n",
       "      <td>0.093349</td>\n",
       "      <td>-0.322308</td>\n",
       "      <td>0.085221</td>\n",
       "      <td>0.338468</td>\n",
       "      <td>-0.563879</td>\n",
       "      <td>0.344935</td>\n",
       "      <td>-0.283559</td>\n",
       "      <td>0.077499</td>\n",
       "      <td>0.071385</td>\n",
       "      <td>0.272426</td>\n",
       "      <td>0.168240</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>-0.149683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098013</td>\n",
       "      <td>0.064746</td>\n",
       "      <td>-0.137143</td>\n",
       "      <td>-0.159934</td>\n",
       "      <td>0.696282</td>\n",
       "      <td>-0.905908</td>\n",
       "      <td>0.552686</td>\n",
       "      <td>-0.221160</td>\n",
       "      <td>0.102271</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.209808</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.119224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclassg1</th>\n",
       "      <td>0.285904</td>\n",
       "      <td>0.098013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.288585</td>\n",
       "      <td>-0.626738</td>\n",
       "      <td>-0.084700</td>\n",
       "      <td>0.025190</td>\n",
       "      <td>-0.055817</td>\n",
       "      <td>0.098974</td>\n",
       "      <td>-0.549044</td>\n",
       "      <td>-0.011706</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.617875</td>\n",
       "      <td>0.296423</td>\n",
       "      <td>-0.155342</td>\n",
       "      <td>-0.161921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclassg2</th>\n",
       "      <td>0.093349</td>\n",
       "      <td>0.064746</td>\n",
       "      <td>-0.288585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.565210</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>-0.023268</td>\n",
       "      <td>-0.068603</td>\n",
       "      <td>0.117162</td>\n",
       "      <td>-0.002079</td>\n",
       "      <td>0.147670</td>\n",
       "      <td>-0.026681</td>\n",
       "      <td>-0.178310</td>\n",
       "      <td>-0.125416</td>\n",
       "      <td>-0.127301</td>\n",
       "      <td>0.189980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclassg3</th>\n",
       "      <td>-0.322308</td>\n",
       "      <td>-0.137143</td>\n",
       "      <td>-0.626738</td>\n",
       "      <td>-0.565210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064918</td>\n",
       "      <td>-0.002767</td>\n",
       "      <td>0.103925</td>\n",
       "      <td>-0.180630</td>\n",
       "      <td>0.474751</td>\n",
       "      <td>-0.110096</td>\n",
       "      <td>-0.214092</td>\n",
       "      <td>-0.387245</td>\n",
       "      <td>-0.153329</td>\n",
       "      <td>0.237449</td>\n",
       "      <td>-0.015104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nameg0</th>\n",
       "      <td>0.085221</td>\n",
       "      <td>-0.159934</td>\n",
       "      <td>-0.084700</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>0.064918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.111359</td>\n",
       "      <td>-0.267651</td>\n",
       "      <td>-0.088394</td>\n",
       "      <td>-0.168255</td>\n",
       "      <td>0.140833</td>\n",
       "      <td>0.092281</td>\n",
       "      <td>-0.023573</td>\n",
       "      <td>-0.035225</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.024264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nameg1</th>\n",
       "      <td>0.338468</td>\n",
       "      <td>0.696282</td>\n",
       "      <td>0.025190</td>\n",
       "      <td>-0.023268</td>\n",
       "      <td>-0.002767</td>\n",
       "      <td>-0.111359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.634112</td>\n",
       "      <td>-0.209419</td>\n",
       "      <td>-0.035363</td>\n",
       "      <td>-0.019159</td>\n",
       "      <td>-0.045908</td>\n",
       "      <td>0.130782</td>\n",
       "      <td>0.041861</td>\n",
       "      <td>0.166350</td>\n",
       "      <td>-0.141356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nameg2</th>\n",
       "      <td>-0.563879</td>\n",
       "      <td>-0.905908</td>\n",
       "      <td>-0.055817</td>\n",
       "      <td>-0.068603</td>\n",
       "      <td>0.103925</td>\n",
       "      <td>-0.267651</td>\n",
       "      <td>-0.634112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.503337</td>\n",
       "      <td>0.284892</td>\n",
       "      <td>-0.155682</td>\n",
       "      <td>-0.040282</td>\n",
       "      <td>-0.195748</td>\n",
       "      <td>-0.067119</td>\n",
       "      <td>-0.077532</td>\n",
       "      <td>0.107590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nameg3</th>\n",
       "      <td>0.344935</td>\n",
       "      <td>0.552686</td>\n",
       "      <td>0.098974</td>\n",
       "      <td>0.117162</td>\n",
       "      <td>-0.180630</td>\n",
       "      <td>-0.088394</td>\n",
       "      <td>-0.209419</td>\n",
       "      <td>-0.503337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.257807</td>\n",
       "      <td>0.156661</td>\n",
       "      <td>0.055066</td>\n",
       "      <td>0.135784</td>\n",
       "      <td>0.066101</td>\n",
       "      <td>-0.091121</td>\n",
       "      <td>-0.000565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fareg0</th>\n",
       "      <td>-0.283559</td>\n",
       "      <td>-0.221160</td>\n",
       "      <td>-0.549044</td>\n",
       "      <td>-0.002079</td>\n",
       "      <td>0.474751</td>\n",
       "      <td>-0.168255</td>\n",
       "      <td>-0.035363</td>\n",
       "      <td>0.284892</td>\n",
       "      <td>-0.257807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.614179</td>\n",
       "      <td>-0.368956</td>\n",
       "      <td>-0.358665</td>\n",
       "      <td>-0.178922</td>\n",
       "      <td>0.139897</td>\n",
       "      <td>0.068706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fareg1</th>\n",
       "      <td>0.077499</td>\n",
       "      <td>0.102271</td>\n",
       "      <td>-0.011706</td>\n",
       "      <td>0.147670</td>\n",
       "      <td>-0.110096</td>\n",
       "      <td>0.140833</td>\n",
       "      <td>-0.019159</td>\n",
       "      <td>-0.155682</td>\n",
       "      <td>0.156661</td>\n",
       "      <td>-0.614179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.215201</td>\n",
       "      <td>-0.209198</td>\n",
       "      <td>-0.028062</td>\n",
       "      <td>-0.020926</td>\n",
       "      <td>0.037753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fareg2</th>\n",
       "      <td>0.071385</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>-0.026681</td>\n",
       "      <td>-0.214092</td>\n",
       "      <td>0.092281</td>\n",
       "      <td>-0.045908</td>\n",
       "      <td>-0.040282</td>\n",
       "      <td>0.055066</td>\n",
       "      <td>-0.368956</td>\n",
       "      <td>-0.215201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.125672</td>\n",
       "      <td>0.042966</td>\n",
       "      <td>-0.110585</td>\n",
       "      <td>0.031951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fareg3</th>\n",
       "      <td>0.272426</td>\n",
       "      <td>0.209808</td>\n",
       "      <td>0.617875</td>\n",
       "      <td>-0.178310</td>\n",
       "      <td>-0.387245</td>\n",
       "      <td>-0.023573</td>\n",
       "      <td>0.130782</td>\n",
       "      <td>-0.195748</td>\n",
       "      <td>0.135784</td>\n",
       "      <td>-0.358665</td>\n",
       "      <td>-0.209198</td>\n",
       "      <td>-0.125672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.282907</td>\n",
       "      <td>-0.081852</td>\n",
       "      <td>-0.196329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarkedg0</th>\n",
       "      <td>0.168240</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.296423</td>\n",
       "      <td>-0.125416</td>\n",
       "      <td>-0.153329</td>\n",
       "      <td>-0.035225</td>\n",
       "      <td>0.041861</td>\n",
       "      <td>-0.067119</td>\n",
       "      <td>0.066101</td>\n",
       "      <td>-0.178922</td>\n",
       "      <td>-0.028062</td>\n",
       "      <td>0.042966</td>\n",
       "      <td>0.282907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>-0.782742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarkedg1</th>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>-0.155342</td>\n",
       "      <td>-0.127301</td>\n",
       "      <td>0.237449</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.166350</td>\n",
       "      <td>-0.077532</td>\n",
       "      <td>-0.091121</td>\n",
       "      <td>0.139897</td>\n",
       "      <td>-0.020926</td>\n",
       "      <td>-0.110585</td>\n",
       "      <td>-0.081852</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.499421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarkedg2</th>\n",
       "      <td>-0.149683</td>\n",
       "      <td>-0.119224</td>\n",
       "      <td>-0.161921</td>\n",
       "      <td>0.189980</td>\n",
       "      <td>-0.015104</td>\n",
       "      <td>0.024264</td>\n",
       "      <td>-0.141356</td>\n",
       "      <td>0.107590</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>0.068706</td>\n",
       "      <td>0.037753</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>-0.196329</td>\n",
       "      <td>-0.782742</td>\n",
       "      <td>-0.499421</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Survived       Sex  Pclassg1  Pclassg2  Pclassg3    Nameg0  \\\n",
       "Survived    1.000000  0.543351  0.285904  0.093349 -0.322308  0.085221   \n",
       "Sex         0.543351  1.000000  0.098013  0.064746 -0.137143 -0.159934   \n",
       "Pclassg1    0.285904  0.098013  1.000000 -0.288585 -0.626738 -0.084700   \n",
       "Pclassg2    0.093349  0.064746 -0.288585  1.000000 -0.565210  0.009903   \n",
       "Pclassg3   -0.322308 -0.137143 -0.626738 -0.565210  1.000000  0.064918   \n",
       "Nameg0      0.085221 -0.159934 -0.084700  0.009903  0.064918  1.000000   \n",
       "Nameg1      0.338468  0.696282  0.025190 -0.023268 -0.002767 -0.111359   \n",
       "Nameg2     -0.563879 -0.905908 -0.055817 -0.068603  0.103925 -0.267651   \n",
       "Nameg3      0.344935  0.552686  0.098974  0.117162 -0.180630 -0.088394   \n",
       "Fareg0     -0.283559 -0.221160 -0.549044 -0.002079  0.474751 -0.168255   \n",
       "Fareg1      0.077499  0.102271 -0.011706  0.147670 -0.110096  0.140833   \n",
       "Fareg2      0.071385  0.000398  0.273684 -0.026681 -0.214092  0.092281   \n",
       "Fareg3      0.272426  0.209808  0.617875 -0.178310 -0.387245 -0.023573   \n",
       "Embarkedg0  0.168240  0.082853  0.296423 -0.125416 -0.153329 -0.035225   \n",
       "Embarkedg1  0.003650  0.074115 -0.155342 -0.127301  0.237449  0.010478   \n",
       "Embarkedg2 -0.149683 -0.119224 -0.161921  0.189980 -0.015104  0.024264   \n",
       "\n",
       "              Nameg1    Nameg2    Nameg3    Fareg0    Fareg1    Fareg2  \\\n",
       "Survived    0.338468 -0.563879  0.344935 -0.283559  0.077499  0.071385   \n",
       "Sex         0.696282 -0.905908  0.552686 -0.221160  0.102271  0.000398   \n",
       "Pclassg1    0.025190 -0.055817  0.098974 -0.549044 -0.011706  0.273684   \n",
       "Pclassg2   -0.023268 -0.068603  0.117162 -0.002079  0.147670 -0.026681   \n",
       "Pclassg3   -0.002767  0.103925 -0.180630  0.474751 -0.110096 -0.214092   \n",
       "Nameg0     -0.111359 -0.267651 -0.088394 -0.168255  0.140833  0.092281   \n",
       "Nameg1      1.000000 -0.634112 -0.209419 -0.035363 -0.019159 -0.045908   \n",
       "Nameg2     -0.634112  1.000000 -0.503337  0.284892 -0.155682 -0.040282   \n",
       "Nameg3     -0.209419 -0.503337  1.000000 -0.257807  0.156661  0.055066   \n",
       "Fareg0     -0.035363  0.284892 -0.257807  1.000000 -0.614179 -0.368956   \n",
       "Fareg1     -0.019159 -0.155682  0.156661 -0.614179  1.000000 -0.215201   \n",
       "Fareg2     -0.045908 -0.040282  0.055066 -0.368956 -0.215201  1.000000   \n",
       "Fareg3      0.130782 -0.195748  0.135784 -0.358665 -0.209198 -0.125672   \n",
       "Embarkedg0  0.041861 -0.067119  0.066101 -0.178922 -0.028062  0.042966   \n",
       "Embarkedg1  0.166350 -0.077532 -0.091121  0.139897 -0.020926 -0.110585   \n",
       "Embarkedg2 -0.141356  0.107590 -0.000565  0.068706  0.037753  0.031951   \n",
       "\n",
       "              Fareg3  Embarkedg0  Embarkedg1  Embarkedg2  \n",
       "Survived    0.272426    0.168240    0.003650   -0.149683  \n",
       "Sex         0.209808    0.082853    0.074115   -0.119224  \n",
       "Pclassg1    0.617875    0.296423   -0.155342   -0.161921  \n",
       "Pclassg2   -0.178310   -0.125416   -0.127301    0.189980  \n",
       "Pclassg3   -0.387245   -0.153329    0.237449   -0.015104  \n",
       "Nameg0     -0.023573   -0.035225    0.010478    0.024264  \n",
       "Nameg1      0.130782    0.041861    0.166350   -0.141356  \n",
       "Nameg2     -0.195748   -0.067119   -0.077532    0.107590  \n",
       "Nameg3      0.135784    0.066101   -0.091121   -0.000565  \n",
       "Fareg0     -0.358665   -0.178922    0.139897    0.068706  \n",
       "Fareg1     -0.209198   -0.028062   -0.020926    0.037753  \n",
       "Fareg2     -0.125672    0.042966   -0.110585    0.031951  \n",
       "Fareg3      1.000000    0.282907   -0.081852   -0.196329  \n",
       "Embarkedg0  0.282907    1.000000   -0.148258   -0.782742  \n",
       "Embarkedg1 -0.081852   -0.148258    1.000000   -0.499421  \n",
       "Embarkedg2 -0.196329   -0.782742   -0.499421    1.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_OH.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e140188",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_OH = pd.DataFrame()\n",
    "#test_OH['Age'] = test_df['Age']\n",
    "test_OH['Sex'] = test_df['Sex']\n",
    "\n",
    "df_keys = ['Pclass', 'Name', 'Fare','Embarked']\n",
    "\n",
    "for i,key in enumerate(df_keys):\n",
    "    group_size = group_vectorization[i]\n",
    "    group_data = np.copy(test_df[key])\n",
    "    for group in group_size:\n",
    "        newlabel =key+'g'+str(group)\n",
    "        temp = np.zeros(len(test_df['Pclass']),dtype = int)\n",
    "        mask = group_data==group\n",
    "        temp[mask]=1\n",
    "        test_OH[newlabel] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96866a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclassg1</th>\n",
       "      <th>Pclassg2</th>\n",
       "      <th>Pclassg3</th>\n",
       "      <th>Nameg0</th>\n",
       "      <th>Nameg1</th>\n",
       "      <th>Nameg2</th>\n",
       "      <th>Nameg3</th>\n",
       "      <th>Fareg0</th>\n",
       "      <th>Fareg1</th>\n",
       "      <th>Fareg2</th>\n",
       "      <th>Fareg3</th>\n",
       "      <th>Embarkedg0</th>\n",
       "      <th>Embarkedg1</th>\n",
       "      <th>Embarkedg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex  Pclassg1  Pclassg2  Pclassg3  Nameg0  Nameg1  Nameg2  Nameg3  \\\n",
       "0      0         0         0         1       0       0       1       0   \n",
       "1      1         0         0         1       0       0       0       1   \n",
       "2      0         0         1         0       0       0       1       0   \n",
       "3      0         0         0         1       0       0       1       0   \n",
       "4      1         0         0         1       0       0       0       1   \n",
       "..   ...       ...       ...       ...     ...     ...     ...     ...   \n",
       "413    0         0         0         1       0       0       1       0   \n",
       "414    1         1         0         0       0       1       0       0   \n",
       "415    0         0         0         1       0       0       1       0   \n",
       "416    0         0         0         1       0       0       1       0   \n",
       "417    0         0         0         1       1       0       0       0   \n",
       "\n",
       "     Fareg0  Fareg1  Fareg2  Fareg3  Embarkedg0  Embarkedg1  Embarkedg2  \n",
       "0         1       0       0       0           0           1           0  \n",
       "1         1       0       0       0           0           0           1  \n",
       "2         1       0       0       0           0           1           0  \n",
       "3         1       0       0       0           0           0           1  \n",
       "4         1       0       0       0           0           0           1  \n",
       "..      ...     ...     ...     ...         ...         ...         ...  \n",
       "413       1       0       0       0           0           0           1  \n",
       "414       0       0       0       1           1           0           0  \n",
       "415       1       0       0       0           0           0           1  \n",
       "416       1       0       0       0           0           0           1  \n",
       "417       0       1       0       0           1           0           0  \n",
       "\n",
       "[418 rows x 15 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_OH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "662909cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_OH=train_OH.drop(['Pclassg2','Nameg0','Fareg1','Fareg2','Embarkedg1'],axis=1)\n",
    "#test_OH = test_OH.drop(['Pclassg2','Nameg0','Fareg1','Fareg2','Embarkedg1'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e57aaa0",
   "metadata": {},
   "source": [
    "#### Prepare data vectors for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a36a2208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 16)\n",
      "(418, 15)\n"
     ]
    }
   ],
   "source": [
    "Dtrain_vec = train_OH.values\n",
    "#Dtrain_vec = np.array(Dtrain_vec).T\n",
    "print(np.shape(Dtrain_vec))\n",
    "\n",
    "Dtest_vec = test_OH.values#[test_df['Pclass'], test_df['Sex'], test_df['Age'],test_df['Fare'], test_df['Embarked']]\n",
    "#Dtest_vec = np.array(Dtest_vec).T\n",
    "print(np.shape(Dtest_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55143a9",
   "metadata": {},
   "source": [
    "#### Final vector correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0cd20205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f662aa765e0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr=np.corrcoef(Dtrain_vec.T)\n",
    "\n",
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.matshow(corr,vmin=-0.7,vmax=.7,cmap = 'bwr')\n",
    "#for (i, j), z in np.ndenumerate(corr):\n",
    "#    ax.text(j, i, '{:0.1f}'.format(z), ha='center', va='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d331c1",
   "metadata": {},
   "source": [
    "# Sequential model\n",
    "\n",
    "    Since we want to predict if given a passenger is either dead or alive\n",
    "    let us model it as \"A binary classification\" problem.\n",
    "    \n",
    "        1. The first try is going to be a Sequential model\n",
    "        2. Lets try to implement a K-fold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0174a1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 22:04:57.596097: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-18 22:04:58.697190: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 22:04:59.811529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-18 22:05:00.001120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-18 22:05:00.001208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f86532d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 22:05:00.021137: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-18 22:05:00.021256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-18 22:05:00.021296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-18 22:05:01.680978: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-18 22:05:01.681107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-18 22:05:01.681117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-07-18 22:05:01.681160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-18 22:05:01.681274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"titanic_Smodel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 16)                256       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 545\n",
      "Trainable params: 545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 22:05:05.089779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-07-18 22:05:05.100167: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f64ac014150 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-18 22:05:05.100209: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-07-18 22:05:05.105828: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-18 22:05:05.538370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-07-18 22:05:05.663180: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-18 22:05:05.752998: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 4s 96ms/step - loss: 0.6900 - accuracy: 0.5037 - val_loss: 0.6697 - val_accuracy: 0.6218\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6683 - accuracy: 0.6124 - val_loss: 0.6401 - val_accuracy: 0.6218\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6385 - accuracy: 0.6236 - val_loss: 0.6020 - val_accuracy: 0.6891\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5993 - accuracy: 0.6873 - val_loss: 0.5562 - val_accuracy: 0.7647\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5549 - accuracy: 0.7416 - val_loss: 0.5125 - val_accuracy: 0.7815\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5199 - accuracy: 0.7790 - val_loss: 0.4794 - val_accuracy: 0.7703\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4952 - accuracy: 0.8015 - val_loss: 0.4589 - val_accuracy: 0.7731\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4758 - accuracy: 0.8109 - val_loss: 0.4554 - val_accuracy: 0.7787\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4605 - accuracy: 0.7996 - val_loss: 0.4640 - val_accuracy: 0.7815\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4755 - accuracy: 0.8071 - val_loss: 0.4708 - val_accuracy: 0.7787\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4671 - accuracy: 0.8071 - val_loss: 0.4727 - val_accuracy: 0.7759\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4606 - accuracy: 0.8090 - val_loss: 0.4689 - val_accuracy: 0.7787\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4595 - accuracy: 0.8090 - val_loss: 0.4628 - val_accuracy: 0.7787\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4534 - accuracy: 0.8165 - val_loss: 0.4585 - val_accuracy: 0.7787\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4535 - accuracy: 0.8221 - val_loss: 0.4559 - val_accuracy: 0.7787\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4559 - accuracy: 0.8221 - val_loss: 0.4531 - val_accuracy: 0.7787\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4529 - accuracy: 0.8184 - val_loss: 0.4484 - val_accuracy: 0.7787\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4440 - accuracy: 0.8240 - val_loss: 0.4449 - val_accuracy: 0.7787\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4514 - accuracy: 0.8071 - val_loss: 0.4427 - val_accuracy: 0.7787\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4519 - accuracy: 0.8052 - val_loss: 0.4415 - val_accuracy: 0.7843\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4517 - accuracy: 0.8296 - val_loss: 0.4392 - val_accuracy: 0.8039\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4516 - accuracy: 0.8258 - val_loss: 0.4368 - val_accuracy: 0.7871\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4489 - accuracy: 0.8202 - val_loss: 0.4362 - val_accuracy: 0.7843\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4581 - accuracy: 0.8090 - val_loss: 0.4371 - val_accuracy: 0.7815\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4483 - accuracy: 0.8202 - val_loss: 0.4392 - val_accuracy: 0.7815\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4506 - accuracy: 0.8165 - val_loss: 0.4410 - val_accuracy: 0.7815\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4425 - accuracy: 0.8184 - val_loss: 0.4429 - val_accuracy: 0.7871\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4364 - accuracy: 0.8146 - val_loss: 0.4448 - val_accuracy: 0.7815\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4462 - accuracy: 0.8090 - val_loss: 0.4457 - val_accuracy: 0.7871\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4367 - accuracy: 0.8165 - val_loss: 0.4456 - val_accuracy: 0.7843\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4409 - accuracy: 0.8240 - val_loss: 0.4436 - val_accuracy: 0.7843\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4445 - accuracy: 0.8202 - val_loss: 0.4398 - val_accuracy: 0.7955\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4406 - accuracy: 0.8165 - val_loss: 0.4376 - val_accuracy: 0.8011\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4510 - accuracy: 0.8127 - val_loss: 0.4364 - val_accuracy: 0.8011\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4466 - accuracy: 0.8277 - val_loss: 0.4332 - val_accuracy: 0.8039\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4424 - accuracy: 0.8146 - val_loss: 0.4294 - val_accuracy: 0.7871\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4387 - accuracy: 0.8090 - val_loss: 0.4304 - val_accuracy: 0.7787\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4382 - accuracy: 0.8052 - val_loss: 0.4328 - val_accuracy: 0.7787\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4500 - accuracy: 0.7959 - val_loss: 0.4320 - val_accuracy: 0.7787\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4489 - accuracy: 0.8127 - val_loss: 0.4303 - val_accuracy: 0.7787\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4477 - accuracy: 0.8127 - val_loss: 0.4309 - val_accuracy: 0.7871\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4365 - accuracy: 0.8202 - val_loss: 0.4343 - val_accuracy: 0.7927\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4522 - accuracy: 0.8090 - val_loss: 0.4389 - val_accuracy: 0.7815\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4318 - accuracy: 0.8240 - val_loss: 0.4425 - val_accuracy: 0.7843\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4376 - accuracy: 0.8258 - val_loss: 0.4461 - val_accuracy: 0.7843\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4466 - accuracy: 0.8184 - val_loss: 0.4489 - val_accuracy: 0.7815\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4361 - accuracy: 0.8258 - val_loss: 0.4490 - val_accuracy: 0.7815\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4468 - accuracy: 0.8146 - val_loss: 0.4452 - val_accuracy: 0.7843\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4419 - accuracy: 0.8146 - val_loss: 0.4406 - val_accuracy: 0.7843\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4511 - accuracy: 0.8165 - val_loss: 0.4363 - val_accuracy: 0.7787\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4402 - accuracy: 0.8165 - val_loss: 0.4344 - val_accuracy: 0.7843\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4429 - accuracy: 0.8052 - val_loss: 0.4312 - val_accuracy: 0.7843\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4416 - accuracy: 0.8071 - val_loss: 0.4304 - val_accuracy: 0.8067\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4323 - accuracy: 0.8258 - val_loss: 0.4297 - val_accuracy: 0.8067\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4447 - accuracy: 0.8146 - val_loss: 0.4283 - val_accuracy: 0.8095\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4500 - accuracy: 0.8221 - val_loss: 0.4268 - val_accuracy: 0.7871\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4321 - accuracy: 0.8315 - val_loss: 0.4250 - val_accuracy: 0.7871\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4321 - accuracy: 0.8109 - val_loss: 0.4237 - val_accuracy: 0.8039\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4415 - accuracy: 0.8202 - val_loss: 0.4233 - val_accuracy: 0.8095\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4446 - accuracy: 0.8258 - val_loss: 0.4240 - val_accuracy: 0.8067\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4421 - accuracy: 0.8146 - val_loss: 0.4243 - val_accuracy: 0.8095\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4393 - accuracy: 0.8202 - val_loss: 0.4248 - val_accuracy: 0.8067\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4447 - accuracy: 0.8202 - val_loss: 0.4248 - val_accuracy: 0.8067\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4401 - accuracy: 0.8277 - val_loss: 0.4241 - val_accuracy: 0.8123\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4362 - accuracy: 0.8184 - val_loss: 0.4241 - val_accuracy: 0.8123\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4338 - accuracy: 0.8202 - val_loss: 0.4254 - val_accuracy: 0.7955\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4344 - accuracy: 0.8240 - val_loss: 0.4270 - val_accuracy: 0.8123\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4326 - accuracy: 0.8221 - val_loss: 0.4286 - val_accuracy: 0.8095\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4292 - accuracy: 0.8333 - val_loss: 0.4320 - val_accuracy: 0.7927\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4453 - accuracy: 0.8315 - val_loss: 0.4324 - val_accuracy: 0.7927\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4341 - accuracy: 0.8296 - val_loss: 0.4321 - val_accuracy: 0.7927\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4339 - accuracy: 0.8277 - val_loss: 0.4326 - val_accuracy: 0.8039\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4371 - accuracy: 0.8258 - val_loss: 0.4340 - val_accuracy: 0.8011\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4359 - accuracy: 0.8315 - val_loss: 0.4340 - val_accuracy: 0.8067\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4261 - accuracy: 0.8165 - val_loss: 0.4334 - val_accuracy: 0.8123\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4410 - accuracy: 0.8146 - val_loss: 0.4331 - val_accuracy: 0.7927\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4388 - accuracy: 0.8221 - val_loss: 0.4324 - val_accuracy: 0.8067\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.4302 - accuracy: 0.8240 - val_loss: 0.4318 - val_accuracy: 0.8067\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4250 - accuracy: 0.8240 - val_loss: 0.4328 - val_accuracy: 0.8011\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4309 - accuracy: 0.8296 - val_loss: 0.4330 - val_accuracy: 0.8067\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.4252 - accuracy: 0.8221 - val_loss: 0.4314 - val_accuracy: 0.8067\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.4368 - accuracy: 0.8221 - val_loss: 0.4309 - val_accuracy: 0.8067\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4300 - accuracy: 0.8258 - val_loss: 0.4320 - val_accuracy: 0.7843\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4238 - accuracy: 0.8165 - val_loss: 0.4338 - val_accuracy: 0.7899\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.4383 - accuracy: 0.8184 - val_loss: 0.4336 - val_accuracy: 0.7899\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4360 - accuracy: 0.8146 - val_loss: 0.4289 - val_accuracy: 0.7871\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4293 - accuracy: 0.8221 - val_loss: 0.4247 - val_accuracy: 0.8067\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4228 - accuracy: 0.8202 - val_loss: 0.4231 - val_accuracy: 0.8067\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4416 - accuracy: 0.8202 - val_loss: 0.4234 - val_accuracy: 0.8095\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4458 - accuracy: 0.8296 - val_loss: 0.4220 - val_accuracy: 0.8095\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4422 - accuracy: 0.8296 - val_loss: 0.4218 - val_accuracy: 0.8039\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4304 - accuracy: 0.8296 - val_loss: 0.4241 - val_accuracy: 0.8039\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4284 - accuracy: 0.8296 - val_loss: 0.4251 - val_accuracy: 0.8039\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4245 - accuracy: 0.8371 - val_loss: 0.4256 - val_accuracy: 0.7927\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4211 - accuracy: 0.8352 - val_loss: 0.4257 - val_accuracy: 0.8067\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4316 - accuracy: 0.8296 - val_loss: 0.4277 - val_accuracy: 0.8067\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4323 - accuracy: 0.8240 - val_loss: 0.4294 - val_accuracy: 0.8067\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4285 - accuracy: 0.8258 - val_loss: 0.4309 - val_accuracy: 0.7927\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4308 - accuracy: 0.8184 - val_loss: 0.4329 - val_accuracy: 0.7871\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4306 - accuracy: 0.8071 - val_loss: 0.4342 - val_accuracy: 0.7843\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4275 - accuracy: 0.8202 - val_loss: 0.4337 - val_accuracy: 0.7899\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4298 - accuracy: 0.8165 - val_loss: 0.4310 - val_accuracy: 0.8067\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4227 - accuracy: 0.8221 - val_loss: 0.4304 - val_accuracy: 0.7983\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4268 - accuracy: 0.8296 - val_loss: 0.4327 - val_accuracy: 0.8039\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4430 - accuracy: 0.8221 - val_loss: 0.4351 - val_accuracy: 0.8039\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4285 - accuracy: 0.8352 - val_loss: 0.4347 - val_accuracy: 0.8039\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4311 - accuracy: 0.8146 - val_loss: 0.4333 - val_accuracy: 0.8039\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4265 - accuracy: 0.8221 - val_loss: 0.4318 - val_accuracy: 0.8067\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4362 - accuracy: 0.8146 - val_loss: 0.4330 - val_accuracy: 0.8067\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4300 - accuracy: 0.8109 - val_loss: 0.4339 - val_accuracy: 0.8067\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4261 - accuracy: 0.8333 - val_loss: 0.4306 - val_accuracy: 0.8067\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4278 - accuracy: 0.8165 - val_loss: 0.4285 - val_accuracy: 0.8067\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4243 - accuracy: 0.8258 - val_loss: 0.4292 - val_accuracy: 0.7983\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4267 - accuracy: 0.8315 - val_loss: 0.4289 - val_accuracy: 0.7983\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4163 - accuracy: 0.8277 - val_loss: 0.4286 - val_accuracy: 0.7983\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4205 - accuracy: 0.8371 - val_loss: 0.4285 - val_accuracy: 0.7983\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4251 - accuracy: 0.8333 - val_loss: 0.4279 - val_accuracy: 0.8067\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4294 - accuracy: 0.8277 - val_loss: 0.4278 - val_accuracy: 0.8067\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4435 - accuracy: 0.8165 - val_loss: 0.4281 - val_accuracy: 0.8067\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4354 - accuracy: 0.8240 - val_loss: 0.4290 - val_accuracy: 0.8067\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4283 - accuracy: 0.8184 - val_loss: 0.4301 - val_accuracy: 0.8067\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4269 - accuracy: 0.8184 - val_loss: 0.4309 - val_accuracy: 0.8067\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4267 - accuracy: 0.8333 - val_loss: 0.4324 - val_accuracy: 0.8067\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4187 - accuracy: 0.8333 - val_loss: 0.4341 - val_accuracy: 0.8067\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4226 - accuracy: 0.8277 - val_loss: 0.4347 - val_accuracy: 0.8095\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4280 - accuracy: 0.8221 - val_loss: 0.4346 - val_accuracy: 0.8095\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4323 - accuracy: 0.8034 - val_loss: 0.4335 - val_accuracy: 0.8011\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4242 - accuracy: 0.8258 - val_loss: 0.4324 - val_accuracy: 0.8011\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4280 - accuracy: 0.8296 - val_loss: 0.4308 - val_accuracy: 0.8011\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4276 - accuracy: 0.8221 - val_loss: 0.4295 - val_accuracy: 0.8011\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4322 - accuracy: 0.8277 - val_loss: 0.4281 - val_accuracy: 0.8011\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4230 - accuracy: 0.8202 - val_loss: 0.4268 - val_accuracy: 0.8011\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4243 - accuracy: 0.8221 - val_loss: 0.4260 - val_accuracy: 0.8011\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4287 - accuracy: 0.8184 - val_loss: 0.4256 - val_accuracy: 0.8011\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4321 - accuracy: 0.8296 - val_loss: 0.4252 - val_accuracy: 0.8095\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4249 - accuracy: 0.8258 - val_loss: 0.4246 - val_accuracy: 0.8095\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4307 - accuracy: 0.8296 - val_loss: 0.4247 - val_accuracy: 0.8095\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4266 - accuracy: 0.8221 - val_loss: 0.4260 - val_accuracy: 0.8011\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4218 - accuracy: 0.8202 - val_loss: 0.4289 - val_accuracy: 0.8011\n",
      "Epoch 140/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4252 - accuracy: 0.8296 - val_loss: 0.4318 - val_accuracy: 0.8011\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4190 - accuracy: 0.8390 - val_loss: 0.4332 - val_accuracy: 0.8011\n",
      "Epoch 142/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4318 - accuracy: 0.8296 - val_loss: 0.4337 - val_accuracy: 0.8011\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4246 - accuracy: 0.8277 - val_loss: 0.4341 - val_accuracy: 0.8011\n",
      "Epoch 144/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4260 - accuracy: 0.8277 - val_loss: 0.4335 - val_accuracy: 0.8011\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4328 - accuracy: 0.8184 - val_loss: 0.4328 - val_accuracy: 0.7983\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4256 - accuracy: 0.8333 - val_loss: 0.4332 - val_accuracy: 0.8095\n",
      "Epoch 147/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4258 - accuracy: 0.8296 - val_loss: 0.4348 - val_accuracy: 0.8039\n",
      "Epoch 148/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4351 - accuracy: 0.8165 - val_loss: 0.4363 - val_accuracy: 0.8039\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4295 - accuracy: 0.8165 - val_loss: 0.4384 - val_accuracy: 0.8039\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4334 - accuracy: 0.8221 - val_loss: 0.4390 - val_accuracy: 0.8039\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4277 - accuracy: 0.8221 - val_loss: 0.4385 - val_accuracy: 0.8095\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4318 - accuracy: 0.8296 - val_loss: 0.4386 - val_accuracy: 0.8095\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4252 - accuracy: 0.8277 - val_loss: 0.4398 - val_accuracy: 0.7983\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4319 - accuracy: 0.8184 - val_loss: 0.4410 - val_accuracy: 0.8067\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4404 - accuracy: 0.8090 - val_loss: 0.4418 - val_accuracy: 0.7899\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4328 - accuracy: 0.8202 - val_loss: 0.4417 - val_accuracy: 0.7927\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4349 - accuracy: 0.8165 - val_loss: 0.4409 - val_accuracy: 0.7927\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4193 - accuracy: 0.8221 - val_loss: 0.4393 - val_accuracy: 0.8011\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4335 - accuracy: 0.8165 - val_loss: 0.4382 - val_accuracy: 0.8095\n",
      "Epoch 160/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4343 - accuracy: 0.8333 - val_loss: 0.4399 - val_accuracy: 0.8095\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4250 - accuracy: 0.8296 - val_loss: 0.4410 - val_accuracy: 0.8095\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4292 - accuracy: 0.8258 - val_loss: 0.4412 - val_accuracy: 0.8123\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4224 - accuracy: 0.8240 - val_loss: 0.4424 - val_accuracy: 0.8011\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4300 - accuracy: 0.8221 - val_loss: 0.4450 - val_accuracy: 0.8039\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4268 - accuracy: 0.8240 - val_loss: 0.4464 - val_accuracy: 0.7843\n",
      "Epoch 166/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4338 - accuracy: 0.8296 - val_loss: 0.4450 - val_accuracy: 0.8011\n",
      "Epoch 167/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4173 - accuracy: 0.8333 - val_loss: 0.4440 - val_accuracy: 0.8011\n",
      "Epoch 168/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4229 - accuracy: 0.8315 - val_loss: 0.4437 - val_accuracy: 0.8011\n",
      "Epoch 169/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4279 - accuracy: 0.8333 - val_loss: 0.4425 - val_accuracy: 0.8011\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4321 - accuracy: 0.8296 - val_loss: 0.4412 - val_accuracy: 0.8011\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4307 - accuracy: 0.8315 - val_loss: 0.4401 - val_accuracy: 0.8011\n",
      "Epoch 172/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4295 - accuracy: 0.8277 - val_loss: 0.4388 - val_accuracy: 0.8011\n",
      "Epoch 173/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4319 - accuracy: 0.8258 - val_loss: 0.4378 - val_accuracy: 0.8011\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4243 - accuracy: 0.8258 - val_loss: 0.4384 - val_accuracy: 0.7843\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4273 - accuracy: 0.8352 - val_loss: 0.4382 - val_accuracy: 0.7843\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4236 - accuracy: 0.8352 - val_loss: 0.4370 - val_accuracy: 0.8011\n",
      "Epoch 177/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4306 - accuracy: 0.8184 - val_loss: 0.4368 - val_accuracy: 0.8011\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4212 - accuracy: 0.8258 - val_loss: 0.4370 - val_accuracy: 0.8011\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4298 - accuracy: 0.8371 - val_loss: 0.4376 - val_accuracy: 0.8011\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4188 - accuracy: 0.8277 - val_loss: 0.4376 - val_accuracy: 0.8123\n",
      "Epoch 181/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4226 - accuracy: 0.8258 - val_loss: 0.4379 - val_accuracy: 0.8011\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4154 - accuracy: 0.8352 - val_loss: 0.4384 - val_accuracy: 0.8011\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4255 - accuracy: 0.8165 - val_loss: 0.4372 - val_accuracy: 0.8011\n",
      "Epoch 184/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4340 - accuracy: 0.8240 - val_loss: 0.4351 - val_accuracy: 0.8123\n",
      "Epoch 185/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4204 - accuracy: 0.8352 - val_loss: 0.4335 - val_accuracy: 0.8123\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4259 - accuracy: 0.8240 - val_loss: 0.4328 - val_accuracy: 0.8095\n",
      "Epoch 187/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4311 - accuracy: 0.8221 - val_loss: 0.4318 - val_accuracy: 0.8095\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4354 - accuracy: 0.8240 - val_loss: 0.4297 - val_accuracy: 0.8095\n",
      "Epoch 189/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4273 - accuracy: 0.8258 - val_loss: 0.4268 - val_accuracy: 0.8095\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4226 - accuracy: 0.8258 - val_loss: 0.4241 - val_accuracy: 0.8123\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4298 - accuracy: 0.8296 - val_loss: 0.4235 - val_accuracy: 0.8151\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4266 - accuracy: 0.8277 - val_loss: 0.4235 - val_accuracy: 0.8151\n",
      "Epoch 193/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4246 - accuracy: 0.8221 - val_loss: 0.4211 - val_accuracy: 0.8151\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4233 - accuracy: 0.8221 - val_loss: 0.4178 - val_accuracy: 0.8151\n",
      "Epoch 195/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4296 - accuracy: 0.8315 - val_loss: 0.4152 - val_accuracy: 0.8151\n",
      "Epoch 196/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4211 - accuracy: 0.8333 - val_loss: 0.4124 - val_accuracy: 0.8151\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4284 - accuracy: 0.8296 - val_loss: 0.4109 - val_accuracy: 0.8123\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4294 - accuracy: 0.8202 - val_loss: 0.4101 - val_accuracy: 0.8039\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4298 - accuracy: 0.8296 - val_loss: 0.4102 - val_accuracy: 0.8039\n",
      "Epoch 200/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4198 - accuracy: 0.8315 - val_loss: 0.4111 - val_accuracy: 0.8095\n",
      "Epoch 201/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4314 - accuracy: 0.8258 - val_loss: 0.4130 - val_accuracy: 0.7983\n",
      "Epoch 202/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4369 - accuracy: 0.8240 - val_loss: 0.4150 - val_accuracy: 0.8039\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4221 - accuracy: 0.8315 - val_loss: 0.4175 - val_accuracy: 0.8011\n",
      "Epoch 204/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4231 - accuracy: 0.8277 - val_loss: 0.4203 - val_accuracy: 0.8011\n",
      "Epoch 205/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4166 - accuracy: 0.8333 - val_loss: 0.4232 - val_accuracy: 0.8011\n",
      "Epoch 206/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4199 - accuracy: 0.8277 - val_loss: 0.4262 - val_accuracy: 0.8011\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4276 - accuracy: 0.8221 - val_loss: 0.4284 - val_accuracy: 0.8011\n",
      "Epoch 208/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4176 - accuracy: 0.8184 - val_loss: 0.4303 - val_accuracy: 0.7983\n",
      "Epoch 209/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4201 - accuracy: 0.8333 - val_loss: 0.4317 - val_accuracy: 0.7983\n",
      "Epoch 210/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4148 - accuracy: 0.8240 - val_loss: 0.4326 - val_accuracy: 0.7983\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4218 - accuracy: 0.8221 - val_loss: 0.4329 - val_accuracy: 0.7983\n",
      "Epoch 212/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4187 - accuracy: 0.8240 - val_loss: 0.4327 - val_accuracy: 0.7983\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4179 - accuracy: 0.8240 - val_loss: 0.4326 - val_accuracy: 0.7983\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4115 - accuracy: 0.8446 - val_loss: 0.4328 - val_accuracy: 0.7983\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4282 - accuracy: 0.8296 - val_loss: 0.4342 - val_accuracy: 0.8067\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4233 - accuracy: 0.8296 - val_loss: 0.4363 - val_accuracy: 0.8067\n",
      "Epoch 217/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4225 - accuracy: 0.8202 - val_loss: 0.4378 - val_accuracy: 0.7983\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4186 - accuracy: 0.8221 - val_loss: 0.4379 - val_accuracy: 0.7983\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4196 - accuracy: 0.8240 - val_loss: 0.4359 - val_accuracy: 0.7983\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4311 - accuracy: 0.8258 - val_loss: 0.4342 - val_accuracy: 0.7983\n",
      "Epoch 221/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4180 - accuracy: 0.8277 - val_loss: 0.4338 - val_accuracy: 0.7983\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4217 - accuracy: 0.8258 - val_loss: 0.4342 - val_accuracy: 0.8095\n",
      "Epoch 223/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4176 - accuracy: 0.8221 - val_loss: 0.4347 - val_accuracy: 0.8067\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4265 - accuracy: 0.8258 - val_loss: 0.4352 - val_accuracy: 0.7983\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4201 - accuracy: 0.8277 - val_loss: 0.4363 - val_accuracy: 0.7983\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4249 - accuracy: 0.8277 - val_loss: 0.4386 - val_accuracy: 0.8095\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4212 - accuracy: 0.8258 - val_loss: 0.4413 - val_accuracy: 0.8095\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4243 - accuracy: 0.8315 - val_loss: 0.4425 - val_accuracy: 0.8095\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4304 - accuracy: 0.8258 - val_loss: 0.4408 - val_accuracy: 0.8095\n",
      "Epoch 230/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4297 - accuracy: 0.8296 - val_loss: 0.4381 - val_accuracy: 0.8095\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4151 - accuracy: 0.8352 - val_loss: 0.4359 - val_accuracy: 0.8095\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4210 - accuracy: 0.8333 - val_loss: 0.4345 - val_accuracy: 0.8095\n",
      "Epoch 233/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4245 - accuracy: 0.8258 - val_loss: 0.4339 - val_accuracy: 0.8095\n",
      "Epoch 234/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4363 - accuracy: 0.8184 - val_loss: 0.4337 - val_accuracy: 0.8151\n",
      "Epoch 235/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4266 - accuracy: 0.8165 - val_loss: 0.4337 - val_accuracy: 0.8039\n",
      "Epoch 236/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4220 - accuracy: 0.8240 - val_loss: 0.4341 - val_accuracy: 0.8123\n",
      "Epoch 237/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4215 - accuracy: 0.8296 - val_loss: 0.4342 - val_accuracy: 0.8123\n",
      "Epoch 238/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4385 - accuracy: 0.8109 - val_loss: 0.4335 - val_accuracy: 0.8123\n",
      "Epoch 239/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4266 - accuracy: 0.8221 - val_loss: 0.4332 - val_accuracy: 0.8123\n",
      "Epoch 240/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4284 - accuracy: 0.8184 - val_loss: 0.4325 - val_accuracy: 0.8123\n",
      "Epoch 241/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4293 - accuracy: 0.8315 - val_loss: 0.4314 - val_accuracy: 0.8039\n",
      "Epoch 242/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4294 - accuracy: 0.8352 - val_loss: 0.4315 - val_accuracy: 0.8123\n",
      "Epoch 243/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4293 - accuracy: 0.8333 - val_loss: 0.4317 - val_accuracy: 0.8011\n",
      "Epoch 244/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4266 - accuracy: 0.8296 - val_loss: 0.4318 - val_accuracy: 0.8039\n",
      "Epoch 245/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4088 - accuracy: 0.8371 - val_loss: 0.4324 - val_accuracy: 0.8123\n",
      "Epoch 246/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4276 - accuracy: 0.8184 - val_loss: 0.4319 - val_accuracy: 0.8123\n",
      "Epoch 247/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4185 - accuracy: 0.8258 - val_loss: 0.4321 - val_accuracy: 0.8123\n",
      "Epoch 248/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4346 - accuracy: 0.8315 - val_loss: 0.4319 - val_accuracy: 0.8039\n",
      "Epoch 249/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4251 - accuracy: 0.8258 - val_loss: 0.4311 - val_accuracy: 0.8039\n",
      "Epoch 250/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4163 - accuracy: 0.8390 - val_loss: 0.4308 - val_accuracy: 0.8011\n",
      "Epoch 251/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4172 - accuracy: 0.8390 - val_loss: 0.4306 - val_accuracy: 0.7955\n",
      "Epoch 252/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4232 - accuracy: 0.8296 - val_loss: 0.4309 - val_accuracy: 0.7955\n",
      "Epoch 253/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4227 - accuracy: 0.8240 - val_loss: 0.4312 - val_accuracy: 0.8011\n",
      "Epoch 254/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4228 - accuracy: 0.8277 - val_loss: 0.4318 - val_accuracy: 0.8123\n",
      "Epoch 255/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4142 - accuracy: 0.8258 - val_loss: 0.4345 - val_accuracy: 0.8123\n",
      "Epoch 256/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4252 - accuracy: 0.8296 - val_loss: 0.4372 - val_accuracy: 0.8123\n",
      "Epoch 257/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4203 - accuracy: 0.8240 - val_loss: 0.4378 - val_accuracy: 0.8123\n",
      "Epoch 258/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4278 - accuracy: 0.8277 - val_loss: 0.4356 - val_accuracy: 0.8123\n",
      "Epoch 259/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4116 - accuracy: 0.8240 - val_loss: 0.4334 - val_accuracy: 0.8011\n",
      "Epoch 260/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4244 - accuracy: 0.8352 - val_loss: 0.4316 - val_accuracy: 0.8011\n",
      "Epoch 261/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4326 - accuracy: 0.8277 - val_loss: 0.4308 - val_accuracy: 0.8011\n",
      "Epoch 262/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4248 - accuracy: 0.8277 - val_loss: 0.4304 - val_accuracy: 0.8011\n",
      "Epoch 263/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4258 - accuracy: 0.8333 - val_loss: 0.4290 - val_accuracy: 0.8011\n",
      "Epoch 264/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4224 - accuracy: 0.8258 - val_loss: 0.4283 - val_accuracy: 0.7983\n",
      "Epoch 265/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4306 - accuracy: 0.8146 - val_loss: 0.4286 - val_accuracy: 0.8095\n",
      "Epoch 266/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4277 - accuracy: 0.8202 - val_loss: 0.4300 - val_accuracy: 0.7983\n",
      "Epoch 267/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4310 - accuracy: 0.8277 - val_loss: 0.4311 - val_accuracy: 0.7815\n",
      "Epoch 268/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4233 - accuracy: 0.8240 - val_loss: 0.4317 - val_accuracy: 0.7815\n",
      "Epoch 269/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4167 - accuracy: 0.8333 - val_loss: 0.4317 - val_accuracy: 0.7983\n",
      "Epoch 270/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4322 - accuracy: 0.8221 - val_loss: 0.4317 - val_accuracy: 0.8095\n",
      "Epoch 271/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4178 - accuracy: 0.8165 - val_loss: 0.4322 - val_accuracy: 0.8095\n",
      "Epoch 272/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4316 - accuracy: 0.8146 - val_loss: 0.4325 - val_accuracy: 0.8095\n",
      "Epoch 273/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4282 - accuracy: 0.8221 - val_loss: 0.4334 - val_accuracy: 0.8095\n",
      "Epoch 274/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4219 - accuracy: 0.8371 - val_loss: 0.4326 - val_accuracy: 0.8095\n",
      "Epoch 275/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4298 - accuracy: 0.8202 - val_loss: 0.4320 - val_accuracy: 0.8123\n",
      "Epoch 276/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4372 - accuracy: 0.8296 - val_loss: 0.4320 - val_accuracy: 0.8011\n",
      "Epoch 277/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4186 - accuracy: 0.8277 - val_loss: 0.4322 - val_accuracy: 0.7955\n",
      "Epoch 278/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4116 - accuracy: 0.8315 - val_loss: 0.4327 - val_accuracy: 0.7955\n",
      "Epoch 279/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4269 - accuracy: 0.8333 - val_loss: 0.4335 - val_accuracy: 0.7955\n",
      "Epoch 280/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4265 - accuracy: 0.8240 - val_loss: 0.4343 - val_accuracy: 0.7955\n",
      "Epoch 281/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4310 - accuracy: 0.8296 - val_loss: 0.4347 - val_accuracy: 0.7955\n",
      "Epoch 282/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4283 - accuracy: 0.8296 - val_loss: 0.4349 - val_accuracy: 0.7927\n",
      "Epoch 283/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4254 - accuracy: 0.8296 - val_loss: 0.4351 - val_accuracy: 0.7927\n",
      "Epoch 284/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4228 - accuracy: 0.8352 - val_loss: 0.4360 - val_accuracy: 0.8039\n",
      "Epoch 285/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4189 - accuracy: 0.8296 - val_loss: 0.4375 - val_accuracy: 0.8039\n",
      "Epoch 286/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4291 - accuracy: 0.8258 - val_loss: 0.4381 - val_accuracy: 0.8039\n",
      "Epoch 287/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4202 - accuracy: 0.8258 - val_loss: 0.4381 - val_accuracy: 0.8039\n",
      "Epoch 288/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4254 - accuracy: 0.8258 - val_loss: 0.4373 - val_accuracy: 0.7927\n",
      "Epoch 289/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4090 - accuracy: 0.8277 - val_loss: 0.4365 - val_accuracy: 0.7983\n",
      "Epoch 290/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4189 - accuracy: 0.8427 - val_loss: 0.4368 - val_accuracy: 0.8067\n",
      "Epoch 291/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4303 - accuracy: 0.8221 - val_loss: 0.4365 - val_accuracy: 0.8067\n",
      "Epoch 292/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4419 - accuracy: 0.8315 - val_loss: 0.4352 - val_accuracy: 0.7983\n",
      "Epoch 293/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4204 - accuracy: 0.8333 - val_loss: 0.4344 - val_accuracy: 0.7983\n",
      "Epoch 294/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4237 - accuracy: 0.8333 - val_loss: 0.4340 - val_accuracy: 0.7983\n",
      "Epoch 295/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4271 - accuracy: 0.8277 - val_loss: 0.4335 - val_accuracy: 0.7983\n",
      "Epoch 296/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4238 - accuracy: 0.8315 - val_loss: 0.4339 - val_accuracy: 0.7927\n",
      "Epoch 297/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4278 - accuracy: 0.8371 - val_loss: 0.4344 - val_accuracy: 0.7927\n",
      "Epoch 298/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4301 - accuracy: 0.8296 - val_loss: 0.4345 - val_accuracy: 0.7983\n",
      "Epoch 299/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4316 - accuracy: 0.8296 - val_loss: 0.4335 - val_accuracy: 0.8011\n",
      "Epoch 300/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4414 - accuracy: 0.8333 - val_loss: 0.4336 - val_accuracy: 0.8011\n",
      "Epoch 301/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4241 - accuracy: 0.8315 - val_loss: 0.4347 - val_accuracy: 0.7843\n",
      "Epoch 302/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4256 - accuracy: 0.8277 - val_loss: 0.4351 - val_accuracy: 0.7927\n",
      "Epoch 303/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4240 - accuracy: 0.8184 - val_loss: 0.4348 - val_accuracy: 0.7843\n",
      "Epoch 304/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4246 - accuracy: 0.8240 - val_loss: 0.4349 - val_accuracy: 0.8011\n",
      "Epoch 305/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4200 - accuracy: 0.8333 - val_loss: 0.4361 - val_accuracy: 0.8011\n",
      "Epoch 306/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4157 - accuracy: 0.8221 - val_loss: 0.4374 - val_accuracy: 0.8011\n",
      "Epoch 307/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4347 - accuracy: 0.8184 - val_loss: 0.4375 - val_accuracy: 0.8011\n",
      "Epoch 308/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4247 - accuracy: 0.8277 - val_loss: 0.4366 - val_accuracy: 0.8011\n",
      "Epoch 309/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4228 - accuracy: 0.8277 - val_loss: 0.4364 - val_accuracy: 0.8011\n",
      "Epoch 310/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4275 - accuracy: 0.8296 - val_loss: 0.4365 - val_accuracy: 0.8011\n",
      "Epoch 311/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4235 - accuracy: 0.8352 - val_loss: 0.4360 - val_accuracy: 0.8011\n",
      "Epoch 312/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4291 - accuracy: 0.8315 - val_loss: 0.4345 - val_accuracy: 0.8011\n",
      "Epoch 313/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4189 - accuracy: 0.8240 - val_loss: 0.4327 - val_accuracy: 0.8011\n",
      "Epoch 314/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4322 - accuracy: 0.8277 - val_loss: 0.4306 - val_accuracy: 0.8011\n",
      "Epoch 315/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4262 - accuracy: 0.8296 - val_loss: 0.4290 - val_accuracy: 0.8011\n",
      "Epoch 316/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4179 - accuracy: 0.8296 - val_loss: 0.4285 - val_accuracy: 0.8011\n",
      "Epoch 317/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4192 - accuracy: 0.8165 - val_loss: 0.4295 - val_accuracy: 0.7843\n",
      "Epoch 318/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4295 - accuracy: 0.8146 - val_loss: 0.4303 - val_accuracy: 0.7955\n",
      "Epoch 319/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4182 - accuracy: 0.8240 - val_loss: 0.4304 - val_accuracy: 0.7927\n",
      "Epoch 320/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4244 - accuracy: 0.8202 - val_loss: 0.4305 - val_accuracy: 0.7927\n",
      "Epoch 321/1000\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.4277 - accuracy: 0.8221 - val_loss: 0.4312 - val_accuracy: 0.8095\n",
      "Epoch 322/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4312 - accuracy: 0.8202 - val_loss: 0.4306 - val_accuracy: 0.8011\n",
      "Epoch 323/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4240 - accuracy: 0.8240 - val_loss: 0.4306 - val_accuracy: 0.7983\n",
      "Epoch 324/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4259 - accuracy: 0.8240 - val_loss: 0.4318 - val_accuracy: 0.8095\n",
      "Epoch 325/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4246 - accuracy: 0.8277 - val_loss: 0.4347 - val_accuracy: 0.8039\n",
      "Epoch 326/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4253 - accuracy: 0.8221 - val_loss: 0.4407 - val_accuracy: 0.8067\n",
      "Epoch 327/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4321 - accuracy: 0.8184 - val_loss: 0.4425 - val_accuracy: 0.8067\n",
      "Epoch 328/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4411 - accuracy: 0.8127 - val_loss: 0.4382 - val_accuracy: 0.8067\n",
      "Epoch 329/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4303 - accuracy: 0.8277 - val_loss: 0.4336 - val_accuracy: 0.8095\n",
      "Epoch 330/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4296 - accuracy: 0.8277 - val_loss: 0.4335 - val_accuracy: 0.8067\n",
      "Epoch 331/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4229 - accuracy: 0.8240 - val_loss: 0.4368 - val_accuracy: 0.8095\n",
      "Epoch 332/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4355 - accuracy: 0.8333 - val_loss: 0.4399 - val_accuracy: 0.7871\n",
      "Epoch 333/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4242 - accuracy: 0.8184 - val_loss: 0.4392 - val_accuracy: 0.7927\n",
      "Epoch 334/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4225 - accuracy: 0.8146 - val_loss: 0.4371 - val_accuracy: 0.7927\n",
      "Epoch 335/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4143 - accuracy: 0.8277 - val_loss: 0.4368 - val_accuracy: 0.8095\n",
      "Epoch 336/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4227 - accuracy: 0.8221 - val_loss: 0.4370 - val_accuracy: 0.8095\n",
      "Epoch 337/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4255 - accuracy: 0.8258 - val_loss: 0.4356 - val_accuracy: 0.8095\n",
      "Epoch 338/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4261 - accuracy: 0.8202 - val_loss: 0.4345 - val_accuracy: 0.7983\n",
      "Epoch 339/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4203 - accuracy: 0.8315 - val_loss: 0.4361 - val_accuracy: 0.8095\n",
      "Epoch 340/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4236 - accuracy: 0.8296 - val_loss: 0.4379 - val_accuracy: 0.8039\n",
      "Epoch 341/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4334 - accuracy: 0.8221 - val_loss: 0.4373 - val_accuracy: 0.8039\n",
      "Epoch 342/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4382 - accuracy: 0.8221 - val_loss: 0.4353 - val_accuracy: 0.8095\n",
      "Epoch 343/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4230 - accuracy: 0.8296 - val_loss: 0.4338 - val_accuracy: 0.8095\n",
      "Epoch 344/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4207 - accuracy: 0.8240 - val_loss: 0.4336 - val_accuracy: 0.7983\n",
      "Epoch 345/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4265 - accuracy: 0.8221 - val_loss: 0.4341 - val_accuracy: 0.8011\n",
      "Epoch 346/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4226 - accuracy: 0.8277 - val_loss: 0.4350 - val_accuracy: 0.8123\n",
      "Epoch 347/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4218 - accuracy: 0.8277 - val_loss: 0.4358 - val_accuracy: 0.8123\n",
      "Epoch 348/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4259 - accuracy: 0.8258 - val_loss: 0.4368 - val_accuracy: 0.8123\n",
      "Epoch 349/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4217 - accuracy: 0.8202 - val_loss: 0.4378 - val_accuracy: 0.8095\n",
      "Epoch 350/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4214 - accuracy: 0.8315 - val_loss: 0.4388 - val_accuracy: 0.8095\n",
      "Epoch 351/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4283 - accuracy: 0.8202 - val_loss: 0.4401 - val_accuracy: 0.8151\n",
      "Epoch 352/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4293 - accuracy: 0.8277 - val_loss: 0.4410 - val_accuracy: 0.8151\n",
      "Epoch 353/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4170 - accuracy: 0.8277 - val_loss: 0.4415 - val_accuracy: 0.8151\n",
      "Epoch 354/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4271 - accuracy: 0.8258 - val_loss: 0.4414 - val_accuracy: 0.8151\n",
      "Epoch 355/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4338 - accuracy: 0.8277 - val_loss: 0.4403 - val_accuracy: 0.8123\n",
      "Epoch 356/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4217 - accuracy: 0.8371 - val_loss: 0.4397 - val_accuracy: 0.8095\n",
      "Epoch 357/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4247 - accuracy: 0.8277 - val_loss: 0.4394 - val_accuracy: 0.8095\n",
      "Epoch 358/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4224 - accuracy: 0.8277 - val_loss: 0.4382 - val_accuracy: 0.8095\n",
      "Epoch 359/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4264 - accuracy: 0.8315 - val_loss: 0.4365 - val_accuracy: 0.8095\n",
      "Epoch 360/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4263 - accuracy: 0.8277 - val_loss: 0.4350 - val_accuracy: 0.8095\n",
      "Epoch 361/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4244 - accuracy: 0.8240 - val_loss: 0.4338 - val_accuracy: 0.8095\n",
      "Epoch 362/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4287 - accuracy: 0.8258 - val_loss: 0.4338 - val_accuracy: 0.8095\n",
      "Epoch 363/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4198 - accuracy: 0.8258 - val_loss: 0.4350 - val_accuracy: 0.8095\n",
      "Epoch 364/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4298 - accuracy: 0.8315 - val_loss: 0.4370 - val_accuracy: 0.8095\n",
      "Epoch 365/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4235 - accuracy: 0.8277 - val_loss: 0.4378 - val_accuracy: 0.8095\n",
      "Epoch 366/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4333 - accuracy: 0.8333 - val_loss: 0.4374 - val_accuracy: 0.8095\n",
      "Epoch 367/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4210 - accuracy: 0.8296 - val_loss: 0.4363 - val_accuracy: 0.8095\n",
      "Epoch 368/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4245 - accuracy: 0.8296 - val_loss: 0.4355 - val_accuracy: 0.8011\n",
      "Epoch 369/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4337 - accuracy: 0.8277 - val_loss: 0.4353 - val_accuracy: 0.8011\n",
      "Epoch 370/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4324 - accuracy: 0.8296 - val_loss: 0.4362 - val_accuracy: 0.7843\n",
      "Epoch 371/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4201 - accuracy: 0.8258 - val_loss: 0.4364 - val_accuracy: 0.7927\n",
      "Epoch 372/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4281 - accuracy: 0.8202 - val_loss: 0.4357 - val_accuracy: 0.8095\n",
      "Epoch 373/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4281 - accuracy: 0.8146 - val_loss: 0.4340 - val_accuracy: 0.8011\n",
      "Epoch 374/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4206 - accuracy: 0.8240 - val_loss: 0.4336 - val_accuracy: 0.7983\n",
      "Epoch 375/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4206 - accuracy: 0.8202 - val_loss: 0.4343 - val_accuracy: 0.7983\n",
      "Epoch 376/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4215 - accuracy: 0.8296 - val_loss: 0.4349 - val_accuracy: 0.7983\n",
      "Epoch 377/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4294 - accuracy: 0.8240 - val_loss: 0.4347 - val_accuracy: 0.8011\n",
      "Epoch 378/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4290 - accuracy: 0.8296 - val_loss: 0.4339 - val_accuracy: 0.8011\n",
      "Epoch 379/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4205 - accuracy: 0.8202 - val_loss: 0.4331 - val_accuracy: 0.7983\n",
      "Epoch 380/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4182 - accuracy: 0.8352 - val_loss: 0.4323 - val_accuracy: 0.7983\n",
      "Epoch 381/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4217 - accuracy: 0.8165 - val_loss: 0.4310 - val_accuracy: 0.7983\n",
      "Epoch 382/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4196 - accuracy: 0.8258 - val_loss: 0.4301 - val_accuracy: 0.7983\n",
      "Epoch 383/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4264 - accuracy: 0.8240 - val_loss: 0.4295 - val_accuracy: 0.7983\n",
      "Epoch 384/1000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4223 - accuracy: 0.8315 - val_loss: 0.4298 - val_accuracy: 0.7983\n",
      "Epoch 385/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4280 - accuracy: 0.8258 - val_loss: 0.4296 - val_accuracy: 0.7983\n",
      "Epoch 386/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4252 - accuracy: 0.8277 - val_loss: 0.4293 - val_accuracy: 0.8095\n",
      "Epoch 387/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4227 - accuracy: 0.8165 - val_loss: 0.4298 - val_accuracy: 0.7927\n",
      "Epoch 388/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4205 - accuracy: 0.8184 - val_loss: 0.4302 - val_accuracy: 0.7927\n",
      "Epoch 389/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4226 - accuracy: 0.8240 - val_loss: 0.4299 - val_accuracy: 0.8095\n",
      "Epoch 390/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4179 - accuracy: 0.8240 - val_loss: 0.4285 - val_accuracy: 0.8011\n",
      "Epoch 391/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4199 - accuracy: 0.8277 - val_loss: 0.4275 - val_accuracy: 0.8011\n",
      "Epoch 392/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4213 - accuracy: 0.8277 - val_loss: 0.4279 - val_accuracy: 0.8011\n",
      "Epoch 393/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4292 - accuracy: 0.8221 - val_loss: 0.4298 - val_accuracy: 0.8011\n",
      "Epoch 394/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4067 - accuracy: 0.8521 - val_loss: 0.4323 - val_accuracy: 0.8011\n",
      "Epoch 395/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4102 - accuracy: 0.8165 - val_loss: 0.4339 - val_accuracy: 0.8011\n",
      "Epoch 396/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4215 - accuracy: 0.8296 - val_loss: 0.4358 - val_accuracy: 0.8095\n",
      "Epoch 397/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4217 - accuracy: 0.8202 - val_loss: 0.4368 - val_accuracy: 0.8095\n",
      "Epoch 398/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4202 - accuracy: 0.8333 - val_loss: 0.4343 - val_accuracy: 0.8011\n",
      "Epoch 399/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4284 - accuracy: 0.8240 - val_loss: 0.4326 - val_accuracy: 0.8011\n",
      "Epoch 400/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4144 - accuracy: 0.8202 - val_loss: 0.4318 - val_accuracy: 0.8123\n",
      "Epoch 401/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4322 - accuracy: 0.8146 - val_loss: 0.4321 - val_accuracy: 0.8039\n",
      "Epoch 402/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4177 - accuracy: 0.8240 - val_loss: 0.4330 - val_accuracy: 0.8123\n",
      "Epoch 403/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4291 - accuracy: 0.8296 - val_loss: 0.4337 - val_accuracy: 0.8123\n",
      "Epoch 404/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4303 - accuracy: 0.8315 - val_loss: 0.4339 - val_accuracy: 0.8123\n",
      "Epoch 405/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4231 - accuracy: 0.8315 - val_loss: 0.4340 - val_accuracy: 0.8123\n",
      "Epoch 406/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4180 - accuracy: 0.8221 - val_loss: 0.4333 - val_accuracy: 0.8123\n",
      "Epoch 407/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4211 - accuracy: 0.8315 - val_loss: 0.4330 - val_accuracy: 0.8151\n",
      "Epoch 408/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4216 - accuracy: 0.8296 - val_loss: 0.4335 - val_accuracy: 0.8151\n",
      "Epoch 409/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4183 - accuracy: 0.8296 - val_loss: 0.4336 - val_accuracy: 0.8151\n",
      "Epoch 410/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4232 - accuracy: 0.8315 - val_loss: 0.4334 - val_accuracy: 0.8151\n",
      "Epoch 411/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4239 - accuracy: 0.8333 - val_loss: 0.4333 - val_accuracy: 0.8151\n",
      "Epoch 412/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4202 - accuracy: 0.8258 - val_loss: 0.4333 - val_accuracy: 0.8039\n",
      "Epoch 413/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4201 - accuracy: 0.8296 - val_loss: 0.4332 - val_accuracy: 0.8039\n",
      "Epoch 414/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4207 - accuracy: 0.8296 - val_loss: 0.4335 - val_accuracy: 0.8151\n",
      "Epoch 415/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4325 - accuracy: 0.8315 - val_loss: 0.4339 - val_accuracy: 0.8151\n",
      "Epoch 416/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4233 - accuracy: 0.8315 - val_loss: 0.4339 - val_accuracy: 0.8151\n",
      "Epoch 417/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4183 - accuracy: 0.8371 - val_loss: 0.4342 - val_accuracy: 0.8151\n",
      "Epoch 418/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4241 - accuracy: 0.8352 - val_loss: 0.4342 - val_accuracy: 0.8151\n",
      "Epoch 419/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4282 - accuracy: 0.8277 - val_loss: 0.4348 - val_accuracy: 0.8151\n",
      "Epoch 420/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4178 - accuracy: 0.8296 - val_loss: 0.4356 - val_accuracy: 0.8151\n",
      "Epoch 421/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4258 - accuracy: 0.8390 - val_loss: 0.4361 - val_accuracy: 0.8151\n",
      "Epoch 422/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4290 - accuracy: 0.8258 - val_loss: 0.4357 - val_accuracy: 0.8151\n",
      "Epoch 423/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4190 - accuracy: 0.8240 - val_loss: 0.4335 - val_accuracy: 0.8151\n",
      "Epoch 424/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4204 - accuracy: 0.8315 - val_loss: 0.4323 - val_accuracy: 0.8151\n",
      "Epoch 425/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4272 - accuracy: 0.8296 - val_loss: 0.4315 - val_accuracy: 0.8151\n",
      "Epoch 426/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4204 - accuracy: 0.8296 - val_loss: 0.4304 - val_accuracy: 0.8151\n",
      "Epoch 427/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4244 - accuracy: 0.8371 - val_loss: 0.4290 - val_accuracy: 0.8151\n",
      "Epoch 428/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4110 - accuracy: 0.8333 - val_loss: 0.4283 - val_accuracy: 0.8151\n",
      "Epoch 429/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4224 - accuracy: 0.8352 - val_loss: 0.4286 - val_accuracy: 0.8123\n",
      "Epoch 430/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4164 - accuracy: 0.8446 - val_loss: 0.4289 - val_accuracy: 0.8123\n",
      "Epoch 431/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4286 - accuracy: 0.8333 - val_loss: 0.4282 - val_accuracy: 0.8123\n",
      "Epoch 432/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4158 - accuracy: 0.8258 - val_loss: 0.4273 - val_accuracy: 0.8123\n",
      "Epoch 433/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4312 - accuracy: 0.8184 - val_loss: 0.4262 - val_accuracy: 0.8151\n",
      "Epoch 434/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4351 - accuracy: 0.8277 - val_loss: 0.4259 - val_accuracy: 0.8039\n",
      "Epoch 435/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4272 - accuracy: 0.8184 - val_loss: 0.4252 - val_accuracy: 0.8039\n",
      "Epoch 436/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4157 - accuracy: 0.8240 - val_loss: 0.4231 - val_accuracy: 0.8039\n",
      "Epoch 437/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4153 - accuracy: 0.8240 - val_loss: 0.4224 - val_accuracy: 0.8039\n",
      "Epoch 438/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4229 - accuracy: 0.8352 - val_loss: 0.4223 - val_accuracy: 0.8039\n",
      "Epoch 439/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4233 - accuracy: 0.8296 - val_loss: 0.4229 - val_accuracy: 0.8151\n",
      "Epoch 440/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4197 - accuracy: 0.8258 - val_loss: 0.4247 - val_accuracy: 0.8123\n",
      "Epoch 441/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4271 - accuracy: 0.8296 - val_loss: 0.4279 - val_accuracy: 0.8123\n",
      "Epoch 442/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4237 - accuracy: 0.8277 - val_loss: 0.4307 - val_accuracy: 0.8095\n",
      "Epoch 443/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4267 - accuracy: 0.8277 - val_loss: 0.4330 - val_accuracy: 0.8095\n",
      "Epoch 444/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4269 - accuracy: 0.8277 - val_loss: 0.4346 - val_accuracy: 0.8123\n",
      "Epoch 445/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4237 - accuracy: 0.8258 - val_loss: 0.4353 - val_accuracy: 0.8123\n",
      "Epoch 446/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4230 - accuracy: 0.8333 - val_loss: 0.4342 - val_accuracy: 0.8123\n",
      "Epoch 447/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4164 - accuracy: 0.8315 - val_loss: 0.4328 - val_accuracy: 0.8123\n",
      "Epoch 448/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4213 - accuracy: 0.8390 - val_loss: 0.4323 - val_accuracy: 0.8011\n",
      "Epoch 449/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4207 - accuracy: 0.8240 - val_loss: 0.4322 - val_accuracy: 0.8011\n",
      "Epoch 450/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4273 - accuracy: 0.8240 - val_loss: 0.4328 - val_accuracy: 0.8011\n",
      "Epoch 451/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4243 - accuracy: 0.8333 - val_loss: 0.4336 - val_accuracy: 0.8011\n",
      "Epoch 452/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4236 - accuracy: 0.8333 - val_loss: 0.4351 - val_accuracy: 0.8039\n",
      "Epoch 453/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4224 - accuracy: 0.8258 - val_loss: 0.4367 - val_accuracy: 0.8123\n",
      "Epoch 454/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4335 - accuracy: 0.8258 - val_loss: 0.4382 - val_accuracy: 0.7955\n",
      "Epoch 455/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4195 - accuracy: 0.8127 - val_loss: 0.4391 - val_accuracy: 0.7955\n",
      "Epoch 456/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4269 - accuracy: 0.8240 - val_loss: 0.4393 - val_accuracy: 0.8123\n",
      "Epoch 457/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4235 - accuracy: 0.8202 - val_loss: 0.4395 - val_accuracy: 0.8123\n",
      "Epoch 458/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4231 - accuracy: 0.8315 - val_loss: 0.4392 - val_accuracy: 0.8039\n",
      "Epoch 459/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4249 - accuracy: 0.8258 - val_loss: 0.4387 - val_accuracy: 0.8011\n",
      "Epoch 460/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4139 - accuracy: 0.8371 - val_loss: 0.4382 - val_accuracy: 0.8011\n",
      "Epoch 461/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4196 - accuracy: 0.8333 - val_loss: 0.4372 - val_accuracy: 0.8011\n",
      "Epoch 462/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4236 - accuracy: 0.8277 - val_loss: 0.4362 - val_accuracy: 0.8039\n",
      "Epoch 463/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4239 - accuracy: 0.8258 - val_loss: 0.4358 - val_accuracy: 0.8039\n",
      "Epoch 464/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4260 - accuracy: 0.8390 - val_loss: 0.4361 - val_accuracy: 0.8039\n",
      "Epoch 465/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4246 - accuracy: 0.8315 - val_loss: 0.4361 - val_accuracy: 0.8123\n",
      "Epoch 466/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4290 - accuracy: 0.8221 - val_loss: 0.4361 - val_accuracy: 0.8095\n",
      "Epoch 467/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4253 - accuracy: 0.8258 - val_loss: 0.4358 - val_accuracy: 0.8095\n",
      "Epoch 468/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4280 - accuracy: 0.8333 - val_loss: 0.4352 - val_accuracy: 0.8095\n",
      "Epoch 469/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4215 - accuracy: 0.8277 - val_loss: 0.4348 - val_accuracy: 0.8095\n",
      "Epoch 470/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4176 - accuracy: 0.8258 - val_loss: 0.4348 - val_accuracy: 0.8095\n",
      "Epoch 471/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4265 - accuracy: 0.8352 - val_loss: 0.4354 - val_accuracy: 0.8095\n",
      "Epoch 472/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4252 - accuracy: 0.8202 - val_loss: 0.4349 - val_accuracy: 0.8067\n",
      "Epoch 473/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4273 - accuracy: 0.8315 - val_loss: 0.4356 - val_accuracy: 0.8095\n",
      "Epoch 474/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4216 - accuracy: 0.8258 - val_loss: 0.4354 - val_accuracy: 0.8123\n",
      "Epoch 475/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4304 - accuracy: 0.8221 - val_loss: 0.4328 - val_accuracy: 0.8095\n",
      "Epoch 476/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4196 - accuracy: 0.8221 - val_loss: 0.4311 - val_accuracy: 0.8067\n",
      "Epoch 477/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4243 - accuracy: 0.8258 - val_loss: 0.4303 - val_accuracy: 0.8067\n",
      "Epoch 478/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4254 - accuracy: 0.8296 - val_loss: 0.4305 - val_accuracy: 0.7983\n",
      "Epoch 479/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4269 - accuracy: 0.8352 - val_loss: 0.4308 - val_accuracy: 0.7983\n",
      "Epoch 480/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4278 - accuracy: 0.8221 - val_loss: 0.4309 - val_accuracy: 0.7983\n",
      "Epoch 481/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4260 - accuracy: 0.8315 - val_loss: 0.4321 - val_accuracy: 0.8095\n",
      "Epoch 482/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4284 - accuracy: 0.8258 - val_loss: 0.4338 - val_accuracy: 0.8039\n",
      "Epoch 483/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4237 - accuracy: 0.8221 - val_loss: 0.4347 - val_accuracy: 0.8039\n",
      "Epoch 484/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4278 - accuracy: 0.8296 - val_loss: 0.4329 - val_accuracy: 0.8039\n",
      "Epoch 485/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4299 - accuracy: 0.8258 - val_loss: 0.4310 - val_accuracy: 0.8123\n",
      "Epoch 486/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4209 - accuracy: 0.8333 - val_loss: 0.4305 - val_accuracy: 0.8039\n",
      "Epoch 487/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4296 - accuracy: 0.8165 - val_loss: 0.4319 - val_accuracy: 0.8123\n",
      "Epoch 488/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4132 - accuracy: 0.8277 - val_loss: 0.4344 - val_accuracy: 0.7955\n",
      "Epoch 489/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4216 - accuracy: 0.8090 - val_loss: 0.4362 - val_accuracy: 0.7955\n",
      "Epoch 490/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4300 - accuracy: 0.8240 - val_loss: 0.4359 - val_accuracy: 0.7955\n",
      "Epoch 491/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4224 - accuracy: 0.8240 - val_loss: 0.4338 - val_accuracy: 0.8123\n",
      "Epoch 492/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4273 - accuracy: 0.8240 - val_loss: 0.4320 - val_accuracy: 0.8039\n",
      "Epoch 493/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4169 - accuracy: 0.8390 - val_loss: 0.4306 - val_accuracy: 0.8151\n",
      "Epoch 494/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4139 - accuracy: 0.8333 - val_loss: 0.4307 - val_accuracy: 0.8151\n",
      "Epoch 495/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4285 - accuracy: 0.8240 - val_loss: 0.4309 - val_accuracy: 0.8123\n",
      "Epoch 496/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4288 - accuracy: 0.8277 - val_loss: 0.4300 - val_accuracy: 0.8123\n",
      "Epoch 497/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4152 - accuracy: 0.8352 - val_loss: 0.4280 - val_accuracy: 0.8123\n",
      "Epoch 498/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4275 - accuracy: 0.8333 - val_loss: 0.4257 - val_accuracy: 0.8151\n",
      "Epoch 499/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4336 - accuracy: 0.8240 - val_loss: 0.4238 - val_accuracy: 0.8151\n",
      "Epoch 500/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4229 - accuracy: 0.8277 - val_loss: 0.4230 - val_accuracy: 0.8151\n",
      "Epoch 501/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4134 - accuracy: 0.8333 - val_loss: 0.4224 - val_accuracy: 0.8151\n",
      "Epoch 502/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4224 - accuracy: 0.8165 - val_loss: 0.4223 - val_accuracy: 0.8039\n",
      "Epoch 503/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4198 - accuracy: 0.8221 - val_loss: 0.4228 - val_accuracy: 0.8123\n",
      "Epoch 504/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4329 - accuracy: 0.8165 - val_loss: 0.4231 - val_accuracy: 0.8123\n",
      "Epoch 505/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4271 - accuracy: 0.8221 - val_loss: 0.4237 - val_accuracy: 0.8123\n",
      "Epoch 506/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4138 - accuracy: 0.8240 - val_loss: 0.4241 - val_accuracy: 0.8123\n",
      "Epoch 507/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4318 - accuracy: 0.8221 - val_loss: 0.4237 - val_accuracy: 0.8123\n",
      "Epoch 508/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4252 - accuracy: 0.8202 - val_loss: 0.4235 - val_accuracy: 0.8123\n",
      "Epoch 509/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4164 - accuracy: 0.8221 - val_loss: 0.4234 - val_accuracy: 0.8123\n",
      "Epoch 510/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4152 - accuracy: 0.8202 - val_loss: 0.4232 - val_accuracy: 0.8039\n",
      "Epoch 511/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4288 - accuracy: 0.8240 - val_loss: 0.4238 - val_accuracy: 0.8151\n",
      "Epoch 512/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4229 - accuracy: 0.8352 - val_loss: 0.4249 - val_accuracy: 0.8123\n",
      "Epoch 513/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4195 - accuracy: 0.8333 - val_loss: 0.4269 - val_accuracy: 0.8095\n",
      "Epoch 514/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4230 - accuracy: 0.8296 - val_loss: 0.4269 - val_accuracy: 0.8123\n",
      "Epoch 515/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4301 - accuracy: 0.8240 - val_loss: 0.4253 - val_accuracy: 0.8123\n",
      "Epoch 516/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4219 - accuracy: 0.8315 - val_loss: 0.4240 - val_accuracy: 0.8151\n",
      "Epoch 517/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4223 - accuracy: 0.8315 - val_loss: 0.4236 - val_accuracy: 0.8039\n",
      "Epoch 518/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4212 - accuracy: 0.8333 - val_loss: 0.4240 - val_accuracy: 0.8039\n",
      "Epoch 519/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4240 - accuracy: 0.8258 - val_loss: 0.4251 - val_accuracy: 0.8039\n",
      "Epoch 520/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4285 - accuracy: 0.8315 - val_loss: 0.4264 - val_accuracy: 0.8039\n",
      "Epoch 521/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4198 - accuracy: 0.8315 - val_loss: 0.4273 - val_accuracy: 0.8039\n",
      "Epoch 522/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4295 - accuracy: 0.8221 - val_loss: 0.4275 - val_accuracy: 0.8151\n",
      "Epoch 523/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4233 - accuracy: 0.8277 - val_loss: 0.4273 - val_accuracy: 0.8151\n",
      "Epoch 524/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4241 - accuracy: 0.8258 - val_loss: 0.4272 - val_accuracy: 0.8151\n",
      "Epoch 525/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4174 - accuracy: 0.8277 - val_loss: 0.4278 - val_accuracy: 0.8151\n",
      "Epoch 526/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4317 - accuracy: 0.8315 - val_loss: 0.4293 - val_accuracy: 0.8123\n",
      "Epoch 527/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4233 - accuracy: 0.8296 - val_loss: 0.4317 - val_accuracy: 0.8123\n",
      "Epoch 528/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4250 - accuracy: 0.8315 - val_loss: 0.4329 - val_accuracy: 0.8123\n",
      "Epoch 529/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4250 - accuracy: 0.8258 - val_loss: 0.4319 - val_accuracy: 0.8123\n",
      "Epoch 530/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4238 - accuracy: 0.8277 - val_loss: 0.4308 - val_accuracy: 0.8123\n",
      "Epoch 531/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4229 - accuracy: 0.8315 - val_loss: 0.4305 - val_accuracy: 0.8151\n",
      "Epoch 532/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4196 - accuracy: 0.8240 - val_loss: 0.4297 - val_accuracy: 0.8151\n",
      "Epoch 533/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4241 - accuracy: 0.8315 - val_loss: 0.4287 - val_accuracy: 0.8123\n",
      "Epoch 534/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4306 - accuracy: 0.8333 - val_loss: 0.4284 - val_accuracy: 0.8123\n",
      "Epoch 535/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4309 - accuracy: 0.8296 - val_loss: 0.4283 - val_accuracy: 0.8123\n",
      "Epoch 536/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4303 - accuracy: 0.8333 - val_loss: 0.4283 - val_accuracy: 0.8123\n",
      "Epoch 537/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4205 - accuracy: 0.8390 - val_loss: 0.4289 - val_accuracy: 0.8123\n",
      "Epoch 538/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4336 - accuracy: 0.8221 - val_loss: 0.4303 - val_accuracy: 0.8123\n",
      "Epoch 539/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4233 - accuracy: 0.8277 - val_loss: 0.4316 - val_accuracy: 0.8123\n",
      "Epoch 540/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4175 - accuracy: 0.8277 - val_loss: 0.4328 - val_accuracy: 0.8123\n",
      "Epoch 541/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4200 - accuracy: 0.8240 - val_loss: 0.4343 - val_accuracy: 0.8123\n",
      "Epoch 542/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4227 - accuracy: 0.8296 - val_loss: 0.4356 - val_accuracy: 0.8039\n",
      "Epoch 543/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4210 - accuracy: 0.8258 - val_loss: 0.4372 - val_accuracy: 0.8123\n",
      "Epoch 544/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4174 - accuracy: 0.8221 - val_loss: 0.4378 - val_accuracy: 0.8123\n",
      "Epoch 545/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4276 - accuracy: 0.8202 - val_loss: 0.4386 - val_accuracy: 0.7955\n",
      "Epoch 546/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4250 - accuracy: 0.8146 - val_loss: 0.4395 - val_accuracy: 0.7955\n",
      "Epoch 547/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4263 - accuracy: 0.8127 - val_loss: 0.4389 - val_accuracy: 0.7955\n",
      "Epoch 548/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4252 - accuracy: 0.8296 - val_loss: 0.4383 - val_accuracy: 0.8123\n",
      "Epoch 549/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4160 - accuracy: 0.8296 - val_loss: 0.4378 - val_accuracy: 0.8039\n",
      "Epoch 550/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4235 - accuracy: 0.8333 - val_loss: 0.4379 - val_accuracy: 0.8067\n",
      "Epoch 551/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4263 - accuracy: 0.8277 - val_loss: 0.4385 - val_accuracy: 0.8067\n",
      "Epoch 552/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4114 - accuracy: 0.8315 - val_loss: 0.4372 - val_accuracy: 0.8067\n",
      "Epoch 553/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4277 - accuracy: 0.8277 - val_loss: 0.4358 - val_accuracy: 0.8011\n",
      "Epoch 554/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4277 - accuracy: 0.8390 - val_loss: 0.4340 - val_accuracy: 0.8123\n",
      "Epoch 555/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4264 - accuracy: 0.8352 - val_loss: 0.4326 - val_accuracy: 0.8123\n",
      "Epoch 556/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4247 - accuracy: 0.8333 - val_loss: 0.4318 - val_accuracy: 0.8151\n",
      "Epoch 557/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4157 - accuracy: 0.8371 - val_loss: 0.4313 - val_accuracy: 0.8151\n",
      "Epoch 558/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4276 - accuracy: 0.8184 - val_loss: 0.4312 - val_accuracy: 0.8151\n",
      "Epoch 559/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4225 - accuracy: 0.8315 - val_loss: 0.4316 - val_accuracy: 0.8151\n",
      "Epoch 560/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4244 - accuracy: 0.8221 - val_loss: 0.4323 - val_accuracy: 0.8039\n",
      "Epoch 561/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4280 - accuracy: 0.8184 - val_loss: 0.4327 - val_accuracy: 0.8151\n",
      "Epoch 562/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4242 - accuracy: 0.8221 - val_loss: 0.4330 - val_accuracy: 0.8151\n",
      "Epoch 563/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4242 - accuracy: 0.8184 - val_loss: 0.4335 - val_accuracy: 0.8151\n",
      "Epoch 564/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4250 - accuracy: 0.8221 - val_loss: 0.4341 - val_accuracy: 0.8123\n",
      "Epoch 565/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4257 - accuracy: 0.8277 - val_loss: 0.4350 - val_accuracy: 0.8095\n",
      "Epoch 566/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4259 - accuracy: 0.8333 - val_loss: 0.4363 - val_accuracy: 0.8095\n",
      "Epoch 567/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4239 - accuracy: 0.8258 - val_loss: 0.4380 - val_accuracy: 0.8095\n",
      "Epoch 568/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4254 - accuracy: 0.8277 - val_loss: 0.4387 - val_accuracy: 0.8095\n",
      "Epoch 569/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4215 - accuracy: 0.8240 - val_loss: 0.4389 - val_accuracy: 0.8095\n",
      "Epoch 570/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4324 - accuracy: 0.8202 - val_loss: 0.4372 - val_accuracy: 0.8095\n",
      "Epoch 571/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4247 - accuracy: 0.8333 - val_loss: 0.4354 - val_accuracy: 0.8095\n",
      "Epoch 572/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4151 - accuracy: 0.8258 - val_loss: 0.4336 - val_accuracy: 0.8123\n",
      "Epoch 573/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4204 - accuracy: 0.8202 - val_loss: 0.4314 - val_accuracy: 0.8123\n",
      "Epoch 574/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4142 - accuracy: 0.8390 - val_loss: 0.4309 - val_accuracy: 0.8123\n",
      "Epoch 575/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4271 - accuracy: 0.8333 - val_loss: 0.4317 - val_accuracy: 0.8123\n",
      "Epoch 576/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4196 - accuracy: 0.8333 - val_loss: 0.4325 - val_accuracy: 0.8011\n",
      "Epoch 577/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4272 - accuracy: 0.8240 - val_loss: 0.4328 - val_accuracy: 0.8039\n",
      "Epoch 578/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4282 - accuracy: 0.8277 - val_loss: 0.4330 - val_accuracy: 0.8039\n",
      "Epoch 579/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4243 - accuracy: 0.8165 - val_loss: 0.4324 - val_accuracy: 0.8039\n",
      "Epoch 580/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4284 - accuracy: 0.8296 - val_loss: 0.4313 - val_accuracy: 0.8011\n",
      "Epoch 581/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4260 - accuracy: 0.8277 - val_loss: 0.4310 - val_accuracy: 0.8011\n",
      "Epoch 582/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4234 - accuracy: 0.8165 - val_loss: 0.4308 - val_accuracy: 0.8011\n",
      "Epoch 583/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4204 - accuracy: 0.8371 - val_loss: 0.4305 - val_accuracy: 0.8011\n",
      "Epoch 584/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4210 - accuracy: 0.8277 - val_loss: 0.4300 - val_accuracy: 0.8011\n",
      "Epoch 585/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4217 - accuracy: 0.8221 - val_loss: 0.4302 - val_accuracy: 0.8011\n",
      "Epoch 586/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4168 - accuracy: 0.8221 - val_loss: 0.4313 - val_accuracy: 0.8011\n",
      "Epoch 587/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4090 - accuracy: 0.8390 - val_loss: 0.4317 - val_accuracy: 0.7983\n",
      "Epoch 588/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4272 - accuracy: 0.8277 - val_loss: 0.4311 - val_accuracy: 0.8095\n",
      "Epoch 589/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4294 - accuracy: 0.8221 - val_loss: 0.4306 - val_accuracy: 0.8095\n",
      "Epoch 590/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4165 - accuracy: 0.8258 - val_loss: 0.4306 - val_accuracy: 0.8095\n",
      "Epoch 591/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4307 - accuracy: 0.8258 - val_loss: 0.4303 - val_accuracy: 0.8095\n",
      "Epoch 592/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4326 - accuracy: 0.8221 - val_loss: 0.4308 - val_accuracy: 0.7983\n",
      "Epoch 593/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4212 - accuracy: 0.8258 - val_loss: 0.4326 - val_accuracy: 0.8095\n",
      "Epoch 594/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4184 - accuracy: 0.8333 - val_loss: 0.4344 - val_accuracy: 0.8123\n",
      "Epoch 595/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4311 - accuracy: 0.8371 - val_loss: 0.4341 - val_accuracy: 0.7955\n",
      "Epoch 596/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4269 - accuracy: 0.8202 - val_loss: 0.4322 - val_accuracy: 0.8123\n",
      "Epoch 597/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4310 - accuracy: 0.8109 - val_loss: 0.4302 - val_accuracy: 0.8067\n",
      "Epoch 598/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4231 - accuracy: 0.8277 - val_loss: 0.4301 - val_accuracy: 0.7983\n",
      "Epoch 599/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4312 - accuracy: 0.8240 - val_loss: 0.4308 - val_accuracy: 0.7983\n",
      "Epoch 600/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4235 - accuracy: 0.8221 - val_loss: 0.4318 - val_accuracy: 0.7983\n",
      "Epoch 601/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4231 - accuracy: 0.8315 - val_loss: 0.4322 - val_accuracy: 0.7983\n",
      "Epoch 602/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4271 - accuracy: 0.8296 - val_loss: 0.4324 - val_accuracy: 0.7983\n",
      "Epoch 603/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4309 - accuracy: 0.8277 - val_loss: 0.4324 - val_accuracy: 0.8095\n",
      "Epoch 604/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4218 - accuracy: 0.8277 - val_loss: 0.4323 - val_accuracy: 0.8095\n",
      "Epoch 605/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4217 - accuracy: 0.8221 - val_loss: 0.4323 - val_accuracy: 0.8095\n",
      "Epoch 606/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4237 - accuracy: 0.8277 - val_loss: 0.4320 - val_accuracy: 0.8095\n",
      "Epoch 607/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4133 - accuracy: 0.8333 - val_loss: 0.4317 - val_accuracy: 0.7983\n",
      "Epoch 608/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4126 - accuracy: 0.8258 - val_loss: 0.4321 - val_accuracy: 0.8067\n",
      "Epoch 609/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4243 - accuracy: 0.8315 - val_loss: 0.4318 - val_accuracy: 0.8095\n",
      "Epoch 610/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4252 - accuracy: 0.8315 - val_loss: 0.4319 - val_accuracy: 0.8123\n",
      "Epoch 611/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4288 - accuracy: 0.8277 - val_loss: 0.4323 - val_accuracy: 0.8123\n",
      "Epoch 612/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4193 - accuracy: 0.8277 - val_loss: 0.4323 - val_accuracy: 0.8123\n",
      "Epoch 613/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4352 - accuracy: 0.8296 - val_loss: 0.4322 - val_accuracy: 0.8123\n",
      "Epoch 614/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4200 - accuracy: 0.8277 - val_loss: 0.4321 - val_accuracy: 0.8095\n",
      "Epoch 615/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4303 - accuracy: 0.8240 - val_loss: 0.4326 - val_accuracy: 0.8095\n",
      "Epoch 616/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4164 - accuracy: 0.8296 - val_loss: 0.4330 - val_accuracy: 0.8095\n",
      "Epoch 617/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4240 - accuracy: 0.8296 - val_loss: 0.4324 - val_accuracy: 0.8095\n",
      "Epoch 618/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4273 - accuracy: 0.8202 - val_loss: 0.4320 - val_accuracy: 0.8095\n",
      "Epoch 619/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4142 - accuracy: 0.8315 - val_loss: 0.4314 - val_accuracy: 0.8095\n",
      "Epoch 620/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4220 - accuracy: 0.8202 - val_loss: 0.4309 - val_accuracy: 0.8123\n",
      "Epoch 621/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4302 - accuracy: 0.8258 - val_loss: 0.4306 - val_accuracy: 0.8123\n",
      "Epoch 622/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4218 - accuracy: 0.8296 - val_loss: 0.4307 - val_accuracy: 0.8207\n",
      "Epoch 623/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4255 - accuracy: 0.8258 - val_loss: 0.4310 - val_accuracy: 0.8095\n",
      "Epoch 624/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4241 - accuracy: 0.8315 - val_loss: 0.4312 - val_accuracy: 0.8095\n",
      "Epoch 625/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4269 - accuracy: 0.8296 - val_loss: 0.4317 - val_accuracy: 0.8095\n",
      "Epoch 626/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4236 - accuracy: 0.8240 - val_loss: 0.4323 - val_accuracy: 0.8095\n",
      "Epoch 627/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4182 - accuracy: 0.8296 - val_loss: 0.4316 - val_accuracy: 0.8067\n",
      "Epoch 628/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4278 - accuracy: 0.8277 - val_loss: 0.4314 - val_accuracy: 0.8067\n",
      "Epoch 629/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4231 - accuracy: 0.8258 - val_loss: 0.4316 - val_accuracy: 0.8067\n",
      "Epoch 630/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4295 - accuracy: 0.8277 - val_loss: 0.4321 - val_accuracy: 0.8067\n",
      "Epoch 631/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4218 - accuracy: 0.8258 - val_loss: 0.4330 - val_accuracy: 0.7983\n",
      "Epoch 632/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4198 - accuracy: 0.8258 - val_loss: 0.4345 - val_accuracy: 0.8095\n",
      "Epoch 633/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4202 - accuracy: 0.8352 - val_loss: 0.4381 - val_accuracy: 0.8095\n",
      "Epoch 634/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4092 - accuracy: 0.8315 - val_loss: 0.4417 - val_accuracy: 0.8095\n",
      "Epoch 635/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4220 - accuracy: 0.8315 - val_loss: 0.4433 - val_accuracy: 0.8095\n",
      "Epoch 636/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4256 - accuracy: 0.8296 - val_loss: 0.4430 - val_accuracy: 0.8095\n",
      "Epoch 637/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4222 - accuracy: 0.8352 - val_loss: 0.4414 - val_accuracy: 0.8095\n",
      "Epoch 638/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4089 - accuracy: 0.8315 - val_loss: 0.4410 - val_accuracy: 0.8011\n",
      "Epoch 639/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4183 - accuracy: 0.8258 - val_loss: 0.4427 - val_accuracy: 0.8123\n",
      "Epoch 640/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4342 - accuracy: 0.8165 - val_loss: 0.4443 - val_accuracy: 0.7955\n",
      "Epoch 641/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4163 - accuracy: 0.8390 - val_loss: 0.4445 - val_accuracy: 0.7955\n",
      "Epoch 642/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4255 - accuracy: 0.8296 - val_loss: 0.4431 - val_accuracy: 0.7955\n",
      "Epoch 643/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4223 - accuracy: 0.8184 - val_loss: 0.4414 - val_accuracy: 0.8123\n",
      "Epoch 644/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4303 - accuracy: 0.8165 - val_loss: 0.4409 - val_accuracy: 0.8123\n",
      "Epoch 645/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4273 - accuracy: 0.8127 - val_loss: 0.4402 - val_accuracy: 0.8123\n",
      "Epoch 646/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4340 - accuracy: 0.8146 - val_loss: 0.4382 - val_accuracy: 0.8123\n",
      "Epoch 647/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4191 - accuracy: 0.8333 - val_loss: 0.4364 - val_accuracy: 0.8039\n",
      "Epoch 648/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4167 - accuracy: 0.8296 - val_loss: 0.4359 - val_accuracy: 0.8039\n",
      "Epoch 649/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4224 - accuracy: 0.8258 - val_loss: 0.4355 - val_accuracy: 0.8039\n",
      "Epoch 650/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4138 - accuracy: 0.8296 - val_loss: 0.4352 - val_accuracy: 0.8151\n",
      "Epoch 651/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4284 - accuracy: 0.8296 - val_loss: 0.4351 - val_accuracy: 0.8151\n",
      "Epoch 652/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4250 - accuracy: 0.8315 - val_loss: 0.4352 - val_accuracy: 0.8123\n",
      "Epoch 653/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4235 - accuracy: 0.8296 - val_loss: 0.4351 - val_accuracy: 0.8011\n",
      "Epoch 654/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4255 - accuracy: 0.8296 - val_loss: 0.4353 - val_accuracy: 0.8039\n",
      "Epoch 655/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4099 - accuracy: 0.8333 - val_loss: 0.4362 - val_accuracy: 0.8123\n",
      "Epoch 656/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4154 - accuracy: 0.8296 - val_loss: 0.4377 - val_accuracy: 0.8123\n",
      "Epoch 657/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4309 - accuracy: 0.8277 - val_loss: 0.4378 - val_accuracy: 0.8123\n",
      "Epoch 658/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4384 - accuracy: 0.8315 - val_loss: 0.4361 - val_accuracy: 0.8123\n",
      "Epoch 659/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4199 - accuracy: 0.8296 - val_loss: 0.4358 - val_accuracy: 0.8123\n",
      "Epoch 660/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4219 - accuracy: 0.8221 - val_loss: 0.4354 - val_accuracy: 0.8123\n",
      "Epoch 661/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4225 - accuracy: 0.8296 - val_loss: 0.4348 - val_accuracy: 0.8123\n",
      "Epoch 662/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4173 - accuracy: 0.8277 - val_loss: 0.4340 - val_accuracy: 0.8123\n",
      "Epoch 663/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4268 - accuracy: 0.8184 - val_loss: 0.4333 - val_accuracy: 0.8095\n",
      "Epoch 664/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4210 - accuracy: 0.8315 - val_loss: 0.4323 - val_accuracy: 0.8179\n",
      "Epoch 665/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4161 - accuracy: 0.8352 - val_loss: 0.4321 - val_accuracy: 0.8179\n",
      "Epoch 666/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4290 - accuracy: 0.8240 - val_loss: 0.4312 - val_accuracy: 0.8095\n",
      "Epoch 667/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4140 - accuracy: 0.8315 - val_loss: 0.4310 - val_accuracy: 0.8095\n",
      "Epoch 668/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4198 - accuracy: 0.8296 - val_loss: 0.4318 - val_accuracy: 0.8179\n",
      "Epoch 669/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4262 - accuracy: 0.8221 - val_loss: 0.4332 - val_accuracy: 0.8207\n",
      "Epoch 670/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4377 - accuracy: 0.8202 - val_loss: 0.4341 - val_accuracy: 0.8095\n",
      "Epoch 671/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4262 - accuracy: 0.8221 - val_loss: 0.4329 - val_accuracy: 0.8095\n",
      "Epoch 672/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4168 - accuracy: 0.8315 - val_loss: 0.4313 - val_accuracy: 0.8207\n",
      "Epoch 673/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4275 - accuracy: 0.8146 - val_loss: 0.4304 - val_accuracy: 0.8095\n",
      "Epoch 674/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4153 - accuracy: 0.8240 - val_loss: 0.4303 - val_accuracy: 0.8095\n",
      "Epoch 675/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4232 - accuracy: 0.8315 - val_loss: 0.4309 - val_accuracy: 0.8095\n",
      "Epoch 676/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4192 - accuracy: 0.8296 - val_loss: 0.4320 - val_accuracy: 0.8095\n",
      "Epoch 677/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4162 - accuracy: 0.8333 - val_loss: 0.4336 - val_accuracy: 0.8095\n",
      "Epoch 678/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4229 - accuracy: 0.8277 - val_loss: 0.4355 - val_accuracy: 0.8095\n",
      "Epoch 679/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4307 - accuracy: 0.8296 - val_loss: 0.4377 - val_accuracy: 0.8095\n",
      "Epoch 680/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4222 - accuracy: 0.8277 - val_loss: 0.4406 - val_accuracy: 0.8151\n",
      "Epoch 681/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4233 - accuracy: 0.8258 - val_loss: 0.4443 - val_accuracy: 0.8123\n",
      "Epoch 682/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4177 - accuracy: 0.8240 - val_loss: 0.4471 - val_accuracy: 0.7955\n",
      "Epoch 683/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4223 - accuracy: 0.8296 - val_loss: 0.4451 - val_accuracy: 0.7955\n",
      "Epoch 684/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4212 - accuracy: 0.8258 - val_loss: 0.4377 - val_accuracy: 0.8123\n",
      "Epoch 685/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4264 - accuracy: 0.8127 - val_loss: 0.4307 - val_accuracy: 0.8011\n",
      "Epoch 686/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4182 - accuracy: 0.8277 - val_loss: 0.4281 - val_accuracy: 0.8095\n",
      "Epoch 687/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4224 - accuracy: 0.8333 - val_loss: 0.4274 - val_accuracy: 0.8095\n",
      "Epoch 688/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4168 - accuracy: 0.8277 - val_loss: 0.4271 - val_accuracy: 0.8095\n",
      "Epoch 689/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4328 - accuracy: 0.8240 - val_loss: 0.4272 - val_accuracy: 0.8095\n",
      "Epoch 690/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4204 - accuracy: 0.8333 - val_loss: 0.4274 - val_accuracy: 0.8123\n",
      "Epoch 691/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4204 - accuracy: 0.8240 - val_loss: 0.4276 - val_accuracy: 0.8011\n",
      "Epoch 692/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4334 - accuracy: 0.8352 - val_loss: 0.4283 - val_accuracy: 0.8039\n",
      "Epoch 693/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4234 - accuracy: 0.8277 - val_loss: 0.4278 - val_accuracy: 0.8039\n",
      "Epoch 694/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4224 - accuracy: 0.8202 - val_loss: 0.4273 - val_accuracy: 0.8011\n",
      "Epoch 695/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4139 - accuracy: 0.8352 - val_loss: 0.4273 - val_accuracy: 0.8011\n",
      "Epoch 696/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4292 - accuracy: 0.8315 - val_loss: 0.4281 - val_accuracy: 0.8123\n",
      "Epoch 697/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4215 - accuracy: 0.8258 - val_loss: 0.4288 - val_accuracy: 0.8123\n",
      "Epoch 698/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4301 - accuracy: 0.8277 - val_loss: 0.4292 - val_accuracy: 0.8123\n",
      "Epoch 699/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4280 - accuracy: 0.8258 - val_loss: 0.4292 - val_accuracy: 0.8123\n",
      "Epoch 700/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4213 - accuracy: 0.8352 - val_loss: 0.4296 - val_accuracy: 0.8123\n",
      "Epoch 701/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4284 - accuracy: 0.8240 - val_loss: 0.4309 - val_accuracy: 0.8011\n",
      "Epoch 702/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4254 - accuracy: 0.8352 - val_loss: 0.4324 - val_accuracy: 0.8039\n",
      "Epoch 703/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4244 - accuracy: 0.8296 - val_loss: 0.4346 - val_accuracy: 0.7955\n",
      "Epoch 704/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4162 - accuracy: 0.8258 - val_loss: 0.4375 - val_accuracy: 0.7955\n",
      "Epoch 705/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4221 - accuracy: 0.8240 - val_loss: 0.4394 - val_accuracy: 0.7955\n",
      "Epoch 706/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4345 - accuracy: 0.8165 - val_loss: 0.4389 - val_accuracy: 0.7955\n",
      "Epoch 707/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4376 - accuracy: 0.8034 - val_loss: 0.4360 - val_accuracy: 0.7955\n",
      "Epoch 708/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4227 - accuracy: 0.8277 - val_loss: 0.4321 - val_accuracy: 0.7955\n",
      "Epoch 709/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4261 - accuracy: 0.8315 - val_loss: 0.4297 - val_accuracy: 0.8039\n",
      "Epoch 710/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4140 - accuracy: 0.8258 - val_loss: 0.4302 - val_accuracy: 0.8039\n",
      "Epoch 711/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4198 - accuracy: 0.8371 - val_loss: 0.4319 - val_accuracy: 0.8123\n",
      "Epoch 712/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4235 - accuracy: 0.8315 - val_loss: 0.4337 - val_accuracy: 0.8095\n",
      "Epoch 713/1000\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.4294 - accuracy: 0.8315 - val_loss: 0.4348 - val_accuracy: 0.8095\n",
      "Epoch 714/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4227 - accuracy: 0.8221 - val_loss: 0.4364 - val_accuracy: 0.8123\n",
      "Epoch 715/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4231 - accuracy: 0.8277 - val_loss: 0.4385 - val_accuracy: 0.8123\n",
      "Epoch 716/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4214 - accuracy: 0.8296 - val_loss: 0.4398 - val_accuracy: 0.8095\n",
      "Epoch 717/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4234 - accuracy: 0.8333 - val_loss: 0.4397 - val_accuracy: 0.8095\n",
      "Epoch 718/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4277 - accuracy: 0.8277 - val_loss: 0.4385 - val_accuracy: 0.8095\n",
      "Epoch 719/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4248 - accuracy: 0.8296 - val_loss: 0.4379 - val_accuracy: 0.8123\n",
      "Epoch 720/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4257 - accuracy: 0.8352 - val_loss: 0.4381 - val_accuracy: 0.8123\n",
      "Epoch 721/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4266 - accuracy: 0.8221 - val_loss: 0.4379 - val_accuracy: 0.8123\n",
      "Epoch 722/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4103 - accuracy: 0.8315 - val_loss: 0.4374 - val_accuracy: 0.8151\n",
      "Epoch 723/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4257 - accuracy: 0.8352 - val_loss: 0.4374 - val_accuracy: 0.8151\n",
      "Epoch 724/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4127 - accuracy: 0.8296 - val_loss: 0.4368 - val_accuracy: 0.8039\n",
      "Epoch 725/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4136 - accuracy: 0.8296 - val_loss: 0.4373 - val_accuracy: 0.8039\n",
      "Epoch 726/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4333 - accuracy: 0.8240 - val_loss: 0.4389 - val_accuracy: 0.8039\n",
      "Epoch 727/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4253 - accuracy: 0.8315 - val_loss: 0.4402 - val_accuracy: 0.8039\n",
      "Epoch 728/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4278 - accuracy: 0.8352 - val_loss: 0.4403 - val_accuracy: 0.8039\n",
      "Epoch 729/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4161 - accuracy: 0.8371 - val_loss: 0.4393 - val_accuracy: 0.8039\n",
      "Epoch 730/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4314 - accuracy: 0.8296 - val_loss: 0.4370 - val_accuracy: 0.8039\n",
      "Epoch 731/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4268 - accuracy: 0.8221 - val_loss: 0.4357 - val_accuracy: 0.8039\n",
      "Epoch 732/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4166 - accuracy: 0.8371 - val_loss: 0.4342 - val_accuracy: 0.8039\n",
      "Epoch 733/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4233 - accuracy: 0.8333 - val_loss: 0.4324 - val_accuracy: 0.8039\n",
      "Epoch 734/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4225 - accuracy: 0.8258 - val_loss: 0.4305 - val_accuracy: 0.8151\n",
      "Epoch 735/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4236 - accuracy: 0.8296 - val_loss: 0.4280 - val_accuracy: 0.8151\n",
      "Epoch 736/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4210 - accuracy: 0.8315 - val_loss: 0.4265 - val_accuracy: 0.8151\n",
      "Epoch 737/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4202 - accuracy: 0.8240 - val_loss: 0.4252 - val_accuracy: 0.8151\n",
      "Epoch 738/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4201 - accuracy: 0.8315 - val_loss: 0.4251 - val_accuracy: 0.8151\n",
      "Epoch 739/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4255 - accuracy: 0.8315 - val_loss: 0.4257 - val_accuracy: 0.8151\n",
      "Epoch 740/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4281 - accuracy: 0.8240 - val_loss: 0.4271 - val_accuracy: 0.8123\n",
      "Epoch 741/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4265 - accuracy: 0.8240 - val_loss: 0.4284 - val_accuracy: 0.8123\n",
      "Epoch 742/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4343 - accuracy: 0.8165 - val_loss: 0.4291 - val_accuracy: 0.8039\n",
      "Epoch 743/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4165 - accuracy: 0.8277 - val_loss: 0.4289 - val_accuracy: 0.8011\n",
      "Epoch 744/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4193 - accuracy: 0.8240 - val_loss: 0.4286 - val_accuracy: 0.8011\n",
      "Epoch 745/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4259 - accuracy: 0.8240 - val_loss: 0.4292 - val_accuracy: 0.8011\n",
      "Epoch 746/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4284 - accuracy: 0.8333 - val_loss: 0.4312 - val_accuracy: 0.8123\n",
      "Epoch 747/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4166 - accuracy: 0.8315 - val_loss: 0.4326 - val_accuracy: 0.8123\n",
      "Epoch 748/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4206 - accuracy: 0.8258 - val_loss: 0.4333 - val_accuracy: 0.8123\n",
      "Epoch 749/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4171 - accuracy: 0.8333 - val_loss: 0.4344 - val_accuracy: 0.8011\n",
      "Epoch 750/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4209 - accuracy: 0.8240 - val_loss: 0.4363 - val_accuracy: 0.8011\n",
      "Epoch 751/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4284 - accuracy: 0.8296 - val_loss: 0.4384 - val_accuracy: 0.8011\n",
      "Epoch 752/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4235 - accuracy: 0.8165 - val_loss: 0.4402 - val_accuracy: 0.8011\n",
      "Epoch 753/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4269 - accuracy: 0.8296 - val_loss: 0.4409 - val_accuracy: 0.8011\n",
      "Epoch 754/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4138 - accuracy: 0.8240 - val_loss: 0.4408 - val_accuracy: 0.8011\n",
      "Epoch 755/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4160 - accuracy: 0.8277 - val_loss: 0.4401 - val_accuracy: 0.8123\n",
      "Epoch 756/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4229 - accuracy: 0.8277 - val_loss: 0.4397 - val_accuracy: 0.8123\n",
      "Epoch 757/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4145 - accuracy: 0.8315 - val_loss: 0.4393 - val_accuracy: 0.8123\n",
      "Epoch 758/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4119 - accuracy: 0.8390 - val_loss: 0.4389 - val_accuracy: 0.8123\n",
      "Epoch 759/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4254 - accuracy: 0.8277 - val_loss: 0.4392 - val_accuracy: 0.8039\n",
      "Epoch 760/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4192 - accuracy: 0.8333 - val_loss: 0.4404 - val_accuracy: 0.8039\n",
      "Epoch 761/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4220 - accuracy: 0.8221 - val_loss: 0.4405 - val_accuracy: 0.8123\n",
      "Epoch 762/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4249 - accuracy: 0.8277 - val_loss: 0.4387 - val_accuracy: 0.8123\n",
      "Epoch 763/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4228 - accuracy: 0.8221 - val_loss: 0.4366 - val_accuracy: 0.8039\n",
      "Epoch 764/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4152 - accuracy: 0.8333 - val_loss: 0.4356 - val_accuracy: 0.8039\n",
      "Epoch 765/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4212 - accuracy: 0.8315 - val_loss: 0.4352 - val_accuracy: 0.8039\n",
      "Epoch 766/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4243 - accuracy: 0.8296 - val_loss: 0.4348 - val_accuracy: 0.8039\n",
      "Epoch 767/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4270 - accuracy: 0.8184 - val_loss: 0.4349 - val_accuracy: 0.8123\n",
      "Epoch 768/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4221 - accuracy: 0.8202 - val_loss: 0.4345 - val_accuracy: 0.8123\n",
      "Epoch 769/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4245 - accuracy: 0.8277 - val_loss: 0.4339 - val_accuracy: 0.8123\n",
      "Epoch 770/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4264 - accuracy: 0.8296 - val_loss: 0.4345 - val_accuracy: 0.8123\n",
      "Epoch 771/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4102 - accuracy: 0.8277 - val_loss: 0.4370 - val_accuracy: 0.8039\n",
      "Epoch 772/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4271 - accuracy: 0.8240 - val_loss: 0.4413 - val_accuracy: 0.8039\n",
      "Epoch 773/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4186 - accuracy: 0.8333 - val_loss: 0.4457 - val_accuracy: 0.8039\n",
      "Epoch 774/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4227 - accuracy: 0.8258 - val_loss: 0.4495 - val_accuracy: 0.8039\n",
      "Epoch 775/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4287 - accuracy: 0.8165 - val_loss: 0.4510 - val_accuracy: 0.8123\n",
      "Epoch 776/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4189 - accuracy: 0.8240 - val_loss: 0.4494 - val_accuracy: 0.8011\n",
      "Epoch 777/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4217 - accuracy: 0.8277 - val_loss: 0.4475 - val_accuracy: 0.8011\n",
      "Epoch 778/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4254 - accuracy: 0.8258 - val_loss: 0.4468 - val_accuracy: 0.8011\n",
      "Epoch 779/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4156 - accuracy: 0.8240 - val_loss: 0.4445 - val_accuracy: 0.8011\n",
      "Epoch 780/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4250 - accuracy: 0.8333 - val_loss: 0.4403 - val_accuracy: 0.8095\n",
      "Epoch 781/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4216 - accuracy: 0.8352 - val_loss: 0.4366 - val_accuracy: 0.8095\n",
      "Epoch 782/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4111 - accuracy: 0.8333 - val_loss: 0.4337 - val_accuracy: 0.7983\n",
      "Epoch 783/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4124 - accuracy: 0.8333 - val_loss: 0.4318 - val_accuracy: 0.8011\n",
      "Epoch 784/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4374 - accuracy: 0.8258 - val_loss: 0.4316 - val_accuracy: 0.8011\n",
      "Epoch 785/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4208 - accuracy: 0.8371 - val_loss: 0.4325 - val_accuracy: 0.8011\n",
      "Epoch 786/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4258 - accuracy: 0.8240 - val_loss: 0.4333 - val_accuracy: 0.8011\n",
      "Epoch 787/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4222 - accuracy: 0.8277 - val_loss: 0.4343 - val_accuracy: 0.8123\n",
      "Epoch 788/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4155 - accuracy: 0.8315 - val_loss: 0.4355 - val_accuracy: 0.8095\n",
      "Epoch 789/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4230 - accuracy: 0.8390 - val_loss: 0.4378 - val_accuracy: 0.8095\n",
      "Epoch 790/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4182 - accuracy: 0.8333 - val_loss: 0.4410 - val_accuracy: 0.8095\n",
      "Epoch 791/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4280 - accuracy: 0.8296 - val_loss: 0.4433 - val_accuracy: 0.8095\n",
      "Epoch 792/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4273 - accuracy: 0.8240 - val_loss: 0.4438 - val_accuracy: 0.8095\n",
      "Epoch 793/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4325 - accuracy: 0.8277 - val_loss: 0.4434 - val_accuracy: 0.8095\n",
      "Epoch 794/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4273 - accuracy: 0.8240 - val_loss: 0.4409 - val_accuracy: 0.8123\n",
      "Epoch 795/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4236 - accuracy: 0.8202 - val_loss: 0.4388 - val_accuracy: 0.8123\n",
      "Epoch 796/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4282 - accuracy: 0.8258 - val_loss: 0.4363 - val_accuracy: 0.8123\n",
      "Epoch 797/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4150 - accuracy: 0.8296 - val_loss: 0.4342 - val_accuracy: 0.8123\n",
      "Epoch 798/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4118 - accuracy: 0.8315 - val_loss: 0.4327 - val_accuracy: 0.8011\n",
      "Epoch 799/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4190 - accuracy: 0.8165 - val_loss: 0.4327 - val_accuracy: 0.8011\n",
      "Epoch 800/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4230 - accuracy: 0.8165 - val_loss: 0.4328 - val_accuracy: 0.8095\n",
      "Epoch 801/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4266 - accuracy: 0.8165 - val_loss: 0.4318 - val_accuracy: 0.8011\n",
      "Epoch 802/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4274 - accuracy: 0.8296 - val_loss: 0.4310 - val_accuracy: 0.8011\n",
      "Epoch 803/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4210 - accuracy: 0.8221 - val_loss: 0.4309 - val_accuracy: 0.8011\n",
      "Epoch 804/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4287 - accuracy: 0.8221 - val_loss: 0.4314 - val_accuracy: 0.8095\n",
      "Epoch 805/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4202 - accuracy: 0.8277 - val_loss: 0.4318 - val_accuracy: 0.7983\n",
      "Epoch 806/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4221 - accuracy: 0.8258 - val_loss: 0.4318 - val_accuracy: 0.7983\n",
      "Epoch 807/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4224 - accuracy: 0.8258 - val_loss: 0.4314 - val_accuracy: 0.8095\n",
      "Epoch 808/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4170 - accuracy: 0.8240 - val_loss: 0.4311 - val_accuracy: 0.8095\n",
      "Epoch 809/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4318 - accuracy: 0.8202 - val_loss: 0.4311 - val_accuracy: 0.8095\n",
      "Epoch 810/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4263 - accuracy: 0.8277 - val_loss: 0.4322 - val_accuracy: 0.8095\n",
      "Epoch 811/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4285 - accuracy: 0.8240 - val_loss: 0.4336 - val_accuracy: 0.8067\n",
      "Epoch 812/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4198 - accuracy: 0.8184 - val_loss: 0.4346 - val_accuracy: 0.8067\n",
      "Epoch 813/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4242 - accuracy: 0.8258 - val_loss: 0.4346 - val_accuracy: 0.8067\n",
      "Epoch 814/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4206 - accuracy: 0.8221 - val_loss: 0.4333 - val_accuracy: 0.8179\n",
      "Epoch 815/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4236 - accuracy: 0.8202 - val_loss: 0.4315 - val_accuracy: 0.8095\n",
      "Epoch 816/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4313 - accuracy: 0.8184 - val_loss: 0.4303 - val_accuracy: 0.8095\n",
      "Epoch 817/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4196 - accuracy: 0.8333 - val_loss: 0.4292 - val_accuracy: 0.8095\n",
      "Epoch 818/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4095 - accuracy: 0.8371 - val_loss: 0.4288 - val_accuracy: 0.8067\n",
      "Epoch 819/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4287 - accuracy: 0.8240 - val_loss: 0.4291 - val_accuracy: 0.8095\n",
      "Epoch 820/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4224 - accuracy: 0.8202 - val_loss: 0.4300 - val_accuracy: 0.8123\n",
      "Epoch 821/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4177 - accuracy: 0.8202 - val_loss: 0.4313 - val_accuracy: 0.8123\n",
      "Epoch 822/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4145 - accuracy: 0.8315 - val_loss: 0.4313 - val_accuracy: 0.7955\n",
      "Epoch 823/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4270 - accuracy: 0.8258 - val_loss: 0.4300 - val_accuracy: 0.7955\n",
      "Epoch 824/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4087 - accuracy: 0.8352 - val_loss: 0.4287 - val_accuracy: 0.8123\n",
      "Epoch 825/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4199 - accuracy: 0.8277 - val_loss: 0.4269 - val_accuracy: 0.8123\n",
      "Epoch 826/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4125 - accuracy: 0.8296 - val_loss: 0.4260 - val_accuracy: 0.8011\n",
      "Epoch 827/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4181 - accuracy: 0.8221 - val_loss: 0.4262 - val_accuracy: 0.8123\n",
      "Epoch 828/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4201 - accuracy: 0.8277 - val_loss: 0.4260 - val_accuracy: 0.8123\n",
      "Epoch 829/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4271 - accuracy: 0.8240 - val_loss: 0.4247 - val_accuracy: 0.8123\n",
      "Epoch 830/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4139 - accuracy: 0.8333 - val_loss: 0.4231 - val_accuracy: 0.8123\n",
      "Epoch 831/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4260 - accuracy: 0.8258 - val_loss: 0.4216 - val_accuracy: 0.8123\n",
      "Epoch 832/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4211 - accuracy: 0.8315 - val_loss: 0.4211 - val_accuracy: 0.8123\n",
      "Epoch 833/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4188 - accuracy: 0.8240 - val_loss: 0.4209 - val_accuracy: 0.8039\n",
      "Epoch 834/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4137 - accuracy: 0.8258 - val_loss: 0.4211 - val_accuracy: 0.8039\n",
      "Epoch 835/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4291 - accuracy: 0.8240 - val_loss: 0.4214 - val_accuracy: 0.8039\n",
      "Epoch 836/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4183 - accuracy: 0.8221 - val_loss: 0.4221 - val_accuracy: 0.8039\n",
      "Epoch 837/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4185 - accuracy: 0.8277 - val_loss: 0.4235 - val_accuracy: 0.8039\n",
      "Epoch 838/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4246 - accuracy: 0.8258 - val_loss: 0.4256 - val_accuracy: 0.8039\n",
      "Epoch 839/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4106 - accuracy: 0.8333 - val_loss: 0.4274 - val_accuracy: 0.8123\n",
      "Epoch 840/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4296 - accuracy: 0.8240 - val_loss: 0.4272 - val_accuracy: 0.8039\n",
      "Epoch 841/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4285 - accuracy: 0.8277 - val_loss: 0.4247 - val_accuracy: 0.8039\n",
      "Epoch 842/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4219 - accuracy: 0.8258 - val_loss: 0.4232 - val_accuracy: 0.8011\n",
      "Epoch 843/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4167 - accuracy: 0.8221 - val_loss: 0.4226 - val_accuracy: 0.8123\n",
      "Epoch 844/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4289 - accuracy: 0.8296 - val_loss: 0.4227 - val_accuracy: 0.8095\n",
      "Epoch 845/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4172 - accuracy: 0.8408 - val_loss: 0.4232 - val_accuracy: 0.8095\n",
      "Epoch 846/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4315 - accuracy: 0.8221 - val_loss: 0.4239 - val_accuracy: 0.8095\n",
      "Epoch 847/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4246 - accuracy: 0.8258 - val_loss: 0.4246 - val_accuracy: 0.8095\n",
      "Epoch 848/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4214 - accuracy: 0.8296 - val_loss: 0.4249 - val_accuracy: 0.8095\n",
      "Epoch 849/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4166 - accuracy: 0.8277 - val_loss: 0.4245 - val_accuracy: 0.8095\n",
      "Epoch 850/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4269 - accuracy: 0.8240 - val_loss: 0.4241 - val_accuracy: 0.8095\n",
      "Epoch 851/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4199 - accuracy: 0.8202 - val_loss: 0.4236 - val_accuracy: 0.8095\n",
      "Epoch 852/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4194 - accuracy: 0.8296 - val_loss: 0.4231 - val_accuracy: 0.8123\n",
      "Epoch 853/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4187 - accuracy: 0.8352 - val_loss: 0.4226 - val_accuracy: 0.8039\n",
      "Epoch 854/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4291 - accuracy: 0.8258 - val_loss: 0.4224 - val_accuracy: 0.8039\n",
      "Epoch 855/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4188 - accuracy: 0.8352 - val_loss: 0.4233 - val_accuracy: 0.8039\n",
      "Epoch 856/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4138 - accuracy: 0.8258 - val_loss: 0.4255 - val_accuracy: 0.8039\n",
      "Epoch 857/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4091 - accuracy: 0.8333 - val_loss: 0.4276 - val_accuracy: 0.8039\n",
      "Epoch 858/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4329 - accuracy: 0.8277 - val_loss: 0.4297 - val_accuracy: 0.8011\n",
      "Epoch 859/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4138 - accuracy: 0.8258 - val_loss: 0.4318 - val_accuracy: 0.8011\n",
      "Epoch 860/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4191 - accuracy: 0.8109 - val_loss: 0.4335 - val_accuracy: 0.8011\n",
      "Epoch 861/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4087 - accuracy: 0.8352 - val_loss: 0.4342 - val_accuracy: 0.8011\n",
      "Epoch 862/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4131 - accuracy: 0.8240 - val_loss: 0.4354 - val_accuracy: 0.8011\n",
      "Epoch 863/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4277 - accuracy: 0.8277 - val_loss: 0.4343 - val_accuracy: 0.8011\n",
      "Epoch 864/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4249 - accuracy: 0.8277 - val_loss: 0.4316 - val_accuracy: 0.8011\n",
      "Epoch 865/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4239 - accuracy: 0.8352 - val_loss: 0.4304 - val_accuracy: 0.8011\n",
      "Epoch 866/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4233 - accuracy: 0.8240 - val_loss: 0.4299 - val_accuracy: 0.7983\n",
      "Epoch 867/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4124 - accuracy: 0.8296 - val_loss: 0.4296 - val_accuracy: 0.7983\n",
      "Epoch 868/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4313 - accuracy: 0.8221 - val_loss: 0.4292 - val_accuracy: 0.7983\n",
      "Epoch 869/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4251 - accuracy: 0.8296 - val_loss: 0.4293 - val_accuracy: 0.7983\n",
      "Epoch 870/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4176 - accuracy: 0.8371 - val_loss: 0.4299 - val_accuracy: 0.7983\n",
      "Epoch 871/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4074 - accuracy: 0.8333 - val_loss: 0.4312 - val_accuracy: 0.7983\n",
      "Epoch 872/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4164 - accuracy: 0.8333 - val_loss: 0.4335 - val_accuracy: 0.7983\n",
      "Epoch 873/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4264 - accuracy: 0.8258 - val_loss: 0.4356 - val_accuracy: 0.7983\n",
      "Epoch 874/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4248 - accuracy: 0.8296 - val_loss: 0.4379 - val_accuracy: 0.8067\n",
      "Epoch 875/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4225 - accuracy: 0.8296 - val_loss: 0.4393 - val_accuracy: 0.8067\n",
      "Epoch 876/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4209 - accuracy: 0.8296 - val_loss: 0.4389 - val_accuracy: 0.7983\n",
      "Epoch 877/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4197 - accuracy: 0.8258 - val_loss: 0.4380 - val_accuracy: 0.7983\n",
      "Epoch 878/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4111 - accuracy: 0.8315 - val_loss: 0.4383 - val_accuracy: 0.7927\n",
      "Epoch 879/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4155 - accuracy: 0.8390 - val_loss: 0.4394 - val_accuracy: 0.7927\n",
      "Epoch 880/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4241 - accuracy: 0.8333 - val_loss: 0.4396 - val_accuracy: 0.7927\n",
      "Epoch 881/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4229 - accuracy: 0.8296 - val_loss: 0.4379 - val_accuracy: 0.7927\n",
      "Epoch 882/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4231 - accuracy: 0.8296 - val_loss: 0.4366 - val_accuracy: 0.7927\n",
      "Epoch 883/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4185 - accuracy: 0.8258 - val_loss: 0.4347 - val_accuracy: 0.7927\n",
      "Epoch 884/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4201 - accuracy: 0.8352 - val_loss: 0.4324 - val_accuracy: 0.7927\n",
      "Epoch 885/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4207 - accuracy: 0.8296 - val_loss: 0.4317 - val_accuracy: 0.7927\n",
      "Epoch 886/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4307 - accuracy: 0.8258 - val_loss: 0.4312 - val_accuracy: 0.7927\n",
      "Epoch 887/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4195 - accuracy: 0.8258 - val_loss: 0.4309 - val_accuracy: 0.7927\n",
      "Epoch 888/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4212 - accuracy: 0.8352 - val_loss: 0.4316 - val_accuracy: 0.7927\n",
      "Epoch 889/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4213 - accuracy: 0.8315 - val_loss: 0.4331 - val_accuracy: 0.7927\n",
      "Epoch 890/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4191 - accuracy: 0.8221 - val_loss: 0.4344 - val_accuracy: 0.7927\n",
      "Epoch 891/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4129 - accuracy: 0.8296 - val_loss: 0.4350 - val_accuracy: 0.7927\n",
      "Epoch 892/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4215 - accuracy: 0.8277 - val_loss: 0.4357 - val_accuracy: 0.7927\n",
      "Epoch 893/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4098 - accuracy: 0.8390 - val_loss: 0.4364 - val_accuracy: 0.7927\n",
      "Epoch 894/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4263 - accuracy: 0.8296 - val_loss: 0.4372 - val_accuracy: 0.7927\n",
      "Epoch 895/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4196 - accuracy: 0.8333 - val_loss: 0.4379 - val_accuracy: 0.7983\n",
      "Epoch 896/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4200 - accuracy: 0.8352 - val_loss: 0.4371 - val_accuracy: 0.7983\n",
      "Epoch 897/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4238 - accuracy: 0.8315 - val_loss: 0.4376 - val_accuracy: 0.8011\n",
      "Epoch 898/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4233 - accuracy: 0.8277 - val_loss: 0.4392 - val_accuracy: 0.8011\n",
      "Epoch 899/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4206 - accuracy: 0.8277 - val_loss: 0.4411 - val_accuracy: 0.8011\n",
      "Epoch 900/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4117 - accuracy: 0.8333 - val_loss: 0.4427 - val_accuracy: 0.8011\n",
      "Epoch 901/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4087 - accuracy: 0.8371 - val_loss: 0.4430 - val_accuracy: 0.8011\n",
      "Epoch 902/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4288 - accuracy: 0.8240 - val_loss: 0.4424 - val_accuracy: 0.7983\n",
      "Epoch 903/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4267 - accuracy: 0.8371 - val_loss: 0.4398 - val_accuracy: 0.7983\n",
      "Epoch 904/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4155 - accuracy: 0.8427 - val_loss: 0.4396 - val_accuracy: 0.8039\n",
      "Epoch 905/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4198 - accuracy: 0.8296 - val_loss: 0.4412 - val_accuracy: 0.8039\n",
      "Epoch 906/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4209 - accuracy: 0.8333 - val_loss: 0.4409 - val_accuracy: 0.8039\n",
      "Epoch 907/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4296 - accuracy: 0.8371 - val_loss: 0.4387 - val_accuracy: 0.8039\n",
      "Epoch 908/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4219 - accuracy: 0.8277 - val_loss: 0.4359 - val_accuracy: 0.8095\n",
      "Epoch 909/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4144 - accuracy: 0.8240 - val_loss: 0.4346 - val_accuracy: 0.7983\n",
      "Epoch 910/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4207 - accuracy: 0.8240 - val_loss: 0.4361 - val_accuracy: 0.8095\n",
      "Epoch 911/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4217 - accuracy: 0.8221 - val_loss: 0.4384 - val_accuracy: 0.7927\n",
      "Epoch 912/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4151 - accuracy: 0.8258 - val_loss: 0.4386 - val_accuracy: 0.7927\n",
      "Epoch 913/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4307 - accuracy: 0.8240 - val_loss: 0.4382 - val_accuracy: 0.8095\n",
      "Epoch 914/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4214 - accuracy: 0.8202 - val_loss: 0.4366 - val_accuracy: 0.7983\n",
      "Epoch 915/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4175 - accuracy: 0.8277 - val_loss: 0.4349 - val_accuracy: 0.8095\n",
      "Epoch 916/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4271 - accuracy: 0.8240 - val_loss: 0.4355 - val_accuracy: 0.8039\n",
      "Epoch 917/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4293 - accuracy: 0.8221 - val_loss: 0.4359 - val_accuracy: 0.8039\n",
      "Epoch 918/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4377 - accuracy: 0.8258 - val_loss: 0.4355 - val_accuracy: 0.8039\n",
      "Epoch 919/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4243 - accuracy: 0.8352 - val_loss: 0.4349 - val_accuracy: 0.8039\n",
      "Epoch 920/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4164 - accuracy: 0.8315 - val_loss: 0.4338 - val_accuracy: 0.8095\n",
      "Epoch 921/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4276 - accuracy: 0.8258 - val_loss: 0.4337 - val_accuracy: 0.8095\n",
      "Epoch 922/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4160 - accuracy: 0.8352 - val_loss: 0.4344 - val_accuracy: 0.8095\n",
      "Epoch 923/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4164 - accuracy: 0.8240 - val_loss: 0.4355 - val_accuracy: 0.7983\n",
      "Epoch 924/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4143 - accuracy: 0.8296 - val_loss: 0.4375 - val_accuracy: 0.8011\n",
      "Epoch 925/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4256 - accuracy: 0.8184 - val_loss: 0.4394 - val_accuracy: 0.8011\n",
      "Epoch 926/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4333 - accuracy: 0.8146 - val_loss: 0.4390 - val_accuracy: 0.8011\n",
      "Epoch 927/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4209 - accuracy: 0.8221 - val_loss: 0.4349 - val_accuracy: 0.8011\n",
      "Epoch 928/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4232 - accuracy: 0.8258 - val_loss: 0.4320 - val_accuracy: 0.8095\n",
      "Epoch 929/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4223 - accuracy: 0.8202 - val_loss: 0.4299 - val_accuracy: 0.8095\n",
      "Epoch 930/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4229 - accuracy: 0.8277 - val_loss: 0.4281 - val_accuracy: 0.8095\n",
      "Epoch 931/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4093 - accuracy: 0.8315 - val_loss: 0.4278 - val_accuracy: 0.8095\n",
      "Epoch 932/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4134 - accuracy: 0.8296 - val_loss: 0.4284 - val_accuracy: 0.8095\n",
      "Epoch 933/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4126 - accuracy: 0.8258 - val_loss: 0.4293 - val_accuracy: 0.8095\n",
      "Epoch 934/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4218 - accuracy: 0.8296 - val_loss: 0.4299 - val_accuracy: 0.8095\n",
      "Epoch 935/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4190 - accuracy: 0.8296 - val_loss: 0.4299 - val_accuracy: 0.8095\n",
      "Epoch 936/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4170 - accuracy: 0.8296 - val_loss: 0.4292 - val_accuracy: 0.8095\n",
      "Epoch 937/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4322 - accuracy: 0.8240 - val_loss: 0.4286 - val_accuracy: 0.8095\n",
      "Epoch 938/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4192 - accuracy: 0.8240 - val_loss: 0.4293 - val_accuracy: 0.8095\n",
      "Epoch 939/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4237 - accuracy: 0.8221 - val_loss: 0.4307 - val_accuracy: 0.8095\n",
      "Epoch 940/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4217 - accuracy: 0.8333 - val_loss: 0.4330 - val_accuracy: 0.8095\n",
      "Epoch 941/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4244 - accuracy: 0.8202 - val_loss: 0.4344 - val_accuracy: 0.8095\n",
      "Epoch 942/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4168 - accuracy: 0.8371 - val_loss: 0.4344 - val_accuracy: 0.8095\n",
      "Epoch 943/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4229 - accuracy: 0.8277 - val_loss: 0.4345 - val_accuracy: 0.8095\n",
      "Epoch 944/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4176 - accuracy: 0.8258 - val_loss: 0.4354 - val_accuracy: 0.8095\n",
      "Epoch 945/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4225 - accuracy: 0.8296 - val_loss: 0.4365 - val_accuracy: 0.7983\n",
      "Epoch 946/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4220 - accuracy: 0.8315 - val_loss: 0.4378 - val_accuracy: 0.8095\n",
      "Epoch 947/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4242 - accuracy: 0.8240 - val_loss: 0.4391 - val_accuracy: 0.8095\n",
      "Epoch 948/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4181 - accuracy: 0.8296 - val_loss: 0.4406 - val_accuracy: 0.8095\n",
      "Epoch 949/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4073 - accuracy: 0.8240 - val_loss: 0.4420 - val_accuracy: 0.7983\n",
      "Epoch 950/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4245 - accuracy: 0.8221 - val_loss: 0.4424 - val_accuracy: 0.8011\n",
      "Epoch 951/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4197 - accuracy: 0.8258 - val_loss: 0.4413 - val_accuracy: 0.8011\n",
      "Epoch 952/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4284 - accuracy: 0.8315 - val_loss: 0.4398 - val_accuracy: 0.8095\n",
      "Epoch 953/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4231 - accuracy: 0.8277 - val_loss: 0.4380 - val_accuracy: 0.8095\n",
      "Epoch 954/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4301 - accuracy: 0.8146 - val_loss: 0.4368 - val_accuracy: 0.7927\n",
      "Epoch 955/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4296 - accuracy: 0.8146 - val_loss: 0.4353 - val_accuracy: 0.8067\n",
      "Epoch 956/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4189 - accuracy: 0.8240 - val_loss: 0.4345 - val_accuracy: 0.7983\n",
      "Epoch 957/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4150 - accuracy: 0.8240 - val_loss: 0.4355 - val_accuracy: 0.7983\n",
      "Epoch 958/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4139 - accuracy: 0.8296 - val_loss: 0.4372 - val_accuracy: 0.8095\n",
      "Epoch 959/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4371 - accuracy: 0.8202 - val_loss: 0.4391 - val_accuracy: 0.8095\n",
      "Epoch 960/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4207 - accuracy: 0.8315 - val_loss: 0.4413 - val_accuracy: 0.8095\n",
      "Epoch 961/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4259 - accuracy: 0.8240 - val_loss: 0.4426 - val_accuracy: 0.8095\n",
      "Epoch 962/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4132 - accuracy: 0.8221 - val_loss: 0.4438 - val_accuracy: 0.8011\n",
      "Epoch 963/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4154 - accuracy: 0.8352 - val_loss: 0.4438 - val_accuracy: 0.8011\n",
      "Epoch 964/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4298 - accuracy: 0.8184 - val_loss: 0.4416 - val_accuracy: 0.8123\n",
      "Epoch 965/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4220 - accuracy: 0.8258 - val_loss: 0.4384 - val_accuracy: 0.8123\n",
      "Epoch 966/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4110 - accuracy: 0.8352 - val_loss: 0.4369 - val_accuracy: 0.8123\n",
      "Epoch 967/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4174 - accuracy: 0.8296 - val_loss: 0.4357 - val_accuracy: 0.8123\n",
      "Epoch 968/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4199 - accuracy: 0.8277 - val_loss: 0.4349 - val_accuracy: 0.8095\n",
      "Epoch 969/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4210 - accuracy: 0.8277 - val_loss: 0.4343 - val_accuracy: 0.8095\n",
      "Epoch 970/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4211 - accuracy: 0.8390 - val_loss: 0.4333 - val_accuracy: 0.8123\n",
      "Epoch 971/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4236 - accuracy: 0.8258 - val_loss: 0.4331 - val_accuracy: 0.8123\n",
      "Epoch 972/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4254 - accuracy: 0.8296 - val_loss: 0.4335 - val_accuracy: 0.8123\n",
      "Epoch 973/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4214 - accuracy: 0.8240 - val_loss: 0.4342 - val_accuracy: 0.8123\n",
      "Epoch 974/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4212 - accuracy: 0.8371 - val_loss: 0.4349 - val_accuracy: 0.8123\n",
      "Epoch 975/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4274 - accuracy: 0.8315 - val_loss: 0.4347 - val_accuracy: 0.8123\n",
      "Epoch 976/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4157 - accuracy: 0.8352 - val_loss: 0.4346 - val_accuracy: 0.8095\n",
      "Epoch 977/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4200 - accuracy: 0.8240 - val_loss: 0.4338 - val_accuracy: 0.8095\n",
      "Epoch 978/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4206 - accuracy: 0.8315 - val_loss: 0.4329 - val_accuracy: 0.8095\n",
      "Epoch 979/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4193 - accuracy: 0.8221 - val_loss: 0.4318 - val_accuracy: 0.8095\n",
      "Epoch 980/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4264 - accuracy: 0.8184 - val_loss: 0.4289 - val_accuracy: 0.8095\n",
      "Epoch 981/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4125 - accuracy: 0.8146 - val_loss: 0.4266 - val_accuracy: 0.7983\n",
      "Epoch 982/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4237 - accuracy: 0.8240 - val_loss: 0.4255 - val_accuracy: 0.8095\n",
      "Epoch 983/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4186 - accuracy: 0.8202 - val_loss: 0.4242 - val_accuracy: 0.8095\n",
      "Epoch 984/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4164 - accuracy: 0.8277 - val_loss: 0.4232 - val_accuracy: 0.8095\n",
      "Epoch 985/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4179 - accuracy: 0.8333 - val_loss: 0.4238 - val_accuracy: 0.8095\n",
      "Epoch 986/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4112 - accuracy: 0.8315 - val_loss: 0.4257 - val_accuracy: 0.8095\n",
      "Epoch 987/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4200 - accuracy: 0.8240 - val_loss: 0.4274 - val_accuracy: 0.8095\n",
      "Epoch 988/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4168 - accuracy: 0.8277 - val_loss: 0.4294 - val_accuracy: 0.8095\n",
      "Epoch 989/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4276 - accuracy: 0.8277 - val_loss: 0.4319 - val_accuracy: 0.8095\n",
      "Epoch 990/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4211 - accuracy: 0.8258 - val_loss: 0.4341 - val_accuracy: 0.8095\n",
      "Epoch 991/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4119 - accuracy: 0.8202 - val_loss: 0.4359 - val_accuracy: 0.8095\n",
      "Epoch 992/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4159 - accuracy: 0.8258 - val_loss: 0.4349 - val_accuracy: 0.7983\n",
      "Epoch 993/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4207 - accuracy: 0.8240 - val_loss: 0.4318 - val_accuracy: 0.8011\n",
      "Epoch 994/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4140 - accuracy: 0.8202 - val_loss: 0.4297 - val_accuracy: 0.8011\n",
      "Epoch 995/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4246 - accuracy: 0.8240 - val_loss: 0.4293 - val_accuracy: 0.8011\n",
      "Epoch 996/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4105 - accuracy: 0.8221 - val_loss: 0.4302 - val_accuracy: 0.8011\n",
      "Epoch 997/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4161 - accuracy: 0.8352 - val_loss: 0.4305 - val_accuracy: 0.8011\n",
      "Epoch 998/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4240 - accuracy: 0.8109 - val_loss: 0.4305 - val_accuracy: 0.8011\n",
      "Epoch 999/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4197 - accuracy: 0.8221 - val_loss: 0.4315 - val_accuracy: 0.8123\n",
      "Epoch 1000/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4241 - accuracy: 0.8315 - val_loss: 0.4327 - val_accuracy: 0.8011\n"
     ]
    }
   ],
   "source": [
    "def model_titanic():\n",
    "    \n",
    "    model = keras.Sequential(name=\"titanic_Smodel\")\n",
    "\n",
    "    model.add(keras.Input(shape=(15,)))  ## argument must be the shape of each sample, not the shape of one batch.\n",
    "    model.add(layers.Dense(16, activation=\"elu\",kernel_initializer='uniform'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(16, activation=\"elu\",kernel_initializer='uniform'))\n",
    "    #model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # then we build the model\n",
    "    model.build()\n",
    "\n",
    "    # Compile\n",
    "    optimizer=keras.optimizers.Adam(5e-3)\n",
    "    model.compile(optimizer=optimizer,#optimizer = \"adam\",#optimizer=\"rmsprop\",   #good for default, generally good for any problem\n",
    "    loss=\"binary_crossentropy\",        # usually good when working with output probabilities \n",
    "    metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "#######\n",
    "model = model_titanic()\n",
    "# and get a summary of the model to check the arquitecture\n",
    "model_titanic().summary()\n",
    "\n",
    "# Training\n",
    "history = model.fit(Dtrain_vec[:,1:],Dtrain_vec[:,0],epochs=1000,batch_size=256,validation_split=0.4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78d0ea8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f659134c1f0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = np.arange(1,len(loss_values)+1)\n",
    "\n",
    "plt.plot(epochs,loss_values,label=\"Training loss\")\n",
    "plt.plot(epochs,val_loss_values,label=\"Validation loss\")\n",
    "\n",
    "\n",
    "acc = history_dict[\"accuracy\"]\n",
    "val_acc = history_dict[\"val_accuracy\"]\n",
    "\n",
    "plt.plot(epochs, acc, label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, label=\"Validation acc\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c4b47c",
   "metadata": {},
   "source": [
    "    What should we expect?\n",
    "        1. the training loss decreases with every epoch.\n",
    "        2. the training accuracy should increases with every epoch. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ea943e",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76dbb9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions= model.predict(Dtest_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "937955e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.98564583, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 3.01435335]),\n",
       " array([0.        , 0.1       , 0.2       , 0.30000001, 0.40000001,\n",
       "        0.5       , 0.60000002, 0.69999999, 0.80000001, 0.89999998,\n",
       "        1.        ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.hist(Dtrain_vec[:,0],density=True)\n",
    "plt.hist(np.round(predictions),density=True,alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf200985",
   "metadata": {},
   "source": [
    "# Final training and create sub_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "304c3a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 1s 7ms/step - loss: 0.6805 - accuracy: 0.6184\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6301 - accuracy: 0.6712\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5707 - accuracy: 0.7116\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7654\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7767\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4569 - accuracy: 0.7879\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4578 - accuracy: 0.7991\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4510 - accuracy: 0.7946\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4494 - accuracy: 0.7991\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.8002\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7946\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.8081\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4498 - accuracy: 0.8047\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4378 - accuracy: 0.8103\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4370 - accuracy: 0.8159\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.8227\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8126\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4377 - accuracy: 0.8126\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.8137\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.8215\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4373 - accuracy: 0.8193\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.8204\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.8238\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.8126\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.8159\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4338 - accuracy: 0.8159\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.8148\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8316\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.8204\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.8193\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.8171\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.8193\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.8159\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.8249\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4283 - accuracy: 0.8227\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4265 - accuracy: 0.8227\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.8204\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4233 - accuracy: 0.8260\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.8249\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8103\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8171\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4238 - accuracy: 0.8272\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8171\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8171\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.8249\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4189 - accuracy: 0.8193\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8238\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.8260\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.8260\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4243 - accuracy: 0.8159\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.8148\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.8249\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.8193\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8272\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.8137\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.8204\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8227\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.8283\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8215\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8272\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8182\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4208 - accuracy: 0.8193\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8159\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8249\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8204\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8215\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8215\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8204\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8249\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8238\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4211 - accuracy: 0.8171\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8227\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8215\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4226 - accuracy: 0.8238\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4162 - accuracy: 0.8260\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8260\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8238\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8171\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4089 - accuracy: 0.8260\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4150 - accuracy: 0.8182\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8260\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.8215\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8193\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.8260\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8182\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4081 - accuracy: 0.8249\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8171\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8171\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8249\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4189 - accuracy: 0.8249\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.8126\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8249\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8283\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8227\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8193\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8260\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8238\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8260\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4131 - accuracy: 0.8215\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8227\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8148\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8204\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8227\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.8204\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8215\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8193\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8227\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8238\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8148\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.8249\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8204\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8182\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8249\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.8193\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.8182\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8215\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4210 - accuracy: 0.8260\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4180 - accuracy: 0.8171\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.8227\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8171\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8193\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8238\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8272\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8193\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8204\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8305\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8283\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4139 - accuracy: 0.8294\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4172 - accuracy: 0.8204\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.8204\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8238\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8260\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8260\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.8215\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.8227\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4257 - accuracy: 0.8215\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8193\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4141 - accuracy: 0.8249\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.8171\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8204\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4282 - accuracy: 0.8249\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.8137\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.8193\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.8238\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8204\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8171\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.8227\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8272\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8193\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8204\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8182\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8260\n",
      "Epoch 153/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.8193\n",
      "Epoch 154/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.8193\n",
      "Epoch 155/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8215\n",
      "Epoch 156/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8238\n",
      "Epoch 157/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8238\n",
      "Epoch 158/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4279 - accuracy: 0.8215\n",
      "Epoch 159/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4114 - accuracy: 0.8227\n",
      "Epoch 160/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4198 - accuracy: 0.8294\n",
      "Epoch 161/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.8204\n",
      "Epoch 162/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8215\n",
      "Epoch 163/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.8215\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8227\n",
      "Epoch 165/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8238\n",
      "Epoch 166/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.8193\n",
      "Epoch 167/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8204\n",
      "Epoch 168/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4190 - accuracy: 0.8182\n",
      "Epoch 169/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.8283\n",
      "Epoch 170/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.8238\n",
      "Epoch 171/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8249\n",
      "Epoch 172/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8171\n",
      "Epoch 173/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.8227\n",
      "Epoch 174/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8249\n",
      "Epoch 175/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4212 - accuracy: 0.8182\n",
      "Epoch 176/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4075 - accuracy: 0.8283\n",
      "Epoch 177/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8182\n",
      "Epoch 178/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4112 - accuracy: 0.8272\n",
      "Epoch 179/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8215\n",
      "Epoch 180/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8193\n",
      "Epoch 181/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8204\n",
      "Epoch 182/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8148\n",
      "Epoch 183/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8193\n",
      "Epoch 184/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.8182\n",
      "Epoch 185/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8238\n",
      "Epoch 186/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.8193\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.8238\n",
      "Epoch 188/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8204\n",
      "Epoch 189/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8126\n",
      "Epoch 190/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4240 - accuracy: 0.8249\n",
      "Epoch 191/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.8204\n",
      "Epoch 192/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8249\n",
      "Epoch 193/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4162 - accuracy: 0.8249\n",
      "Epoch 194/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4122 - accuracy: 0.8260\n",
      "Epoch 195/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.8159\n",
      "Epoch 196/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8204\n",
      "Epoch 197/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8238\n",
      "Epoch 198/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4244 - accuracy: 0.8159\n",
      "Epoch 199/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4149 - accuracy: 0.8249\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8193\n",
      "Epoch 201/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8148\n",
      "Epoch 202/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.8182\n",
      "Epoch 203/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.8204\n",
      "Epoch 204/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8238\n",
      "Epoch 205/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8238\n",
      "Epoch 206/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4256 - accuracy: 0.8182\n",
      "Epoch 207/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8182\n",
      "Epoch 208/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8215\n",
      "Epoch 209/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4081 - accuracy: 0.8283\n",
      "Epoch 210/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4181 - accuracy: 0.8260\n",
      "Epoch 211/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.8182\n",
      "Epoch 212/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8227\n",
      "Epoch 213/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8171\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8171\n",
      "Epoch 215/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8148\n",
      "Epoch 216/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4177 - accuracy: 0.8171\n",
      "Epoch 217/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4154 - accuracy: 0.8227\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8238\n",
      "Epoch 219/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.8249\n",
      "Epoch 220/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8204\n",
      "Epoch 221/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8227\n",
      "Epoch 222/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8215\n",
      "Epoch 223/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8182\n",
      "Epoch 224/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8193\n",
      "Epoch 225/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4093 - accuracy: 0.8227\n",
      "Epoch 226/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8193\n",
      "Epoch 227/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8227\n",
      "Epoch 228/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.8182\n",
      "Epoch 229/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8182\n",
      "Epoch 230/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8193\n",
      "Epoch 231/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8227\n",
      "Epoch 232/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4208 - accuracy: 0.8204\n",
      "Epoch 233/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8215\n",
      "Epoch 234/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8227\n",
      "Epoch 235/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8193\n",
      "Epoch 236/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8193\n",
      "Epoch 237/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8204\n",
      "Epoch 238/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8103\n",
      "Epoch 239/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8204\n",
      "Epoch 240/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8193\n",
      "Epoch 241/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.8272\n",
      "Epoch 242/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.8204\n",
      "Epoch 243/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8294\n",
      "Epoch 244/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4093 - accuracy: 0.8260\n",
      "Epoch 245/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8171\n",
      "Epoch 246/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8249\n",
      "Epoch 247/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8182\n",
      "Epoch 248/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8227\n",
      "Epoch 249/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8260\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8182\n",
      "Epoch 251/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.8204\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8305\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.8238\n",
      "Epoch 254/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.8171\n",
      "Epoch 255/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4163 - accuracy: 0.8159\n",
      "Epoch 256/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8171\n",
      "Epoch 257/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.8238\n",
      "Epoch 258/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8193\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8260\n",
      "Epoch 260/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8260\n",
      "Epoch 261/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8204\n",
      "Epoch 262/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8260\n",
      "Epoch 263/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8182\n",
      "Epoch 264/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.8227\n",
      "Epoch 265/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8193\n",
      "Epoch 266/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4136 - accuracy: 0.8193\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8193\n",
      "Epoch 268/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8249\n",
      "Epoch 269/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8238\n",
      "Epoch 270/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4154 - accuracy: 0.8193\n",
      "Epoch 271/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4141 - accuracy: 0.8260\n",
      "Epoch 272/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.8260\n",
      "Epoch 273/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8159\n",
      "Epoch 274/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4242 - accuracy: 0.8227\n",
      "Epoch 275/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8249\n",
      "Epoch 276/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.8294\n",
      "Epoch 277/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8272\n",
      "Epoch 278/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.8238\n",
      "Epoch 279/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.8215\n",
      "Epoch 280/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.8227\n",
      "Epoch 281/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4139 - accuracy: 0.8171\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.8238\n",
      "Epoch 283/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.8215\n",
      "Epoch 284/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4147 - accuracy: 0.8171\n",
      "Epoch 285/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.8227\n",
      "Epoch 286/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.8148\n",
      "Epoch 287/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8260\n",
      "Epoch 288/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8272\n",
      "Epoch 289/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4085 - accuracy: 0.8260\n",
      "Epoch 290/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8137\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4200 - accuracy: 0.8171\n",
      "Epoch 292/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8283\n",
      "Epoch 293/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.8182\n",
      "Epoch 294/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8249\n",
      "Epoch 295/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.8182\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8238\n",
      "Epoch 297/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4172 - accuracy: 0.8171\n",
      "Epoch 298/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4130 - accuracy: 0.8204\n",
      "Epoch 299/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4213 - accuracy: 0.8193\n",
      "Epoch 300/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8249\n",
      "Epoch 301/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4211 - accuracy: 0.8137\n",
      "Epoch 302/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8238\n",
      "Epoch 303/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8260\n",
      "Epoch 304/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8215\n",
      "Epoch 305/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8227\n",
      "Epoch 306/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8238\n",
      "Epoch 307/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8171\n",
      "Epoch 308/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8137\n",
      "Epoch 309/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8249\n",
      "Epoch 310/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.8182\n",
      "Epoch 311/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4143 - accuracy: 0.8227\n",
      "Epoch 312/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8204\n",
      "Epoch 313/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4111 - accuracy: 0.8249\n",
      "Epoch 314/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4146 - accuracy: 0.8193\n",
      "Epoch 315/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8272\n",
      "Epoch 316/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8159\n",
      "Epoch 317/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8193\n",
      "Epoch 318/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8249\n",
      "Epoch 319/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.8148\n",
      "Epoch 320/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8215\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8238\n",
      "Epoch 322/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.8227\n",
      "Epoch 323/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4231 - accuracy: 0.8227\n",
      "Epoch 324/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8204\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8238\n",
      "Epoch 326/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4093 - accuracy: 0.8193\n",
      "Epoch 327/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.8182\n",
      "Epoch 328/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8204\n",
      "Epoch 329/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8272\n",
      "Epoch 330/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8159\n",
      "Epoch 331/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8227\n",
      "Epoch 332/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4092 - accuracy: 0.8272\n",
      "Epoch 333/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8193\n",
      "Epoch 334/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.8182\n",
      "Epoch 335/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8215\n",
      "Epoch 336/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4094 - accuracy: 0.8260\n",
      "Epoch 337/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.8182\n",
      "Epoch 338/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8227\n",
      "Epoch 339/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8272\n",
      "Epoch 340/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8215\n",
      "Epoch 341/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4078 - accuracy: 0.8272\n",
      "Epoch 342/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8238\n",
      "Epoch 343/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.8249\n",
      "Epoch 344/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8272\n",
      "Epoch 345/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.8215\n",
      "Epoch 346/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8238\n",
      "Epoch 347/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4183 - accuracy: 0.8193\n",
      "Epoch 348/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4114 - accuracy: 0.8215\n",
      "Epoch 349/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4163 - accuracy: 0.8204\n",
      "Epoch 350/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8260\n",
      "Epoch 351/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8272\n",
      "Epoch 352/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8182\n",
      "Epoch 353/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4172 - accuracy: 0.8272\n",
      "Epoch 354/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8204\n",
      "Epoch 355/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.8137\n",
      "Epoch 356/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8182\n",
      "Epoch 357/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8182\n",
      "Epoch 358/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4232 - accuracy: 0.8227\n",
      "Epoch 359/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8182\n",
      "Epoch 360/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.8171\n",
      "Epoch 361/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8249\n",
      "Epoch 362/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8204\n",
      "Epoch 363/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4229 - accuracy: 0.8272\n",
      "Epoch 364/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4058 - accuracy: 0.8182\n",
      "Epoch 365/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4179 - accuracy: 0.8193\n",
      "Epoch 366/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4073 - accuracy: 0.8171\n",
      "Epoch 367/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4202 - accuracy: 0.8260\n",
      "Epoch 368/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8182\n",
      "Epoch 369/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4069 - accuracy: 0.8215\n",
      "Epoch 370/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4096 - accuracy: 0.8294\n",
      "Epoch 371/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4134 - accuracy: 0.8159\n",
      "Epoch 372/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4191 - accuracy: 0.8148\n",
      "Epoch 373/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4141 - accuracy: 0.8204\n",
      "Epoch 374/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4124 - accuracy: 0.8238\n",
      "Epoch 375/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8215\n",
      "Epoch 376/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4101 - accuracy: 0.8193\n",
      "Epoch 377/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4062 - accuracy: 0.8260\n",
      "Epoch 378/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4115 - accuracy: 0.8227\n",
      "Epoch 379/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4130 - accuracy: 0.8283\n",
      "Epoch 380/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4170 - accuracy: 0.8171\n",
      "Epoch 381/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4102 - accuracy: 0.8148\n",
      "Epoch 382/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.8249\n",
      "Epoch 383/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8193\n",
      "Epoch 384/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8249\n",
      "Epoch 385/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8215\n",
      "Epoch 386/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4168 - accuracy: 0.8171\n",
      "Epoch 387/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8193\n",
      "Epoch 388/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8204\n",
      "Epoch 389/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8238\n",
      "Epoch 390/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4155 - accuracy: 0.8238\n",
      "Epoch 391/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.8204\n",
      "Epoch 392/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4155 - accuracy: 0.8294\n",
      "Epoch 393/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4090 - accuracy: 0.8238\n",
      "Epoch 394/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4079 - accuracy: 0.8227\n",
      "Epoch 395/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4067 - accuracy: 0.8215\n",
      "Epoch 396/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4159 - accuracy: 0.8182\n",
      "Epoch 397/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4207 - accuracy: 0.8227\n",
      "Epoch 398/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4179 - accuracy: 0.8249\n",
      "Epoch 399/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.8182\n",
      "Epoch 400/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.8215\n",
      "Epoch 401/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4189 - accuracy: 0.8283\n",
      "Epoch 402/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4199 - accuracy: 0.8249\n",
      "Epoch 403/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4099 - accuracy: 0.8238\n",
      "Epoch 404/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4095 - accuracy: 0.8204\n",
      "Epoch 405/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4136 - accuracy: 0.8182\n",
      "Epoch 406/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4089 - accuracy: 0.8182\n",
      "Epoch 407/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4158 - accuracy: 0.8260\n",
      "Epoch 408/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4109 - accuracy: 0.8238\n",
      "Epoch 409/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4091 - accuracy: 0.8249\n",
      "Epoch 410/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4072 - accuracy: 0.8227\n",
      "Epoch 411/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4113 - accuracy: 0.8260\n",
      "Epoch 412/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4124 - accuracy: 0.8171\n",
      "Epoch 413/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.8137\n",
      "Epoch 414/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4207 - accuracy: 0.8204\n",
      "Epoch 415/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4130 - accuracy: 0.8260\n",
      "Epoch 416/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4077 - accuracy: 0.8204\n",
      "Epoch 417/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4186 - accuracy: 0.8193\n",
      "Epoch 418/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4148 - accuracy: 0.8227\n",
      "Epoch 419/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4192 - accuracy: 0.8182\n",
      "Epoch 420/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4109 - accuracy: 0.8227\n",
      "Epoch 421/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4177 - accuracy: 0.8182\n",
      "Epoch 422/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4087 - accuracy: 0.8137\n",
      "Epoch 423/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4160 - accuracy: 0.8159\n",
      "Epoch 424/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4080 - accuracy: 0.8171\n",
      "Epoch 425/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4071 - accuracy: 0.8294\n",
      "Epoch 426/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4150 - accuracy: 0.8249\n",
      "Epoch 427/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4134 - accuracy: 0.8227\n",
      "Epoch 428/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4130 - accuracy: 0.8182\n",
      "Epoch 429/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4090 - accuracy: 0.8182\n",
      "Epoch 430/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4181 - accuracy: 0.8193\n",
      "Epoch 431/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4184 - accuracy: 0.8227\n",
      "Epoch 432/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4132 - accuracy: 0.8215\n",
      "Epoch 433/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4072 - accuracy: 0.8159\n",
      "Epoch 434/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.8238\n",
      "Epoch 435/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.8182\n",
      "Epoch 436/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4126 - accuracy: 0.8249\n",
      "Epoch 437/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8204\n",
      "Epoch 438/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4170 - accuracy: 0.8215\n",
      "Epoch 439/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4113 - accuracy: 0.8227\n",
      "Epoch 440/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4044 - accuracy: 0.8227\n",
      "Epoch 441/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4125 - accuracy: 0.8238\n",
      "Epoch 442/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4151 - accuracy: 0.8193\n",
      "Epoch 443/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.8238\n",
      "Epoch 444/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4195 - accuracy: 0.8215\n",
      "Epoch 445/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4156 - accuracy: 0.8204\n",
      "Epoch 446/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.8249\n",
      "Epoch 447/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4231 - accuracy: 0.8182\n",
      "Epoch 448/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4123 - accuracy: 0.8294\n",
      "Epoch 449/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4061 - accuracy: 0.8215\n",
      "Epoch 450/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4110 - accuracy: 0.8215\n",
      "Epoch 451/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4127 - accuracy: 0.8227\n",
      "Epoch 452/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4135 - accuracy: 0.8215\n",
      "Epoch 453/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4093 - accuracy: 0.8238\n",
      "Epoch 454/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4144 - accuracy: 0.8249\n",
      "Epoch 455/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4186 - accuracy: 0.8227\n",
      "Epoch 456/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4096 - accuracy: 0.8182\n",
      "Epoch 457/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8249\n",
      "Epoch 458/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4142 - accuracy: 0.8204\n",
      "Epoch 459/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.8227\n",
      "Epoch 460/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8171\n",
      "Epoch 461/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.8193\n",
      "Epoch 462/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4140 - accuracy: 0.8193\n",
      "Epoch 463/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4073 - accuracy: 0.8238\n",
      "Epoch 464/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4212 - accuracy: 0.8238\n",
      "Epoch 465/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8204\n",
      "Epoch 466/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4135 - accuracy: 0.8227\n",
      "Epoch 467/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4155 - accuracy: 0.8193\n",
      "Epoch 468/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4182 - accuracy: 0.8238\n",
      "Epoch 469/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4095 - accuracy: 0.8182\n",
      "Epoch 470/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4155 - accuracy: 0.8260\n",
      "Epoch 471/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4112 - accuracy: 0.8171\n",
      "Epoch 472/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4116 - accuracy: 0.8215\n",
      "Epoch 473/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.8193\n",
      "Epoch 474/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4120 - accuracy: 0.8227\n",
      "Epoch 475/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4008 - accuracy: 0.8227\n",
      "Epoch 476/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4130 - accuracy: 0.8305\n",
      "Epoch 477/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4165 - accuracy: 0.8114\n",
      "Epoch 478/1000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4133 - accuracy: 0.8204\n",
      "Epoch 479/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4182 - accuracy: 0.8193\n",
      "Epoch 480/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4188 - accuracy: 0.8193\n",
      "Epoch 481/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4082 - accuracy: 0.8182\n",
      "Epoch 482/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4119 - accuracy: 0.8227\n",
      "Epoch 483/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4115 - accuracy: 0.8171\n",
      "Epoch 484/1000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4084 - accuracy: 0.8114\n",
      "Epoch 485/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4166 - accuracy: 0.8204\n",
      "Epoch 486/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4162 - accuracy: 0.8193\n",
      "Epoch 487/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.8171\n",
      "Epoch 488/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8182\n",
      "Epoch 489/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.8260\n",
      "Epoch 490/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.8204\n",
      "Epoch 491/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4182 - accuracy: 0.8204\n",
      "Epoch 492/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8249\n",
      "Epoch 493/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4164 - accuracy: 0.8227\n",
      "Epoch 494/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4079 - accuracy: 0.8238\n",
      "Epoch 495/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8159\n",
      "Epoch 496/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.8215\n",
      "Epoch 497/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4082 - accuracy: 0.8204\n",
      "Epoch 498/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4091 - accuracy: 0.8238\n",
      "Epoch 499/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.8182\n",
      "Epoch 500/1000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4089 - accuracy: 0.8193\n",
      "Epoch 501/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4161 - accuracy: 0.8260\n",
      "Epoch 502/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4135 - accuracy: 0.8171\n",
      "Epoch 503/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4083 - accuracy: 0.8272\n",
      "Epoch 504/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4058 - accuracy: 0.8182\n",
      "Epoch 505/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.8204\n",
      "Epoch 506/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4141 - accuracy: 0.8204\n",
      "Epoch 507/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4099 - accuracy: 0.8215\n",
      "Epoch 508/1000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.4102 - accuracy: 0.8182\n",
      "Epoch 509/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4179 - accuracy: 0.8238\n",
      "Epoch 510/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8238\n",
      "Epoch 511/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4120 - accuracy: 0.8227\n",
      "Epoch 512/1000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.4091 - accuracy: 0.8182\n",
      "Epoch 513/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4114 - accuracy: 0.8148\n",
      "Epoch 514/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4143 - accuracy: 0.8204\n",
      "Epoch 515/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8215\n",
      "Epoch 516/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4068 - accuracy: 0.8182\n",
      "Epoch 517/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8249\n",
      "Epoch 518/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8249\n",
      "Epoch 519/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4098 - accuracy: 0.8249\n",
      "Epoch 520/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8193\n",
      "Epoch 521/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4207 - accuracy: 0.8171\n",
      "Epoch 522/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4112 - accuracy: 0.8182\n",
      "Epoch 523/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8171\n",
      "Epoch 524/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8215\n",
      "Epoch 525/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8260\n",
      "Epoch 526/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4149 - accuracy: 0.8204\n",
      "Epoch 527/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4213 - accuracy: 0.8227\n",
      "Epoch 528/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4110 - accuracy: 0.8193\n",
      "Epoch 529/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8339\n",
      "Epoch 530/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8249\n",
      "Epoch 531/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.8215\n",
      "Epoch 532/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.8171\n",
      "Epoch 533/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4124 - accuracy: 0.8171\n",
      "Epoch 534/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8249\n",
      "Epoch 535/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4128 - accuracy: 0.8193\n",
      "Epoch 536/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8171\n",
      "Epoch 537/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8238\n",
      "Epoch 538/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8204\n",
      "Epoch 539/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8227\n",
      "Epoch 540/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4097 - accuracy: 0.8215\n",
      "Epoch 541/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4072 - accuracy: 0.8204\n",
      "Epoch 542/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8227\n",
      "Epoch 543/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.8260\n",
      "Epoch 544/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4128 - accuracy: 0.8204\n",
      "Epoch 545/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8238\n",
      "Epoch 546/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8238\n",
      "Epoch 547/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4155 - accuracy: 0.8204\n",
      "Epoch 548/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8193\n",
      "Epoch 549/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8193\n",
      "Epoch 550/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8182\n",
      "Epoch 551/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8193\n",
      "Epoch 552/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4079 - accuracy: 0.8227\n",
      "Epoch 553/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8215\n",
      "Epoch 554/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8249\n",
      "Epoch 555/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8204\n",
      "Epoch 556/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8193\n",
      "Epoch 557/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4126 - accuracy: 0.8272\n",
      "Epoch 558/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4082 - accuracy: 0.8204\n",
      "Epoch 559/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8260\n",
      "Epoch 560/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4127 - accuracy: 0.8249\n",
      "Epoch 561/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4146 - accuracy: 0.8238\n",
      "Epoch 562/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4140 - accuracy: 0.8227\n",
      "Epoch 563/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4179 - accuracy: 0.8204\n",
      "Epoch 564/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4097 - accuracy: 0.8249\n",
      "Epoch 565/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.8171\n",
      "Epoch 566/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8249\n",
      "Epoch 567/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.8260\n",
      "Epoch 568/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4142 - accuracy: 0.8227\n",
      "Epoch 569/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.8171\n",
      "Epoch 570/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4074 - accuracy: 0.8249\n",
      "Epoch 571/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4065 - accuracy: 0.8272\n",
      "Epoch 572/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4117 - accuracy: 0.8215\n",
      "Epoch 573/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8182\n",
      "Epoch 574/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4132 - accuracy: 0.8204\n",
      "Epoch 575/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4194 - accuracy: 0.8260\n",
      "Epoch 576/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4190 - accuracy: 0.8193\n",
      "Epoch 577/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4121 - accuracy: 0.8260\n",
      "Epoch 578/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8260\n",
      "Epoch 579/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4212 - accuracy: 0.8260\n",
      "Epoch 580/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8204\n",
      "Epoch 581/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4090 - accuracy: 0.8260\n",
      "Epoch 582/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.8260\n",
      "Epoch 583/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8193\n",
      "Epoch 584/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4083 - accuracy: 0.8215\n",
      "Epoch 585/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4099 - accuracy: 0.8227\n",
      "Epoch 586/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8193\n",
      "Epoch 587/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4112 - accuracy: 0.8204\n",
      "Epoch 588/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8260\n",
      "Epoch 589/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4131 - accuracy: 0.8249\n",
      "Epoch 590/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4118 - accuracy: 0.8283\n",
      "Epoch 591/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8215\n",
      "Epoch 592/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8159\n",
      "Epoch 593/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8238\n",
      "Epoch 594/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4140 - accuracy: 0.8204\n",
      "Epoch 595/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4117 - accuracy: 0.8249\n",
      "Epoch 596/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4097 - accuracy: 0.8249\n",
      "Epoch 597/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8227\n",
      "Epoch 598/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4086 - accuracy: 0.8148\n",
      "Epoch 599/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4131 - accuracy: 0.8215\n",
      "Epoch 600/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8227\n",
      "Epoch 601/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4107 - accuracy: 0.8238\n",
      "Epoch 602/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8204\n",
      "Epoch 603/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.8227\n",
      "Epoch 604/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4148 - accuracy: 0.8204\n",
      "Epoch 605/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4080 - accuracy: 0.8204\n",
      "Epoch 606/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8215\n",
      "Epoch 607/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8227\n",
      "Epoch 608/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4162 - accuracy: 0.8204\n",
      "Epoch 609/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.8283\n",
      "Epoch 610/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4075 - accuracy: 0.8227\n",
      "Epoch 611/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8283\n",
      "Epoch 612/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8272\n",
      "Epoch 613/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8249\n",
      "Epoch 614/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4129 - accuracy: 0.8260\n",
      "Epoch 615/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8193\n",
      "Epoch 616/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8204\n",
      "Epoch 617/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4086 - accuracy: 0.8182\n",
      "Epoch 618/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8215\n",
      "Epoch 619/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4107 - accuracy: 0.8215\n",
      "Epoch 620/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8182\n",
      "Epoch 621/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.8204\n",
      "Epoch 622/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4070 - accuracy: 0.8193\n",
      "Epoch 623/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8238\n",
      "Epoch 624/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4109 - accuracy: 0.8272\n",
      "Epoch 625/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8238\n",
      "Epoch 626/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8260\n",
      "Epoch 627/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8182\n",
      "Epoch 628/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8227\n",
      "Epoch 629/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4079 - accuracy: 0.8260\n",
      "Epoch 630/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8249\n",
      "Epoch 631/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.8171\n",
      "Epoch 632/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4135 - accuracy: 0.8227\n",
      "Epoch 633/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.8204\n",
      "Epoch 634/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8260\n",
      "Epoch 635/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4070 - accuracy: 0.8215\n",
      "Epoch 636/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8215\n",
      "Epoch 637/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8227\n",
      "Epoch 638/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8215\n",
      "Epoch 639/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8171\n",
      "Epoch 640/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.8249\n",
      "Epoch 641/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4095 - accuracy: 0.8227\n",
      "Epoch 642/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8272\n",
      "Epoch 643/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8272\n",
      "Epoch 644/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4152 - accuracy: 0.8249\n",
      "Epoch 645/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4069 - accuracy: 0.8238\n",
      "Epoch 646/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8204\n",
      "Epoch 647/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4054 - accuracy: 0.8238\n",
      "Epoch 648/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.8215\n",
      "Epoch 649/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8227\n",
      "Epoch 650/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4064 - accuracy: 0.8238\n",
      "Epoch 651/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4164 - accuracy: 0.8238\n",
      "Epoch 652/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.8272\n",
      "Epoch 653/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4095 - accuracy: 0.8260\n",
      "Epoch 654/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4106 - accuracy: 0.8249\n",
      "Epoch 655/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4035 - accuracy: 0.8227\n",
      "Epoch 656/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4068 - accuracy: 0.8260\n",
      "Epoch 657/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.8182\n",
      "Epoch 658/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4096 - accuracy: 0.8260\n",
      "Epoch 659/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8227\n",
      "Epoch 660/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4079 - accuracy: 0.8227\n",
      "Epoch 661/1000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.4156 - accuracy: 0.8227\n",
      "Epoch 662/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8148\n",
      "Epoch 663/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8215\n",
      "Epoch 664/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8204\n",
      "Epoch 665/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4106 - accuracy: 0.8272\n",
      "Epoch 666/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4119 - accuracy: 0.8238\n",
      "Epoch 667/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4145 - accuracy: 0.8204\n",
      "Epoch 668/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4102 - accuracy: 0.8204\n",
      "Epoch 669/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4107 - accuracy: 0.8193\n",
      "Epoch 670/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8227\n",
      "Epoch 671/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8227\n",
      "Epoch 672/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8182\n",
      "Epoch 673/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.8227\n",
      "Epoch 674/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8171\n",
      "Epoch 675/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.8215\n",
      "Epoch 676/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4126 - accuracy: 0.8171\n",
      "Epoch 677/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4100 - accuracy: 0.8272\n",
      "Epoch 678/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4058 - accuracy: 0.8238\n",
      "Epoch 679/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4093 - accuracy: 0.8238\n",
      "Epoch 680/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4152 - accuracy: 0.8215\n",
      "Epoch 681/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4078 - accuracy: 0.8204\n",
      "Epoch 682/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4074 - accuracy: 0.8272\n",
      "Epoch 683/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.8227\n",
      "Epoch 684/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8227\n",
      "Epoch 685/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8148\n",
      "Epoch 686/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8249\n",
      "Epoch 687/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8249\n",
      "Epoch 688/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8260\n",
      "Epoch 689/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4120 - accuracy: 0.8260\n",
      "Epoch 690/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8171\n",
      "Epoch 691/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8249\n",
      "Epoch 692/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4066 - accuracy: 0.8249\n",
      "Epoch 693/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8260\n",
      "Epoch 694/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8215\n",
      "Epoch 695/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.8238\n",
      "Epoch 696/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8182\n",
      "Epoch 697/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8148\n",
      "Epoch 698/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8238\n",
      "Epoch 699/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4144 - accuracy: 0.8171\n",
      "Epoch 700/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.8283\n",
      "Epoch 701/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4049 - accuracy: 0.8272\n",
      "Epoch 702/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8227\n",
      "Epoch 703/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4073 - accuracy: 0.8249\n",
      "Epoch 704/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.8260\n",
      "Epoch 705/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4087 - accuracy: 0.8193\n",
      "Epoch 706/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8260\n",
      "Epoch 707/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4208 - accuracy: 0.8215\n",
      "Epoch 708/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4081 - accuracy: 0.8249\n",
      "Epoch 709/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8227\n",
      "Epoch 710/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8260\n",
      "Epoch 711/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4089 - accuracy: 0.8204\n",
      "Epoch 712/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4124 - accuracy: 0.8272\n",
      "Epoch 713/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4090 - accuracy: 0.8260\n",
      "Epoch 714/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4136 - accuracy: 0.8193\n",
      "Epoch 715/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.8171\n",
      "Epoch 716/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.8260\n",
      "Epoch 717/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4125 - accuracy: 0.8260\n",
      "Epoch 718/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4192 - accuracy: 0.8171\n",
      "Epoch 719/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8193\n",
      "Epoch 720/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4212 - accuracy: 0.8238\n",
      "Epoch 721/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4030 - accuracy: 0.8238\n",
      "Epoch 722/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8204\n",
      "Epoch 723/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8215\n",
      "Epoch 724/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8249\n",
      "Epoch 725/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.8227\n",
      "Epoch 726/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8238\n",
      "Epoch 727/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8171\n",
      "Epoch 728/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8260\n",
      "Epoch 729/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8328\n",
      "Epoch 730/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4097 - accuracy: 0.8272\n",
      "Epoch 731/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4126 - accuracy: 0.8249\n",
      "Epoch 732/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4142 - accuracy: 0.8159\n",
      "Epoch 733/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8148\n",
      "Epoch 734/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.8215\n",
      "Epoch 735/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4145 - accuracy: 0.8148\n",
      "Epoch 736/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8227\n",
      "Epoch 737/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4082 - accuracy: 0.8204\n",
      "Epoch 738/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4090 - accuracy: 0.8204\n",
      "Epoch 739/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4064 - accuracy: 0.8272\n",
      "Epoch 740/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4085 - accuracy: 0.8249\n",
      "Epoch 741/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4115 - accuracy: 0.8182\n",
      "Epoch 742/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4079 - accuracy: 0.8215\n",
      "Epoch 743/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8227\n",
      "Epoch 744/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4072 - accuracy: 0.8204\n",
      "Epoch 745/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4162 - accuracy: 0.8249\n",
      "Epoch 746/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8238\n",
      "Epoch 747/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4083 - accuracy: 0.8215\n",
      "Epoch 748/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8249\n",
      "Epoch 749/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8215\n",
      "Epoch 750/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.8215\n",
      "Epoch 751/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.8215\n",
      "Epoch 752/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8182\n",
      "Epoch 753/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4114 - accuracy: 0.8238\n",
      "Epoch 754/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4062 - accuracy: 0.8215\n",
      "Epoch 755/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4101 - accuracy: 0.8204\n",
      "Epoch 756/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8249\n",
      "Epoch 757/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4105 - accuracy: 0.8227\n",
      "Epoch 758/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4099 - accuracy: 0.8204\n",
      "Epoch 759/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8159\n",
      "Epoch 760/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4089 - accuracy: 0.8249\n",
      "Epoch 761/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4044 - accuracy: 0.8238\n",
      "Epoch 762/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8193\n",
      "Epoch 763/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4092 - accuracy: 0.8148\n",
      "Epoch 764/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8193\n",
      "Epoch 765/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8238\n",
      "Epoch 766/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8215\n",
      "Epoch 767/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4128 - accuracy: 0.8215\n",
      "Epoch 768/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8283\n",
      "Epoch 769/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4137 - accuracy: 0.8204\n",
      "Epoch 770/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8238\n",
      "Epoch 771/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4061 - accuracy: 0.8249\n",
      "Epoch 772/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8260\n",
      "Epoch 773/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8283\n",
      "Epoch 774/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8204\n",
      "Epoch 775/1000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8182\n",
      "Epoch 776/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4147 - accuracy: 0.8238\n",
      "Epoch 777/1000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4141 - accuracy: 0.8249\n",
      "Epoch 778/1000\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.4113 - accuracy: 0.8260\n",
      "Epoch 779/1000\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.4166 - accuracy: 0.8249\n",
      "Epoch 780/1000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.4233 - accuracy: 0.8238\n",
      "Epoch 781/1000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4188 - accuracy: 0.8215\n",
      "Epoch 782/1000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4094 - accuracy: 0.8215\n",
      "Epoch 783/1000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.4136 - accuracy: 0.8204\n",
      "Epoch 784/1000\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.4095 - accuracy: 0.8227\n",
      "Epoch 785/1000\n",
      "4/4 [==============================] - 0s 131ms/step - loss: 0.4098 - accuracy: 0.8238\n",
      "Epoch 786/1000\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.4115 - accuracy: 0.8238\n",
      "Epoch 787/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.4104 - accuracy: 0.8193\n",
      "Epoch 788/1000\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.4122 - accuracy: 0.8272\n",
      "Epoch 789/1000\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.4113 - accuracy: 0.8339\n",
      "Epoch 790/1000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.4212 - accuracy: 0.8159\n",
      "Epoch 791/1000\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.4000 - accuracy: 0.8227\n",
      "Epoch 792/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.4107 - accuracy: 0.8249\n",
      "Epoch 793/1000\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.4096 - accuracy: 0.8238\n",
      "Epoch 794/1000\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.4095 - accuracy: 0.8238\n",
      "Epoch 795/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4097 - accuracy: 0.8182\n",
      "Epoch 796/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4127 - accuracy: 0.8227\n",
      "Epoch 797/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4063 - accuracy: 0.8238\n",
      "Epoch 798/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8283\n",
      "Epoch 799/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.8272\n",
      "Epoch 800/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4027 - accuracy: 0.8204\n",
      "Epoch 801/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8215\n",
      "Epoch 802/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8227\n",
      "Epoch 803/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4077 - accuracy: 0.8227\n",
      "Epoch 804/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4117 - accuracy: 0.8260\n",
      "Epoch 805/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4167 - accuracy: 0.8215\n",
      "Epoch 806/1000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4107 - accuracy: 0.8215\n",
      "Epoch 807/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4062 - accuracy: 0.8238\n",
      "Epoch 808/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8294\n",
      "Epoch 809/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4156 - accuracy: 0.8159\n",
      "Epoch 810/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4092 - accuracy: 0.8294\n",
      "Epoch 811/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4165 - accuracy: 0.8238\n",
      "Epoch 812/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4166 - accuracy: 0.8294\n",
      "Epoch 813/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4150 - accuracy: 0.8260\n",
      "Epoch 814/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4141 - accuracy: 0.8215\n",
      "Epoch 815/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4147 - accuracy: 0.8227\n",
      "Epoch 816/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8238\n",
      "Epoch 817/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4101 - accuracy: 0.8238\n",
      "Epoch 818/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.8238\n",
      "Epoch 819/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4058 - accuracy: 0.8294\n",
      "Epoch 820/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4053 - accuracy: 0.8260\n",
      "Epoch 821/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4114 - accuracy: 0.8204\n",
      "Epoch 822/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4088 - accuracy: 0.8204\n",
      "Epoch 823/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4084 - accuracy: 0.8283\n",
      "Epoch 824/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8204\n",
      "Epoch 825/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4123 - accuracy: 0.8316\n",
      "Epoch 826/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8215\n",
      "Epoch 827/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4139 - accuracy: 0.8215\n",
      "Epoch 828/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4073 - accuracy: 0.8238\n",
      "Epoch 829/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4141 - accuracy: 0.8249\n",
      "Epoch 830/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4092 - accuracy: 0.8215\n",
      "Epoch 831/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.8227\n",
      "Epoch 832/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4137 - accuracy: 0.8204\n",
      "Epoch 833/1000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4110 - accuracy: 0.8227\n",
      "Epoch 834/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4133 - accuracy: 0.8294\n",
      "Epoch 835/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4082 - accuracy: 0.8238\n",
      "Epoch 836/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4125 - accuracy: 0.8260\n",
      "Epoch 837/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4044 - accuracy: 0.8260\n",
      "Epoch 838/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4105 - accuracy: 0.8215\n",
      "Epoch 839/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4057 - accuracy: 0.8193\n",
      "Epoch 840/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4094 - accuracy: 0.8204\n",
      "Epoch 841/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4175 - accuracy: 0.8193\n",
      "Epoch 842/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4151 - accuracy: 0.8193\n",
      "Epoch 843/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8272\n",
      "Epoch 844/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4091 - accuracy: 0.8171\n",
      "Epoch 845/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4120 - accuracy: 0.8249\n",
      "Epoch 846/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4063 - accuracy: 0.8316\n",
      "Epoch 847/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4161 - accuracy: 0.8148\n",
      "Epoch 848/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4071 - accuracy: 0.8249\n",
      "Epoch 849/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8171\n",
      "Epoch 850/1000\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.4150 - accuracy: 0.8260\n",
      "Epoch 851/1000\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.4157 - accuracy: 0.8272\n",
      "Epoch 852/1000\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.4178 - accuracy: 0.8193\n",
      "Epoch 853/1000\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.4113 - accuracy: 0.8260\n",
      "Epoch 854/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.4076 - accuracy: 0.8238\n",
      "Epoch 855/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.4105 - accuracy: 0.8249\n",
      "Epoch 856/1000\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.4115 - accuracy: 0.8215\n",
      "Epoch 857/1000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.4150 - accuracy: 0.8159\n",
      "Epoch 858/1000\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.4131 - accuracy: 0.8182\n",
      "Epoch 859/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.4079 - accuracy: 0.8238\n",
      "Epoch 860/1000\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.4153 - accuracy: 0.8171\n",
      "Epoch 861/1000\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.4064 - accuracy: 0.8204\n",
      "Epoch 862/1000\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.4158 - accuracy: 0.8193\n",
      "Epoch 863/1000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.4015 - accuracy: 0.8249\n",
      "Epoch 864/1000\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.4143 - accuracy: 0.8238\n",
      "Epoch 865/1000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4095 - accuracy: 0.8193\n",
      "Epoch 866/1000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4166 - accuracy: 0.8126\n",
      "Epoch 867/1000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.4110 - accuracy: 0.8193\n",
      "Epoch 868/1000\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.4107 - accuracy: 0.8204\n",
      "Epoch 869/1000\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.4120 - accuracy: 0.8272\n",
      "Epoch 870/1000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.4182 - accuracy: 0.8159\n",
      "Epoch 871/1000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.4068 - accuracy: 0.8193\n",
      "Epoch 872/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.4063 - accuracy: 0.8249\n",
      "Epoch 873/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.4106 - accuracy: 0.8238\n",
      "Epoch 874/1000\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.4156 - accuracy: 0.8215\n",
      "Epoch 875/1000\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.4129 - accuracy: 0.8193\n",
      "Epoch 876/1000\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.4055 - accuracy: 0.8227\n",
      "Epoch 877/1000\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.4090 - accuracy: 0.8227\n",
      "Epoch 878/1000\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.4117 - accuracy: 0.8238\n",
      "Epoch 879/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.4086 - accuracy: 0.8238\n",
      "Epoch 880/1000\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.4039 - accuracy: 0.8283\n",
      "Epoch 881/1000\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.4057 - accuracy: 0.8238\n",
      "Epoch 882/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.4179 - accuracy: 0.8182\n",
      "Epoch 883/1000\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.4142 - accuracy: 0.8148\n",
      "Epoch 884/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.4171 - accuracy: 0.8227\n",
      "Epoch 885/1000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.4090 - accuracy: 0.8316\n",
      "Epoch 886/1000\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.4133 - accuracy: 0.8204\n",
      "Epoch 887/1000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.4155 - accuracy: 0.8204\n",
      "Epoch 888/1000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4087 - accuracy: 0.8249\n",
      "Epoch 889/1000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4074 - accuracy: 0.8249\n",
      "Epoch 890/1000\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.4111 - accuracy: 0.8215\n",
      "Epoch 891/1000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.4122 - accuracy: 0.8238\n",
      "Epoch 892/1000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.4178 - accuracy: 0.8249\n",
      "Epoch 893/1000\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.4089 - accuracy: 0.8227\n",
      "Epoch 894/1000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4047 - accuracy: 0.8227\n",
      "Epoch 895/1000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.4108 - accuracy: 0.8249\n",
      "Epoch 896/1000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.4172 - accuracy: 0.8215\n",
      "Epoch 897/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.4131 - accuracy: 0.8215\n",
      "Epoch 898/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.4179 - accuracy: 0.8238\n",
      "Epoch 899/1000\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.4174 - accuracy: 0.8159\n",
      "Epoch 900/1000\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.4113 - accuracy: 0.8227\n",
      "Epoch 901/1000\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.4109 - accuracy: 0.8193\n",
      "Epoch 902/1000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4055 - accuracy: 0.8249\n",
      "Epoch 903/1000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4075 - accuracy: 0.8227\n",
      "Epoch 904/1000\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.4102 - accuracy: 0.8272\n",
      "Epoch 905/1000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.4080 - accuracy: 0.8272\n",
      "Epoch 906/1000\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.4093 - accuracy: 0.8193\n",
      "Epoch 907/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.4063 - accuracy: 0.8215\n",
      "Epoch 908/1000\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.4148 - accuracy: 0.8249\n",
      "Epoch 909/1000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4092 - accuracy: 0.8305\n",
      "Epoch 910/1000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4118 - accuracy: 0.8283\n",
      "Epoch 911/1000\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.4099 - accuracy: 0.8204\n",
      "Epoch 912/1000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4117 - accuracy: 0.8171\n",
      "Epoch 913/1000\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.4125 - accuracy: 0.8260\n",
      "Epoch 914/1000\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.4075 - accuracy: 0.8227\n",
      "Epoch 915/1000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.4178 - accuracy: 0.8204\n",
      "Epoch 916/1000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.4103 - accuracy: 0.8238\n",
      "Epoch 917/1000\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.4161 - accuracy: 0.8204\n",
      "Epoch 918/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.4100 - accuracy: 0.8272\n",
      "Epoch 919/1000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.4087 - accuracy: 0.8227\n",
      "Epoch 920/1000\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.4086 - accuracy: 0.8227\n",
      "Epoch 921/1000\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.4097 - accuracy: 0.8227\n",
      "Epoch 922/1000\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.4101 - accuracy: 0.8227\n",
      "Epoch 923/1000\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.4135 - accuracy: 0.8227\n",
      "Epoch 924/1000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.4153 - accuracy: 0.8182\n",
      "Epoch 925/1000\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.4106 - accuracy: 0.8193\n",
      "Epoch 926/1000\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.4028 - accuracy: 0.8249\n",
      "Epoch 927/1000\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.4079 - accuracy: 0.8204\n",
      "Epoch 928/1000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.4090 - accuracy: 0.8227\n",
      "Epoch 929/1000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.4099 - accuracy: 0.8283\n",
      "Epoch 930/1000\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.4119 - accuracy: 0.8215\n",
      "Epoch 931/1000\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.4049 - accuracy: 0.8272\n",
      "Epoch 932/1000\n",
      "4/4 [==============================] - 0s 138ms/step - loss: 0.4099 - accuracy: 0.8215\n",
      "Epoch 933/1000\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.4063 - accuracy: 0.8227\n",
      "Epoch 934/1000\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.4048 - accuracy: 0.8204\n",
      "Epoch 935/1000\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.4062 - accuracy: 0.8171\n",
      "Epoch 936/1000\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.4103 - accuracy: 0.8260\n",
      "Epoch 937/1000\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 0.4054 - accuracy: 0.8215\n",
      "Epoch 938/1000\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.4169 - accuracy: 0.8182\n",
      "Epoch 939/1000\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.4015 - accuracy: 0.8215\n",
      "Epoch 940/1000\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.4121 - accuracy: 0.8227\n",
      "Epoch 941/1000\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.4066 - accuracy: 0.8227\n",
      "Epoch 942/1000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.4146 - accuracy: 0.8148\n",
      "Epoch 943/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4095 - accuracy: 0.8227\n",
      "Epoch 944/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4090 - accuracy: 0.8227\n",
      "Epoch 945/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4100 - accuracy: 0.8215\n",
      "Epoch 946/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4104 - accuracy: 0.8193\n",
      "Epoch 947/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4097 - accuracy: 0.8204\n",
      "Epoch 948/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4121 - accuracy: 0.8227\n",
      "Epoch 949/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.8193\n",
      "Epoch 950/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8238\n",
      "Epoch 951/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4099 - accuracy: 0.8238\n",
      "Epoch 952/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.8238\n",
      "Epoch 953/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4193 - accuracy: 0.8215\n",
      "Epoch 954/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4040 - accuracy: 0.8260\n",
      "Epoch 955/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.8193\n",
      "Epoch 956/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.8249\n",
      "Epoch 957/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4099 - accuracy: 0.8305\n",
      "Epoch 958/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4071 - accuracy: 0.8204\n",
      "Epoch 959/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.8227\n",
      "Epoch 960/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8249\n",
      "Epoch 961/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4120 - accuracy: 0.8260\n",
      "Epoch 962/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8148\n",
      "Epoch 963/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8227\n",
      "Epoch 964/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.8249\n",
      "Epoch 965/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4100 - accuracy: 0.8227\n",
      "Epoch 966/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8238\n",
      "Epoch 967/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4157 - accuracy: 0.8238\n",
      "Epoch 968/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4100 - accuracy: 0.8227\n",
      "Epoch 969/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4089 - accuracy: 0.8193\n",
      "Epoch 970/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4134 - accuracy: 0.8227\n",
      "Epoch 971/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4117 - accuracy: 0.8215\n",
      "Epoch 972/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4068 - accuracy: 0.8260\n",
      "Epoch 973/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4137 - accuracy: 0.8238\n",
      "Epoch 974/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8249\n",
      "Epoch 975/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4129 - accuracy: 0.8204\n",
      "Epoch 976/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.8148\n",
      "Epoch 977/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8227\n",
      "Epoch 978/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8238\n",
      "Epoch 979/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4070 - accuracy: 0.8238\n",
      "Epoch 980/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8283\n",
      "Epoch 981/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4141 - accuracy: 0.8215\n",
      "Epoch 982/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4082 - accuracy: 0.8249\n",
      "Epoch 983/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4216 - accuracy: 0.8238\n",
      "Epoch 984/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8260\n",
      "Epoch 985/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4176 - accuracy: 0.8238\n",
      "Epoch 986/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.8182\n",
      "Epoch 987/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4081 - accuracy: 0.8260\n",
      "Epoch 988/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4105 - accuracy: 0.8227\n",
      "Epoch 989/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4065 - accuracy: 0.8249\n",
      "Epoch 990/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8249\n",
      "Epoch 991/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8305\n",
      "Epoch 992/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4078 - accuracy: 0.8215\n",
      "Epoch 993/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.8260\n",
      "Epoch 994/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4085 - accuracy: 0.8283\n",
      "Epoch 995/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4122 - accuracy: 0.8260\n",
      "Epoch 996/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4092 - accuracy: 0.8316\n",
      "Epoch 997/1000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.8316\n",
      "Epoch 998/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8227\n",
      "Epoch 999/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8193\n",
      "Epoch 1000/1000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.8283\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "#######\n",
    "# preparing validation and training data set\n",
    "model = model_titanic()\n",
    "# Training\n",
    "history = model.fit(Dtrain_vec[:,1:],Dtrain_vec[:,0],epochs=1000,batch_size=256,shuffle=True)\n",
    "#######\n",
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a552fbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'accuaracy')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "loss_values = history_dict['loss']\n",
    "epochs = np.arange(1,len(loss_values)+1)\n",
    "\n",
    "plt.plot(epochs,loss_values,\"o-\",label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "acc = history_dict[\"accuracy\"]\n",
    "plt.plot(epochs, acc, \"o-\", label=\"Training acc\")\n",
    "plt.legend()\n",
    "plt.title(\"accuaracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e82fddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([7.1291865 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 2.87081271]),\n",
       " array([0.        , 0.1       , 0.2       , 0.30000001, 0.40000001,\n",
       "        0.5       , 0.60000002, 0.69999999, 0.80000001, 0.89999998,\n",
       "        1.        ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions= np.round(model.predict(Dtest_vec))\n",
    "plt.hist(Dtrain_vec[:,0],density=True)\n",
    "plt.hist(predictions,density=True,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2feb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df  = pd.read_csv('kdata_gender_submission.csv', sep=',', header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94831204",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prediction = pd.DataFrame()\n",
    "my_prediction['PassengerId']=np.copy(test_df['PassengerId'])\n",
    "my_prediction['Survived']=predictions.astype(int)\n",
    "\n",
    "my_prediction.to_csv('my_prediction.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9f4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
